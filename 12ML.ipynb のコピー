{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/group-nai-shomu/00/blob/main/12ML.ipynb","timestamp":1682401790694}],"collapsed_sections":["vO9f-N4Fe3sx","rEqpNQCm2bwU","Tmflw9mF2bjY","M-Hc4YNz2b-r","bj_0nMco3Uu7","pTdUsY50estq","QKoH-aUpp0MI","1r-F3Y7BipWY","l5leAysy4Mp_","SVeDomJ4sp7q"],"toc_visible":true,"authorship_tag":"ABX9TyPDD0l3YkbcdKUGOfDXwkUi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"SodkKgcYM5gm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│線形回帰</font>\n","$\\hat{y} = \\pmb{x}^\\top \\pmb{w}$<br><br>\n","$\\displaystyle L = \\frac{1}{2}\\sum_{n=1}^N (y^{(n)}-t^{(n)})^2+λ \\sum_{i=1}^Kw_i^2$<br><br>\n","$\\displaystyle \\nabla {\\mathcal{L}}_{\\mathcal{D}}(\\pmb{w})=\\frac{\\partial L}{\\partial w}=\\pmb{x}_n^{\\top}(y - t)+2λw$<br><br>\n","class PolynomialRegression(object):<br>\n","$\\qquad$def __ init __ (self, lr=0.01, max_iter=100, lam=0.0):<br>\n","$\\qquad$$\\qquad$self.lr = lr<br>\n","$\\qquad$$\\qquad$self.max_iter = max_iter<br>\n","$\\qquad$$\\qquad$self.w = None<br>\n","$\\qquad$$\\qquad$self.lam = lam<br>\n","$\\qquad$$\\qquad$self.loss_list = []<br>\n","$\\qquad$def fit(self, X, t): <font color=\"silver\">パラメータ更新の繰り返し</font><br>\n","$\\qquad$$\\qquad$self.w = np.random.random(X.shape[1])<br>\n","$\\qquad$$\\qquad$for _ in range(self.max_iter):<br>\n","$\\qquad$$\\qquad$$\\qquad$y = np.dot(X, self.w)  <font color=\"silver\">wは1次元の配列</font><br>\n","$\\qquad$$\\qquad$$\\qquad$loss = (1 / 2) * np.sum((y - t) ** 2) + self.lam * np.sum(self.w ** 2, axis=0) <font color=\"blue\">np.sum, axis=0</font><br>\n","$\\qquad$$\\qquad$$\\qquad$self.loss_list.append(loss) </font><br>\n","$\\qquad$$\\qquad$$\\qquad$gradient = np.dot(X.T, y - t) + 2 * self.lam * self.w<font color=\"blue\">$~\\leftarrow\\ast$</font></font><br>\n","$\\qquad$$\\qquad$$\\qquad$self.w = self.w - self.lr * gradient<br>\n","$\\qquad$def predict(self, X):<br>\n","$\\qquad$$\\qquad$return np.dot(X, self.w)<br>\n"],"metadata":{"id":"6jRtEjPIMmoB"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│ロジスティック回帰</font>\n","class LogisticRegression(object):<br>\n","$\\qquad$def __ init __ (self, lr=0.001, max_iter=100):<br>\n","$\\qquad$$\\qquad$self.lr = lr<br>\n","$\\qquad$$\\qquad$self.max_iter = max_iter<br>\n","$\\qquad$$\\qquad$self.w = None<br>\n","$\\qquad$def _sigmoid(self, z):<br>\n","$\\qquad$$\\qquad$return 1 / (1 + np.exp(-z))<br>\n","$\\qquad$def fit(self, X, t):<br>\n","$\\qquad$$\\qquad$self.w = np.random.randn(X.shape[1])<br>\n","$\\qquad$$\\qquad$for _ in range(self.max_iter): <font color=\"silver\">パラメータ更新の繰り返し</font><br>\n","$\\qquad$$\\qquad$$\\qquad$z = np.dot(X, self.w)<br>\n","$\\qquad$$\\qquad$$\\qquad$y = self._sigmoid(z)<br>\n","$\\qquad$$\\qquad$$\\qquad$loss = np.sum(-t * np.log(y) - (1 - t) * np.log(1 - y))<br>\n","$\\qquad$$\\qquad$$\\qquad$gradient = np.dot(X.T, y - t)<br>\n","$\\qquad$$\\qquad$$\\qquad$self.w -= self.lr * gradient<br>\n","$\\qquad$def predict_proba(self, X):<br>\n","$\\qquad$$\\qquad$z = np.dot(X, self.w)<br>\n","$\\qquad$$\\qquad$return self._sigmoid(z).ravel()<br>\n","$\\qquad$def predict(self, X, threshold=0.5):<br>\n","$\\qquad$$\\qquad$return (self.predict_proba(X) >= threshold).ravel()<br>\n","$\\qquad$def odds(self, X):<br>\n","$\\qquad$$\\qquad$p = self.predict_proba(X)<br>\n","$\\qquad$$\\qquad$return p / (1 - p)<br><br>"],"metadata":{"id":"9CN4Tb6kNHmN"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│近傍法\n","[<font color=\"silver\">$\\tiny{\\rm Code}$…</font>](https://kunassy.com/knn-from-scratch/)</font></font></font><br>\n","<font color=\"silver\">X_new：ラベルを推定したいデータ<br>\n","X：ラベルが判明しているデータ<br>\n","y：Xの各点に対応するラベル<br></font>\n","def kneighbors(X_new, X, n_neighbors, metric):<br>\n","$\\qquad$dist = distance.cdist(X_new, X, metric)<font color=\"silver\">   # 距離行列distを作成<br></font>\n","$\\qquad$k = n_neighbors<br>\n","$\\qquad$neigh_ind = np.argpartition(dist, k)[:,:k] <font color=\"Blue\">np.argpartition</font><font color=\"silver\">   # 距離行列distのうち上位k件のインデックス<br></font>\n","$\\qquad$return neigh_ind<br>\n","def predict(X_new, X, y, n_neighbors, metric):<br>\n","$\\qquad$classes, _y = np.unique(y, return_inverse=True)<br>\n","$\\qquad$neigh_ind = kneighbors(X_new, X, n_neighbors, metric)<font color=\"silver\">   # 距離行列distのうち上位k件のインデックス<br></font>\n","$\\qquad$class_ind, _ = stats.mode(_y[neighbors_ind], axis=1) <font color=\"Blue\">stats.mode, axis=1</font><font color=\"silver\">  # 最頻値 _は最頻値のカウント<br></font>\n","$\\qquad$pred = classes.take(class_ind).ravel()<font color=\"silver\">  # 軸を指定して要素を取り出す<br></font>\n","$\\qquad$return pred<br><br>\n","class KNeighborsClassifier(object):<br>\n","$\\qquad$def __ init __ (self, k=5):<br>\n","$\\qquad$$\\qquad$self.k = k<br>\n","$\\qquad$$\\qquad$self.X_train = None<br>\n","$\\qquad$$\\qquad$self.y_train = None<br>\n","$\\qquad$def fit(self, X, y):<br>\n","$\\qquad$$\\qquad$self.X_train = X<br>\n","$\\qquad$$\\qquad$self.y_train = y<br>\n","$\\qquad$def predict(self, X_target):<br>\n","$\\qquad$$\\qquad$k = self.k<br>\n","$\\qquad$$\\qquad$X_train = self.X_train<br>\n","$\\qquad$$\\qquad$y_train = self.y_train<br>\n","$\\qquad$$\\qquad$predicted = np.array([]) <font color=\"silver\"> # 予測ラベルが格納される配列</font><br>\n","$\\qquad$$\\qquad$for x in X_target:<br>\n","$\\qquad$$\\qquad$$\\qquad$distance = np.linalg.norm(X_train - x, axis=1) <font color=\"Blue\">np.linalg.norm, axis=1</font><font color=\"silver\"> # 距離の算出</font><br>\n","$\\qquad$$\\qquad$$\\qquad$neighbors = np.argsort(distance, axis=0)[:k] <font color=\"Blue\">np.argsort, axis=0</font> <font color=\"silver\"> # 近傍データの選定</font><br>\n","$\\qquad$$\\qquad$$\\qquad$neighbors_class = np.array([y_train[n] for n in neighbors]) <font color=\"silver\"> # 近傍データのクラスを取得</font><br>\n","$\\qquad$$\\qquad$$\\qquad$count = np.bincount(neighbors_class) <font color=\"silver\"> # 各クラスの度数を取得</font><br>\n","$\\qquad$$\\qquad$$\\qquad$mode = np.argmax(count) <font color=\"Blue\">np.argmax</font> <font color=\"silver\"> # 最頻クラスを取得</font><br>\n","$\\qquad$$\\qquad$$\\qquad$predicted = np.append(predicted, mode)<br>\n","$\\qquad$$\\qquad$return predicted<br>"],"metadata":{"id":"NDBqpNltVERm"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│k-means</font>\n","クラスタ数$\\,k\\,$と各クラスタに対応するセントロイド$\\,\\mu_k\\,$の初期値を設定する<br>\n","  while：do<br>\n","  $\\quad$各入力データ$\\,x_i\\,$とセントロイド$\\,\\mu_k\\,$との距離を求める<br>\n","  $\\quad$距離が最も小さいクラスタを求めて、データ$\\,x_i\\,$の新しいクラスタを割り当てる<br>\n","  $\\quad$クラスタ内のデータ$\\,x_i\\,$の平均ベクトルを求めて、新しいセントロイド$\\,\\mu_k\\,$を設定する<br>\n","  $\\quad$新旧クラスタを比較して、クラスタが変わらなかったら終了する<br>\n","  end while：<br><br>\n","<font color=\"silver\"># k個の重心をランダムに設定する</font><br>\n","def init_centroid(X, n_data, k):<br>\n","$\\qquad$idx = np.random.permutation(n_data)[:k] <font color=\"silver\"> # k＝3</font> <font color=\"blue\">np.random.permutation</font><br>\n","$\\qquad$centroids = X[idx]<font color=\"silver\">  # (3, 4)</font><br>\n","$\\qquad$return centroids<br>\n","<font color=\"silver\"># 各点xとk個の重心の距離を格納する配列を作成する</font><br>\n","def compute_distances(X, k, n_data, centroids):<br>\n","$\\qquad$distances = np.zeros((n_data, k)) <font color=\"silver\">  # 距離を格納する受け皿, 零行列, (150, 3), <font color=\"blue\">np.zeros</font></font><br>\n","$\\qquad$for idx_centroids in range(k):<font color=\"silver\">  # 受け皿に距離を格納する</font><br>\n","$\\qquad$$\\qquad$dist = np.sqrt(np.sum((X - centroids[idx_centroids]) ** 2, axis=1)) <font color=\"blue\">np.sum, axis=1</font><br>\n","$\\qquad$$\\qquad$distances[:, idx_centroids] = dist <br>\n","$\\qquad$return distances<br>\n","def k_means(k, X, max_iter=300):<font color=\"silver\">  # k＝3</font><br>\n","$\\qquad$n_data, n_features = X.shape<font color=\"silver\">  # (150, 4)</font><br>\n","$\\qquad$centroids = init_centroid(X, n_data, k)<font color=\"silver\">  # 更新した重心を格納する受け皿, ランダム値, (3, 4), <font color=\"blue\">init_centroid()</font></font><br>\n","$\\qquad$cluster = np.zeros(n_data)<font color=\"silver\">  # クラスタを格納する受け皿, 零行列, (150,), <font color=\"blue\">np.zeros</font></font><br>\n","$\\qquad$new_cluster = np.zeros(n_data)<font color=\"silver\">  # 更新したクラスタを格納する受け皿, 零行列, (150,), <font color=\"blue\">np.zeros</font></font><br>\n","$\\qquad$for epoch in range(max_iter):<br>\n","$\\qquad$$\\qquad$distances = compute_distances(X, k, n_data, centroids)<font color=\"silver\">  #  各点xの要素とk個の重心との距離行列, (150, 3)</font><br>\n","$\\qquad$$\\qquad$new_cluster = np.argmin(distances, axis=1)<font color=\"silver\">  # 距離が一番短いクラスタを新しいクラスタとする, (150,)</font><br>\n","$\\qquad$$\\qquad$for idx_centroids in range(k): <font color=\"silver\">  # クラスタ内の平均を重心とする, (3, 4) </font><font color=\"blue\">np.argmin, axis=1</font><br>\n","$\\qquad$$\\qquad$$\\qquad$centroids[idx_centroids] = X[new_cluster == idx_centroids].mean(axis=0) <font color=\"blue\">mean(axis=0)</font><br> </font>\n","$\\qquad$$\\qquad$if (new_cluster == cluster).all():<font color=\"silver\">  # 更新したクラスタに変化がなくなったら終了</font><br>\n","$\\qquad$$\\qquad$$\\qquad$break<br>\n","$\\qquad$$\\qquad$cluster = new_cluster<br>\n","$\\qquad$return cluster<br>"],"metadata":{"id":"CECyYIQtVMo_"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│k-means++\n","\n"," - データ$\\,x_i\\,$からランダムに1つデータを選び、それをセントロイド$\\,\\mu_1\\,$とする<br>\n"," -  データ$\\,x_i\\,$とセントロイド$\\,\\mu_1\\,$との最も近い距離$\\,d(x)^2\\,$をとる<br>\n"," - 重み付き確率からセントロイドをランダムに設定する<br>\n","$\\phi(x) = \\cfrac{d(x_k)^2}{\\sum_k d(x_k)^2}$<br>\n"," - 代表点の合計数が$\\,k\\,$個集まればk-meansを実行する<br><br>\n"," def k_init(X, n_clusters):<br>\n","$\\qquad$n_samples, n_features = X.shape<br>\n","$\\qquad$centers = np.empty((n_clusters, n_features), dtype = X.dtype)<br>\n","$\\qquad$center_id = np.random.randint(n_samples) <font color=\"silver\"> # 最初の重心を設定</font><br>\n","$\\qquad$centers[0] = Ｘ[center_id]<br>\n","$\\qquad$closest_dist_sq = distance.cdist(Ｘ[[center_id]], X, metric = \"sqeuclidean\") <font color=\"silver\"> # 各点xと重心との距離</font><br>\n","$\\qquad$current_pot = closest_dist_sq.sum()<font color=\"silver\"> # 距離の合計</font><br>\n","$\\qquad$for c in range(1, n_clusters):<br>\n","$\\qquad$$\\qquad$rand_val = np.random.random_sample(1) * current_pot<font color=\"silver\"> # サンプリングに距離を掛ける</font><br>\n","$\\qquad$$\\qquad$center_id = np.serchsorted(np.cumsum(closest_dist_sq), rand_val)<br>\n","$\\qquad$$\\qquad$tmp_dist = distance.cdist(Ｘ[[center_id]], X, metric = \"sqeuclidean\") <font color=\"silver\"> # 重心との距離を求める</font><br>\n","$\\qquad$$\\qquad$closest_dist_sq = np.minimum(closest_dist_sq, tmp_dist)<br>\n","$\\qquad$$\\qquad$centers[c] = X[center_id]<font color=\"silver\"> # サンプリングされた重心を追加</font><br>\n","$\\qquad$$\\qquad$current_pot = closest_dist_sq.sum()<font color=\"silver\"># 距離の合計</font><br>\n","$\\qquad$return centers<br><br>\n","<font color=\"silver\"># 各点xとk個のセントロイドの距離を格納する配列を作成する</font><br>\n","def compute_distances(X, k, n_data, centroids):<br>\n","$\\qquad$distances = np.zeros((n_data, k)) <font color=\"silver\">  # 距離を格納する受け皿, 零行列, (150, 3), <font color=\"blue\">np.zeros</font></font><br>\n","$\\qquad$for idx_centroids in range(k):<font color=\"silver\">  # 受け皿に距離を格納する</font><br>\n","$\\qquad$$\\qquad$dist = np.sqrt(np.sum((X - centroids[idx_centroids]) ** 2, axis=1)) <font color=\"blue\">np.sum, axis=1</font><br>\n","$\\qquad$$\\qquad$distances[:, idx_centroids] = dist <br>\n","$\\qquad$return distances<br>\n","def init_centroid(X, k, n_data):<br>\n","$\\qquad$idx = np.random.choice(n_data, 1)<font color=\"silver\"> # 最初の重心をランダムに設定, <font color=\"blue\">np.random.choice</font></font><br>\n","$\\qquad$centroids = X[idx]<br>\n","$\\qquad$for i in range(k - 1):<br>\n","$\\qquad$$\\qquad$distances = compute_distances(X, len(centroids), n_data, centroids)<font color=\"silver\"> # 各点xと重心との距離</font><br>\n","$\\qquad$$\\qquad$closest_dist_sq = np.min(distances ** 2, axis=1)<font color=\"silver\"> # 各点xと最も近い重心との距離の二乗和</font> <font color=\"blue\">np.min, axis=1</font><br>\n","$\\qquad$$\\qquad$weights = closest_dist_sq.sum()<font color=\"silver\"> # 距離の合計</font> <font color=\"blue\">sum()</font><br>\n","$\\qquad$$\\qquad$rand_vals = np.random.random_sample() * weights<font color=\"silver\"><font color=\"silver\"> # サンプリングに距離を掛ける</font></font><br>\n","$\\qquad$$\\qquad$candidate_ids = np.searchsorted(np.cumsum(closest_dist_sq), rand_vals) <font color=\"blue\">np.searchsorted</font><br>\n","$\\qquad$$\\qquad$centroids = np.vstack([centroids, X[candidate_ids]])<font color=\"silver\"> # サンプリングされた重心を追加</font> <font color=\"blue\">np.vstack</font><br>\n","$\\qquad$return centroids<br>\n"],"metadata":{"id":"Wnwt6jDBVNxI"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│PCA</font>\n","def svd(A)<br>\n","$\\qquad$B = np.dot(A.T, A)<br>\n","$\\qquad$eigen_values, eigen_vectors = np.linalg,eig(B) <font color=\"silver\"> # 固有値と固有値ベクトルを求める</font><br>\n","$\\qquad$singular_values = np.sqrt(eigen_values) <font color=\"silver\">  # 特異値を求める</font><br>\n","$\\qquad$singular_index = np.argsort(singular_values)[::-1]<br>\n","$\\qquad$S = np.diagflat(singular_values[singular_index]) <font color=\"silver\">  # 特異値行列を求める</font><br>\n","$\\qquad$V = eigen_vectors[:, singular_index] <font color=\"silver\">  # 右特異値行列を求める</font><br>\n","$\\qquad$dig = S.diagonal() <font color=\"silver\">  # 左特異値行列を求める</font><br>\n","$\\qquad$U = [np.dot(A, V[:, i]) / dig[i] for i in range(len(dig))]<br>\n","$\\qquad$U = np.array(U).T<br>\n","$\\qquad$return U, S, V<br>\n","def pca(X, n_components):<br>\n","$\\qquad$X = X - X.mean(axis=0)<br>\n","$\\qquad$U, S, V = svd(X)<br>\n","$\\qquad$n = n_components<br>\n","$\\qquad$X_new = np.dot(U[:, :n], S[:n, :n])<br>\n","$\\qquad$retuerm X_new<br>\n","<br>\n","def pca(X, n_components=2):    \n","$\\qquad$cov = np.cov(X, rowvar=False)  <font color=\"silver\">  # 共分散行列</font><br>\n","$\\qquad$l, v = np.linalg.eig(cov)  <font color=\"silver\">  # 固有値＝分散、固有ベクトル≒主成分負荷量</font><br>\n","$\\qquad$l_index = np.argsort(l)[::-1]  <font color=\"silver\">  # 固有値の大きい順にソート</font><br>\n","$\\qquad$v_ = v[:,l_index] <br>\n","$\\qquad$components = v_[:,:n_components]  <font color=\"silver\">  # n_components分, 主成分方向を取得</font>    \n","$\\qquad$T = np.dot(X, components)  <font color=\"silver\">  # データを低次元空間へ射影</font><br>\n","$\\qquad$return T</font><br>"],"metadata":{"id":"tOn2Q2TwVO3k"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│Affine</font>\n","$\\scriptsize\\pmb{Y} = \\pmb{X} \\pmb{W}+ \\pmb{B} \\qquad \\cfrac{\\partial L}{\\partial \\pmb{X}}= \\cfrac{\\partial L}{\\partial \\pmb{Y}}\\pmb{W}^{\\top} \\qquad \\cfrac{\\partial L}{\\partial \\pmb{W}}= \\pmb{X}^{\\top} \\cfrac{\\partial L}{\\partial \\pmb{Y}}  \\qquad \\cfrac{\\partial L}{\\partial \\pmb{B}} = \\cfrac{\\partial L}{\\partial \\pmb{Y}}$<br><br>\n","out = np.dot(x, W) + b<br>\n","<font color=\"red\">dx = np.dot(dout, W.T)<br>\n","dW = np.dot(x.T, dout)<br>\n","db = np.sum(dout, axis=0)</font><br><br>\n","class Affine:<br>\n","$\\qquad$    def __init __(self, W, b):<br>\n","$\\qquad$$\\qquad$self.W =W<br>\n","$\\qquad$$\\qquad$self.b = b<br>\n","$\\qquad$$\\qquad$self.x = None<br>\n","$\\qquad$$\\qquad$self.original_x_shape = None<br>\n","$\\qquad$$\\qquad$self.dW = None<br>\n","$\\qquad$$\\qquad$self.db = None<br>\n","$\\qquad$def forward(self, x):<br>\n","$\\qquad$$\\qquad$self.original_x_shape = x.shape<br>\n","$\\qquad$$\\qquad$x = x.reshape(x.shape[0], -1)<br>\n","$\\qquad$$\\qquad$self.x = x <font color=\"silver\"># 逆伝播で使う</font><br>\n","$\\qquad$$\\qquad$out = np.dot(self.x, self.W) + self.b<br>\n","$\\qquad$$\\qquad$return out<br>\n","$\\qquad$def backward(self, dout):<br>\n","$\\qquad$$\\qquad$dx = np.dot(dout, self.W.T)<br>\n","$\\qquad$$\\qquad$self.dW = np.dot(self.x.T, dout)<br>\n","$\\qquad$$\\qquad$self.db = np.sum(dout, axis=0) <br>\n","$\\qquad$$\\qquad$dx = dx.reshape(*self.original_x_shape) <br> \n","$\\qquad$$\\qquad$return dx<br> \n"],"metadata":{"id":"bUVn5VW91wpv"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│Convolution</font>\n","- <font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/jun40vn/items/be48afbdd9da19f1e43e)<br></font>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F209705%2Fdbc63c54-5af4-58ce-4e60-afdd60fa66ae.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=64f069c6a2ee316857848529e8cad72c\" width=\"480\"><br><br>\n","$\\scriptsize \\rm OH = \\cfrac{H + 2P - FH}{S} + 1 \\qquad OW = \\cfrac{W + 2P - FW}{S} + 1$<br><br>\n","<font color=\"black\">def im2col(input_data, filter_h, filter_w, stride=1, pad=0, constant_values=0):  <font color=\"silver\"># (N, C, H, W)</font><br>\n","$\\qquad$N, C, H, W = input_data.shape <br>\n","$\\qquad$out_h = (H + 2 * pad - filter_h)//stride + 1<br>\n","$\\qquad$out_w = (W + 2 * pad - filter_w)//stride + 1 <font color=\"silver\">np.pad(img, [(上, 下), (左, 右)], 'constant')</font><br>\n","$\\qquad$img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant', constant_values=constant_values)<br>\n","$\\qquad$col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))  <font color=\"silver\"># 受け皿, (N, C, FH, FW, OH, OW)</font><br>\n","$\\qquad$for y in range(filter_h):<br>\n","$\\qquad$$\\qquad$y_max = y + stride * out_h<br>\n","$\\qquad$$\\qquad$for x in range(filter_w):<br>\n","$\\qquad$$\\qquad$$\\qquad$x_max = x + stride * out_w<br>\n","$\\qquad$$\\qquad$$\\qquad$col[ : , $\\:$ : , $\\:$ y, $\\:$ x, $\\:$ : , $\\:$ : ] = img[ : , $\\:$ : , $\\:$ y : y_max : stride, $\\:$ x : x_max : stride]<br>\n","$\\qquad$$\\qquad$col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)<br>\n","$\\qquad$$\\qquad$return col <font color=\"silver\"># (N×OH×OW, C×FH×FW)</font><br> \n","def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0): <br>\n","$\\qquad$N, C, H, W = input_shape<br>\n","$\\qquad$out_h = (H + 2*pad - filter_h)//stride + 1<br>\n","$\\qquad$out_w = (W + 2*pad - filter_w)//stride + 1<br>\n","$\\qquad$col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)   <font color=\"silver\"># (N, C, FH, FW, OH, OW)</font><br></font>\n","$\\qquad$img = np.zeros((N, C, H + 2 * pad + stride - 1, W + 2 * pad + stride - 1))  <font color=\"silver\"># 受け皿, (N, C, H, W)</font><br>\n","$\\qquad$for y in range(filter_h):<br>\n","$\\qquad$$\\qquad$y_max = y + stride * out_h<br>\n","$\\qquad$$\\qquad$for x in range(filter_w):<br>\n","$\\qquad$$\\qquad$$\\qquad$x_max = x + stride*out_w<br>\n","$\\qquad$$\\qquad$$\\qquad$img[ :, $\\:$ : , $\\:$ y : y_max : stride, $\\:$ x : x_max  : stride ] += col[ : , $\\:$ : , $\\:$ y, $\\:$ x, $\\:$ : , $\\:$ : ]<br>\n","$\\qquad$return img[ :, $\\:$ : , $\\:$ pad : H + pad, $\\:$ pad : W + pad]   <font color=\"silver\"># (N, C, H, W), pad分と(stride - 1)分を除いて真ん中だけを取り出す<br>\n","$\\qquad$# 2*padは、pad分を大きくとっている。<br>\n","$\\qquad$# (stride - 1)は、im2colで画像が切り捨てられる場合のサイズ調整分。<br>\n","$\\qquad$# im2colで、strideを2以上に設定した場合、あるひとつの方向に最大で(stride - 1)個の画素が切り捨てられる。<br>\n","$\\qquad$# このような切り捨てが発生する場合、col2imのimg[:, :, y:y_max:stride, x:x_max:stride] でスライスを使って<br>\n","$\\qquad$# stride刻みで値を代入する際にエラーが出て止まってしまう。<br>\n","$\\qquad$# そのため、縦横ともに(stride - 1)個分だけ余分に配列を確保しておき、<br>\n","$\\qquad$# 最後に余分なところを切り捨てることでサイズを調整している。<br></font>\n","class Convolution:<br>\n","$\\qquad$def __ init __ (self, W, b, stride=1, pad=0):<br>\n","$\\qquad$$\\qquad$self.W = W<br>\n","$\\qquad$$\\qquad$self.b = b<br>\n","$\\qquad$$\\qquad$self.stride = stride<br>\n","$\\qquad$$\\qquad$self.pad = pad<br>\n","$\\qquad$$\\qquad$self.x = None   <br>\n","$\\qquad$$\\qquad$self.col = None<br>\n","$\\qquad$$\\qquad$self.col_W = None<br>\n","$\\qquad$$\\qquad$self.dcol = None<br>\n","$\\qquad$$\\qquad$self.dW = None<br>\n","$\\qquad$$\\qquad$self.db = None<br>\n","$\\qquad$def forward(self, x):<br>\n","$\\qquad$$\\qquad$FN, C, FH, FW = self.W.shape<br>\n","$\\qquad$$\\qquad$N, C, H, W = x.shape<br>\n","$\\qquad$$\\qquad$out_h = (H + 2 * self.pad - FH) // self.stride + 1<br>\n","$\\qquad$$\\qquad$out_w =(W + 2 * self.pad - FW) // self.stride + 1<br>\n","$\\qquad$$\\qquad$col = im2col(x, FH, FW, self.stride, self.pad) <font color=\"silver\"> # (N, C, H, W) → (N×OH×OW, C×FH×FW)<br></font>\n","$\\qquad$$\\qquad$col_W = self.W.reshape(FN, -1).T <font color=\"silver\"> # (FN, C, FH, FW) → (C×FH×FW, FN)<br></font>\n","$\\qquad$$\\qquad$out = np.dot(col, col_W) + self.b <font color=\"silver\"> # (N×OH×OW, C×FH×FW) ･ (C×FH×FW, FN) → (N×OH×OW, FN)<br></font>\n","$\\qquad$$\\qquad$out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2) <font color=\"silver\"> # (N×OH×OW, FN) → (N, FN, OH, OW) <br></font>\n","$\\qquad$$\\qquad$self.x = x<br>\n","$\\qquad$$\\qquad$self.col = col<br>\n","$\\qquad$$\\qquad$self.col_W = col_W<br>\n","$\\qquad$$\\qquad$return out<br>\n","$\\qquad$def backward(self, dout):<br>\n","$\\qquad$$\\qquad$FN, C, FH, FW = self.W.shape  <br>\n","$\\qquad$$\\qquad$dout = dout.transpose(0,2,3,1).reshape(-1, FN) <font color=\"silver\"> # (N, FN, OH, OW) → (N, OH, OW, FN) → (N×OH×OW, FN)<br></font>\n","$\\qquad$$\\qquad$self.db = np.sum(dout, axis=0)<br>\n","$\\qquad$$\\qquad$self.dW = np.dot(self.col.T, dout)<br>\n","$\\qquad$$\\qquad$self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)<br>\n","$\\qquad$$\\qquad$dcol = np.dot(dout, self.col_W.T)<br>\n","$\\qquad$$\\qquad$dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad, is_backward=True)    <br>\n","$\\qquad$$\\qquad$return dx"],"metadata":{"id":"ZQtfmpuV13d6"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│Pooling</font>\n"," - <font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/jun40vn/items/be48afbdd9da19f1e43e)<br></font>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F209705%2F61f173ac-cd49-b11a-dff0-3dc09ca6e2fa.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=56e79a9ecd6420ab0b0221ebf34708d9\" width=\"480\"><br><br>\n","class MaxPooling:<br>\n","$\\qquad$def __ init__(self, pool_h, pool_w, stride=1, pad=0):<br>\n","$\\qquad$$\\qquad$self.pool_h = pool_h<br>\n","$\\qquad$$\\qquad$self.pool_w = pool_w<br>\n","$\\qquad$$\\qquad$self.stride = stride<br>\n","$\\qquad$$\\qquad$self.pad = pad<br>\n","$\\qquad$$\\qquad$self.x = None<br>\n","$\\qquad$$\\qquad$self.arg_max = None<br>\n","$\\qquad$$\\qquad$self.dcol = None <br>\n","$\\qquad$def forward(self, x): <br>\n","$\\qquad$$\\qquad$N, C, H, W = x.shape<br>\n","$\\qquad$$\\qquad$out_h = (H  + 2 * self.pad - self.pool_h) // self.stride + 1<br>\n","$\\qquad$$\\qquad$out_w = (W + 2 * self.pad - self.pool_w) // self.stride + 1 <font color=\"silver\"> # (N, C, H, W) → (N×OH×OW, C×PH×PW)</font><br>\n","$\\qquad$$\\qquad$col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad, constant_values=-np.inf)<br>\n","$\\qquad$$\\qquad$col = col.reshape(-1, self.pool_h*self.pool_w) <font color=\"silver\"> # (N×OH×OW×C, PH×PW)<br></font>\n","$\\qquad$$\\qquad$arg_max = np.argmax(col, axis=1)<br>\n","$\\qquad$$\\qquad$out = np.max(col, axis=1) <font color=\"silver\"> # (N×OH×OW×C, )<br></font>\n","$\\qquad$$\\qquad$out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2) <font color=\"silver\"> # (N, C, H, W)</font><br>\n","$\\qquad$$\\qquad$self.x = x<br>\n","$\\qquad$$\\qquad$self.arg_max = arg_max<br>\n","$\\qquad$$\\qquad$return out <font color=\"silver\"> # (N, C, H, W)</font><br>\n","$\\qquad$def backward(self, dout):<br>\n","$\\qquad$$\\qquad$dout = dout.transpose(0, 2, 3, 1)<br>\n","$\\qquad$$\\qquad$pool_size = self.pool_h * self.pool_w<br>\n","$\\qquad$$\\qquad$dcol = np.zeros((dout.size, pool_size)) <font color=\"silver\"> # 受け皿, (N×OH×OW×C, PH×PW)</font><br>\n","$\\qquad$$\\qquad$dcol[np.arange(dcol.shape[0]), self.arg_max] = dout.flatten()<font color=\"silver\"> # 最大値となった場所にdoutを配置する<br></font>\n","$\\qquad$$\\qquad$dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad, is_backward=True)<br>\n","$\\qquad$$\\qquad$return dx"],"metadata":{"id":"RZ4oaGxa18wL"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│Embedding [<font color=\"silver\">…</font>](https://colab.research.google.com/drive/1jHoNQ3WVt23ckB6h41dTcKzL6Lp-bE8P) [<font color=\"silver\">…</font>](https://colab.research.google.com/drive/1-x4z7J09ofCMIEIDBGzOxWjJtcStYGCt)</font>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/jun40vn/items/35f6f0d26f9e58f01e4e)</font><br>\n","<img src=\"https://camo.qiitausercontent.com/32654fed87f53f2b82b773d50c36e94a97f9bec0/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3230393730352f31363033633765302d653532392d346237632d653936312d3039396561653661663433632e706e67\" width=\"400\"><br><br>\n","class Embedding:<br>\n","$\\qquad$def __ init __ (self, W): <font color=\"silver\"> # W（語彙数、埋め込みベクトルの要素数）</font><br>\n","$\\qquad$$\\qquad$self.params = [W] <font color=\"silver\"> # 要素は1つだけであるが、他のレイヤと仕様を揃えるため、リストで定義</font><br>\n","$\\qquad$$\\qquad$self.grads = [np.zeros_like(W)] <font color=\"silver\"> # 要素は1つだけであるが、他のレイヤと仕様を揃えるため、リストで定義</font><br>\n","$\\qquad$$\\qquad$self.idx = None<br>\n","$\\qquad$def forward(self, idx):<br>\n","$\\qquad$$\\qquad$W = self.params[0]<br>\n","$\\qquad$$\\qquad$self.idx = idx<br>\n","$\\qquad$$\\qquad$out = W[idx] <font color=\"silver\"> # 埋め込み行列から埋め込みベクトルを取り出す</font><br>\n","$\\qquad$$\\qquad$return out<br>\n","$\\qquad$def backward(self, dout):<br>\n","$\\qquad$$\\qquad$dW = self.grads[0]  <font color=\"silver\"> # gradsというリストの1要素目を参照する </font><br>\n","$\\qquad$$\\qquad$dW.fill(0)  <font color=\"silver\"># 配列の全ての要素に0を代入する</font><br>\n","$\\qquad$$\\qquad$np.add.at(dW, self.idx, dout) <font color=\"silver\"> # dWのidxの場所にdoutを加える</font><br>\n","$\\qquad$$\\qquad$return None<br><br>\n","class Embedder(nn.Module):<br>\n","$\\qquad$def  __ init __ (self, text_embedding_vectors):<br>\n","$\\qquad$$\\qquad$super(Embedder, self). __ init __ ()<br>\n","$\\qquad$$\\qquad$self.embeddings = nn.Embedding.from_pretrained(text_embedding_vectors, freeze=True) <font color=\"silver\"># freeze=Trueで更新しない</font><br>\n","$\\qquad$def forward(self, x): <font color=\"silver\">(T, ) = (256, )</font><br>\n","$\\qquad$$\\qquad$x_vec = self.embeddings(x)<br>\n","$\\qquad$$\\qquad$return x_vec <font color=\"silver\">(T, D) = (256, 300)</font><br>"],"metadata":{"id":"BVrNvmq82Bt5"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│RNN [<font color=\"silver\">…</font>](https://colab.research.google.com/drive/1_yk7HQMLkOcRYW2pVuXwsUGgBwQud9Hi) [<font color=\"silver\">…</font>](https://colab.research.google.com/drive/1XB4YMUWWA7SnBUjATacx9aPADISqMafv)</font>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/jun40vn/items/35f6f0d26f9e58f01e4e)</font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F209705%2F19a3800d-3b64-913e-9ae4-71afde545a8e.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=7297e80d594fe5f8a5038f1251e11b9d\" width=\"640\"><br><br>\n","$\\mathbf{H}_t^{(l)} = \\tanh(\\mathbf{H}_t^{(l-1)} \\mathbf{W}_{xh}^{(l)} + \\mathbf{H}_{t-1}^{(l)} \\mathbf{W}_{hh}^{(l)}  + \\mathbf{b}_h^{(l)})$<br><br>\n","t = np.dot(h_prev, Wh) + np.dot(x, Wx) + b<br>\n","h_next = np.tanh(t)<br><br>\n","h_next = np.tanh(t)<br>\n","<font color=\"red\">dt = dh_next * (1 - h_next ** 2)</font><br>\n","t = np.dot(h_prev, Wh) + np.dot(x, Wx) + b<br>\n","<font color=\"red\">db = np.sum(dt, axis=0)<br>\n","dWh = np.dot(h_prev.T, dt)<br>\n","dh_prev = np.dot(dt, Wh.T)<br>\n","dWx = np.dot(x.T, dt)<br>\n","dx = np.dot(dt, Wx.T)</font><br><br>\n","class RNN:<br>\n","$\\qquad$def __ init __(self, Wx, Wh, b):<br>\n","$\\qquad$$\\qquad$self.params = [Wx, Wh, b]<br>\n","$\\qquad$$\\qquad$self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]<br>\n","$\\qquad$$\\qquad$self.cache = None<br>\n","$\\qquad$def forward(self, x, h_prev):<br>\n","$\\qquad$$\\qquad$Wx, Wh, b = self.params<br>\n","$\\qquad$$\\qquad$t = np.dot(h_prev, Wh) + np.dot(x, Wx) + b<br>\n","$\\qquad$$\\qquad$h_next = np.tanh(t)<br>\n","$\\qquad$$\\qquad$self.cache = (x, h_prev, h_next)<br>\n","$\\qquad$$\\qquad$return h_next<br>\n","$\\qquad$def backward(self, dh_next):<br>\n","$\\qquad$$\\qquad$Wx, Wh, b = self.params<br>\n","$\\qquad$$\\qquad$x, h_prev, h_next = self.cache<br>\n","$\\qquad$$\\qquad$A3 = dh_next * (1 - h_next ** 2) # dh_next * (1 - y^2)<br>\n","$\\qquad$$\\qquad$db = np.sum(A3, axis=0)<br>\n","$\\qquad$$\\qquad$dWh = np.dot(h_prev.T, A3)<br>\n","$\\qquad$$\\qquad$dh_prev = np.dot(A3, Wh.T)<br>\n","$\\qquad$$\\qquad$dWx = np.dot(x.T, A3)<br>\n","$\\qquad$$\\qquad$dx = np.dot(A3, Wx.T)<br>\n","$\\qquad$$\\qquad$self.grads[0][:] = dWx <br>\n","$\\qquad$$\\qquad$self.grads[1][:] = dWh <br>\n","$\\qquad$$\\qquad$self.grads[2][:] = db<br>\n","$\\qquad$$\\qquad$return dx, dh_prev<br>\n"],"metadata":{"id":"OkokyP4g2GZ7"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│LSTM</font>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/jun40vn/items/35f6f0d26f9e58f01e4e)</font><br>\n","<img src=\"https://camo.qiitausercontent.com/b9387ed37d1f247f8f679184f8dd2efd1e7a709a/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3230393730352f35306164343264652d643433642d333162392d333761652d3637666462313032393939612e706e67\" width=\"640\"><br><br>\n","N, H = h_prev.shape<br>\n","A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b<br>\n","f = A[:, :H]<br>\n","g = A[:, H:2H]<br>\n","i = A[:, 2H:3H]<br>\n","o = A[:, 3H:]<br>\n","f = sigmoid(f)<br>\n","g = np.tanh(g)<br>\n","i = sigmoid(i)<br>\n","o = sigmoid(o)<br>\n","c_next = f * c_prev + g * i<br>\n","tanh_c_next = np.tanh(c_next)<br>\n","h_next = o * tanh_c_next<br><br>\n","<img src=\"https://camo.qiitausercontent.com/bd2fad9749a2dd322a1dd9f8dcfbcf3ee209107a/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3230393730352f62366631386438372d613436662d643762302d303435382d3733656163373434663465662e706e67\" width=\"640\"><br><br>\n","N, H = h_prev.shape<br>\n","A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b<br>\n","f = A[:, :H]<br>\n","g = A[:, H:2H]<br>\n","i = A[:, 2H:3H]<br>\n","o = A[:, 3H:]<br>\n","f = sigmoid(f)<br>\n","g = np.tanh(g)<br>\n","i = sigmoid(i)<br>\n","o = sigmoid(o)<br>\n","c_next = f * c_prev + g * i<br>\n","tanh_c_next = np.tanh(c_next)<br>\n","h_next = o * tanh_c_next<br>\n","<font color=\"red\">A2 = (dh_next * o) * (1 - tanh_c_next ** 2)<br>\n","ds = dc_next + A2<br>\n","dc_prev = ds * f<br>\n","di = ds * g<br>\n","df = ds * c_prev<br>\n","do = dh_next * tanh_c_next<br>\n","dg = ds * i<br>\n","di * = i * (1 - i)<br>\n","df * = f * (1 - f)<br>\n","do * = o * (1 - o)<br>\n","dg * = (1 - g * * 2)<br>\n","dA = np.hstack((df, dg, di, do))<br>\n","dWh = np.dot(h_prev.T, dA)<br>\n","dWx = np.dot(x.T, dA)<br>\n","db = dA.sum(axis=0)<br>\n","dx = np.dot(dA, Wx.T)<br>\n","dh_prev = np.dot(dA, Wh.T)</font><br><br>\n","\n","class LSTM:<br>\n","$\\qquad$def __ init __ (self, Wx, Wh, b):<br>\n","$\\qquad$$\\qquad$self.params = [Wx, Wh, b]<br>\n","$\\qquad$$\\qquad$self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]<br>\n","$\\qquad$$\\qquad$self.cache = None<br>\n","$\\qquad$def forward(self, x, h_prev, c_prev): <br>\n","$\\qquad$$\\qquad$Wx, Wh, b = self.params<br>\n","$\\qquad$$\\qquad$N, H = h_prev.shape<br>\n","$\\qquad$$\\qquad$A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b<br>\n","$\\qquad$$\\qquad$f = A[:, :H]<br>\n","$\\qquad$$\\qquad$g = A[:, H:2*H]<br>\n","$\\qquad$$\\qquad$i = A[:, 2*H:3*H]<br>\n","$\\qquad$$\\qquad$o = A[:, 3*H:]<br>\n","$\\qquad$$\\qquad$f = sigmoid(f)<br>\n","$\\qquad$$\\qquad$g = np.tanh(g)<br>\n","$\\qquad$$\\qquad$i = sigmoid(i)<br>\n","$\\qquad$$\\qquad$o = sigmoid(o)<br>\n","$\\qquad$$\\qquad$c_next = f * c_prev + g * i<br>\n","$\\qquad$$\\qquad$tanh_c_next = np.tanh(c_next)<br>\n","$\\qquad$$\\qquad$h_next = o * tanh_c_next<br>\n","$\\qquad$$\\qquad$self.cache = (x, h_prev, c_prev, i, f, g, o, tanh_c_next)<br>\n","$\\qquad$$\\qquad$return h_next, c_next<br>\n","$\\qquad$def backward(self, dh_next, dc_next):<br>\n","$\\qquad$$\\qquad$Wx, Wh, b = self.params<br>\n","$\\qquad$$\\qquad$x, h_prev, c_prev, i, f, g, o, tanh_c_next = self.cache<br>\n","$\\qquad$$\\qquad$A2 = (dh_next * o) * (1 - tanh_c_next ** 2)<br>\n","$\\qquad$$\\qquad$ds = dc_next + A2<br>\n","$\\qquad$$\\qquad$dc_prev = ds * f<br>\n","$\\qquad$$\\qquad$di = ds * g<br>\n","$\\qquad$$\\qquad$df = ds * c_prev<br>\n","$\\qquad$$\\qquad$do = dh_next * tanh_c_next<br>\n","$\\qquad$$\\qquad$dg = ds * i<br>\n","$\\qquad$$\\qquad$di * = i * (1 - i)<br>\n","$\\qquad$$\\qquad$df * = f * (1 - f)<br>\n","$\\qquad$$\\qquad$do * = o * (1 - o)<br>\n","$\\qquad$$\\qquad$dg * = (1 - g * * 2)<br>\n","$\\qquad$$\\qquad$dA = np.hstack((df, dg, di, do))<br>\n","$\\qquad$$\\qquad$dWh = np.dot(h_prev.T, dA)<br>\n","$\\qquad$$\\qquad$dWx = np.dot(x.T, dA)<br>\n","$\\qquad$$\\qquad$db = dA.sum(axis=0)<br>\n","$\\qquad$$\\qquad$dx = np.dot(dA, Wx.T)<br>\n","$\\qquad$$\\qquad$dh_prev = np.dot(dA, Wh.T)<br>\n","$\\qquad$$\\qquad$self.grads[0][:] = dWx<br>\n","$\\qquad$$\\qquad$self.grads[1][:] = dWh<br>\n","$\\qquad$$\\qquad$self.grads[2][:] = db<br>\n","$\\qquad$$\\qquad$return dx, dh_prev, dc_prev<br>"],"metadata":{"id":"vll_aAT92KsD"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│GRU</font>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/jun40vn/items/4ca1645210e5fbfafa1f)</font></font><br>\n","<img src=\"https://camo.qiitausercontent.com/f80caaadacd1c4ded8d1190d0fd964f3786f8fe5/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3230393730352f34356163383866642d393137662d373661352d633562662d3733633466396164616666352e706e67\" width=\"320\"><br><br>\n","def forward(self, x, h_prev):<br>\n","$\\qquad$Wx, Wh, b = self.params<br>\n","$\\qquad$N, H = h_prev.shape<br>\n","$\\qquad$Wxz, Wxr, Wxh = Wx[:, :H], Wx[:, H:2 * H], Wx[:, 2 * H:]<br>\n","$\\qquad$Whz, Whr, Whh = Wh[:, :H], Wh[:, H:2 * H], Wh[:, 2 * H:]<br>\n","$\\qquad$bhz,   bhr,  bhh =  b[:H], b[H:2 * H], b[2 * H:]<br>\n","$\\qquad$z = sigmoid(np.dot(x, Wxz) + np.dot(h_prev, Whz) + bhz)<br>\n","$\\qquad$r = sigmoid(np.dot(x, Wxr) + np.dot(h_prev, Whr) + bhr)<br>\n","$\\qquad$h_hat = np.tanh(np.dot(x, Wxh) + np.dot(r*h_prev, Whh) + bhh)<br>\n","$\\qquad$h_next = z * h_prev + (1-z) * h_hat<br>\n","$\\qquad$self.cache = (x, h_prev, z, r, h_hat)<br>\n","$\\qquad$return h_next<br><br>\n"],"metadata":{"id":"5I8ga98h2O05"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│SigmoidWithLoss\n"," y = sigmoid(x)<br>\n","loss = cross_entropy_error(y, t)<br>\n","<font color=\"red\">dx = (y - t) / batch_size</font><br><br>\n","class Sigmoid:<br>\n","$\\qquad$def forward(self, x, w, b):<br>\n","$\\qquad$$\\qquad$self.x = x<br>\n","$\\qquad$$\\qquad$z = np.sum(w * x,  axis=1) + b <font color=\"blue\">axis=1</font><br>\n","$\\qquad$$\\qquad$y_pred = 1 / (1 + np.exp(-z))<br>\n","$\\qquad$$\\qquad$self.y_pred = y_pred<br>\n","$\\qquad$$\\qquad$return y_pred<br>\n","$\\qquad$def backward(self, dy):<br>\n","$\\qquad$$\\qquad$dz = dy * (1.0 - self.y_pred) * self.y_pred<br>\n","$\\qquad$$\\qquad$dw = np.sum(self.x * dz.reshape(-1,1), axis=0) <font color=\"blue\">axis=0</font><br>\n","$\\qquad$$\\qquad$db = np.sum(dz)<br>\n","$\\qquad$$\\qquad$return dw, db<br>\n","class NegativeLogLikelihood:<br>\n","$\\qquad$def forward(self, y_pred, y_true):<br>\n","$\\qquad$$\\qquad$self.y_pred = y_pred<br>\n","$\\qquad$$\\qquad$self.y_true = y_true<br>\n","$\\qquad$$\\qquad$loss = - (y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))<br>\n","$\\qquad$$\\qquad$return loss.sum()<br>\n","$\\qquad$def backward(self):<br>\n","$\\qquad$$\\qquad$dy = - (self.y_true / self.y_pred) + ((1 - self.y_true) / (1 - self.y_pred))<br>\n","$\\qquad$$\\qquad$return dy<br>"],"metadata":{"id":"W-fbyH6Hg76A"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│SoftmaxWithLoss</font>\n"," y = softmax(x)<br>\n","loss = cross_entropy_error(y, t)<br>\n","<font color=\"red\">dx = (y - t) / batch_size</font><br><br>\n","def cross_entropy_error(y, t):<br>\n","$\\qquad$if y.ndim==1:<br>\n","$\\qquad$$\\qquad$t = t.reshape(1, -1) <br>\n","$\\qquad$$\\qquad$y = y.reshape(1, -1)  <br> \n","$\\qquad$batch_size = y.shape[0]<br>\n","$\\qquad$delta = 1e-7<br>\n","$\\qquad$return -np.sum( t * np.log(y + delta)) / batch_size<br>\n","class SoftmaxWithLoss:<br>\n","$\\qquad$def __ init __(self):<br>\n","$\\qquad$$\\qquad$self.loss = None<br>\n","$\\qquad$$\\qquad$self.y = None<br>\n","$\\qquad$$\\qquad$self.t = None <br>\n","$\\qquad$def forward(self, x, t):<br>\n","$\\qquad$$\\qquad$self.t = t<br>\n","$\\qquad$$\\qquad$self.y = softmax(x)<br>\n","$\\qquad$$\\qquad$self.loss = cross_entropy_error(self.y, self.t) <br>\n","$\\qquad$$\\qquad$return self.loss<br>\n","$\\qquad$def backward(self, dout=1):<br>\n","$\\qquad$$\\qquad$batch_size = self.t.shape[0]<br>\n","$\\qquad$$\\qquad$dx = (self.y - self.t) / batch_size<br>\n","$\\qquad$$\\qquad$return dx<br>"],"metadata":{"id":"nQQjZ2Tng0z-"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│TrainerCNN</font>\n","<font color=\"silver\"># モデルとオプティマイザーの定義</font><br>\n","snet = SimpleConvNet(<br>\n","$\\qquad$input_dim=(1, 28, 28),<br>\n","$\\qquad$conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},<br>\n","$\\qquad$pool_param={'pool_size':2, 'pad':0, 'stride':2},<br>\n","$\\qquad$hidden_size=100, <br>\n","$\\qquad$output_size=10, <br>\n","$\\qquad$weight_init_std=0.01<br>\n","$\\qquad$)<br>\n","optimizer = RMSProp(lr=0.01, rho=0.9)<br>\n","<font color=\"silver\"># バッチサイズとエポックを定義して学習</font><br>\n","xsize = x.shape[0]<br>\n","batch_size = 100<br>\n","epochs = 10<br>\n","iter_num = np.ceil(xsize / batch_size).astype(np.int)<br>\n","for epoch in range(epochs):<br>\n","$\\qquad$idx = np.arange(xsize)<br>\n","$\\qquad$np.random.shuffle(idx)<br>\n","$\\qquad$for it in range(iter_num):<br>\n","$\\qquad$$\\qquad$mask = idx[batch_size*it : batch_size*(it+1)]<br>\n","$\\qquad$$\\qquad$x_train = x[mask]<br>\n","$\\qquad$$\\qquad$t_train = t[mask]<br>\n","$\\qquad$$\\qquad$grads = snet.gradient(x_train, t_train)<br>\n","$\\qquad$$\\qquad$optimizer.update(snet.params, grads)<br>\n","<br>\n","for epoch in range(epochs):</font><br>\n","$\\qquad$model.train()  <font color=\"silver\"># モデルを学習モードに切り替え</font><br>\n","$\\qquad$for X, y in train_loader:<br>\n","$\\qquad$$\\qquad$<font color=\"silver\"># lossの計算, 順伝播</font><br>\n","$\\qquad$$\\qquad$y_pred = model(X.to(device))<br>\n","$\\qquad$$\\qquad$loss = loss_func(y_pred, y.to(device))<br>\n","$\\qquad$$\\qquad$<font color=\"silver\"># モデルの更新, 逆伝播＋パラメータ更新</font><br>\n","$\\qquad$$\\qquad$optimizer.zero_grad()<font color=\"silver\"> # 勾配を0で初期化</font><br>\n","$\\qquad$$\\qquad$loss.backward()<br>\n","$\\qquad$$\\qquad$optimizer.step()<br>\n","$\\qquad$model.eval()  <font color=\"silver\"># モデルを評価モードに切り替え</font><br>\n","$\\qquad$with torch.no_grad():  <font color=\"silver\"># 勾配計算を行わない</font><br>\n","$\\qquad$$\\qquad$for X_valid, y_valid in test_loader:<br>\n","$\\qquad$$\\qquad$$\\qquad$<font color=\"silver\"># lossの計算</font><br>\n","$\\qquad$$\\qquad$$\\qquad$y_pred_valid = model(X_valid.to(device))<br>\n","$\\qquad$$\\qquad$$\\qquad$loss_valid = loss_func(y_pred_valid, y_valid.to(device))<br>\n","<br>\n","model_naive.train()  <font color=\"silver\"># モデルを学習モードに切り替え</font><br>\n","for epoch in range(1, epoch_num+1):<br>\n","$\\qquad$for image, label in train_loader:<br>\n","$\\qquad$$\\qquad$<font color=\"silver\"># lossの計算, 順伝播</font><br>\n","$\\qquad$$\\qquad$if use_cuda:<br>\n","$\\qquad$$\\qquad$$\\qquad$image = image.cuda()<br>\n","$\\qquad$$\\qquad$$\\qquad$label = label.cuda()<br>\n","$\\qquad$$\\qquad$y = model_naive(image)<br>\n","$\\qquad$$\\qquad$loss = criterion(y, label)<br>\n","$\\qquad$$\\qquad$<font color=\"silver\"># モデルの更新, 逆伝播＋パラメータ更新</font><br>\n","$\\qquad$$\\qquad$model_naive.zero_grad()<font color=\"silver\"> # 勾配を0で初期化</font><br>\n","$\\qquad$$\\qquad$loss.backward() <br>\n","$\\qquad$$\\qquad$optimizer_naive.step() <br>\n","model_naive.eval()  <font color=\"silver\"># モデルを評価モードに切り替え</font><br>\n","with torch.no_grad():  <font color=\"silver\"># 勾配計算を行わない</font><br>\n","$\\qquad$for image, label in test_loader:<br>\n","$\\qquad$$\\qquad$<font color=\"silver\"># 評価の計算</font><br>\n","$\\qquad$$\\qquad$if use_cuda:<br>\n","$\\qquad$$\\qquad$$\\qquad$image = image.cuda()<br>\n","$\\qquad$$\\qquad$$\\qquad$label = label.cuda()<br>\n","$\\qquad$$\\qquad$y = model_naive(image)<br>\n","$\\qquad$$\\qquad$pred = torch.argmax(y, dim=1)<br>"],"metadata":{"id":"VfIG0V7V0kNR"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│TrainerRNN</font>\n","corpus, word_to_id, id_to_word = ptb.load_data('train')   # 学習データの読み込み（データセットを小さくする）<br>\n","corpus_size = 1000<br>\n","corpus = corpus[:corpus_size]<br>\n","vocab_size = int(max(corpus) + 1)<br>\n","wordvec_size = 100<br>\n","hidden_size = 100<br>\n","xs = corpus[:-1]  # 入力<br>\n","ts = corpus[1:]  # 出力（教師ラベル）<br>\n","data_size = len(xs)<br>\n","print('corpus size: %d, vocabulary size: %d' % (corpus_size, vocab_size))<br>\n","model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)<br>\n","optimizer = SGD(lr = 0.1)<br>\n","batch_size = 10<br>\n","time_size = 5  <br>\n","max_iters = data_size // (batch_size * time_size)<br>\n","max_epoch = 100<br>\n","time_idx = 0<br>\n","total_loss = 0<br>\n","loss_count = 0<br>\n","ppl_list = []<br>\n","ミニバッチの各サンプルの読み込み開始位置を計算<br>\n","jump = (corpus_size - 1) // batch_size<br>\n","offsets = [i * jump for i in range(batch_size)]<br>\n","for epoch in range(max_epoch):<br>\n","$\\qquad$for iter in range(max_iters):<br>\n","$\\qquad$$\\qquad$batch_x = np.empty((batch_size, time_size), dtype='i')<br>\n","$\\qquad$$\\qquad$batch_t = np.empty((batch_size, time_size), dtype='i')<br>\n","$\\qquad$$\\qquad$for t in range(time_size):<br>\n","$\\qquad$$\\qquad$$\\qquad$for i, offset in enumerate(offsets):<br>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$batch_x[i, t] = xs[(offset + time_idx) % data_size]<br>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$batch_t[i, t] = ts[(offset + time_idx) % data_size]<br>\n","$\\qquad$$\\qquad$$\\qquad$time_idx += 1<br>\n","$\\qquad$$\\qquad$loss = model.forward(batch_x, batch_t)<br>\n","$\\qquad$$\\qquad$model.backward()<br>\n","$\\qquad$$\\qquad$optimizer.update(model.params, model.grads)<br>\n","$\\qquad$$\\qquad$total_loss += loss<br>\n","$\\qquad$$\\qquad$loss_count += 1<br>\n","$\\qquad$ppl = np.exp(total_loss / loss_count)<br>\n","$\\qquad$print('| epoch %d | perplexity %.2f'<br>\n","$\\qquad$$\\qquad$  % (epoch+1, ppl))<br>\n","$\\qquad$ppl_list.append(float(ppl))<br>\n","$\\qquad$total_loss, loss_count = 0, 0<br>\n","x = np.arange(len(ppl_list))<br>\n","plt.plot(x, ppl_list, label='train')<br>\n","plt.xlabel('epochs')<br>\n","plt.ylabel('perplexity')<br>\n","plt.show()<br>\n","<br>\n","class RnnlmTrainer:<br>\n","$\\qquad$def __ init __ (self, model, optimizer):<br>\n","$\\qquad$$\\qquad$self.model = model<br>\n","$\\qquad$$\\qquad$self.optimizer = optimizer<br>\n","$\\qquad$def get_batch(self, x, t, batch_size, time_size):<br>\n","$\\qquad$$\\qquad$batch_x = np.empty((batch_size, time_size), dtype='i')<br>\n","$\\qquad$$\\qquad$batch_t = np.empty((batch_size, time_size), dtype='i')<br>\n","$\\qquad$$\\qquad$data_size = len(x)<br>\n","$\\qquad$$\\qquad$jump = data_size // batch_size<br>\n","$\\qquad$$\\qquad$offsets = [i * jump for i in range(batch_size)] <font color=\"silver\"> # バッチの各サンプルの読み込み開始位置<br></font>\n","$\\qquad$$\\qquad$for time in range(time_size):<br>\n","$\\qquad$$\\qquad$$\\qquad$for i, offset in enumerate(offsets):<br>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$batch_x[i, time] = x[(offset + self.time_idx) % data_size]<br>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$batch_t[i, time] = t[(offset + self.time_idx) % data_size]<br>\n","$\\qquad$$\\qquad$$\\qquad$self.time_idx += 1<br>\n","$\\qquad$$\\qquad$return batch_x, batch_t<br>\n","$\\qquad$def fit(self, xs, ts, max_epoch=10, batch_size=20, time_size=35,<br>\n","$\\qquad$$\\qquad$$\\qquad$max_grad=None, eval_interval=20):<br>\n","$\\qquad$$\\qquad$data_size = len(xs)<br>\n","$\\qquad$$\\qquad$max_iters = data_size // (batch_size * time_size)<br>\n","$\\qquad$$\\qquad$model, optimizer = self.model, self.optimizer<br>\n","$\\qquad$$\\qquad$for epoch in range(max_epoch):<br>\n","$\\qquad$$\\qquad$$\\qquad$for iters in range(max_iters):<br>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$batch_x, batch_t = self.get_batch(xs, ts, batch_size, time_size)<br>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$loss = model.forward(batch_x, batch_t)<br>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$model.backward()<br>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$params, grads = remove_duplicate(model.params, model.grads) <font color=\"silver\"> # 共有された重みを1つに集約<br></font>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$if max_grad is not None:<br>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$$\\qquad$clip_grads(grads, max_grad)<br>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$optimizer.update(params, grads)<br>\n","$\\qquad$$\\qquad$$\\qquad$self.current_epoch += 1<br>\n","<br>\n","class Trainer:<br>\n","$\\qquad$def __ init __ (self, model, optimizer):<br>\n","$\\qquad$$\\qquad$self.model = model<br>\n","$\\qquad$$\\qquad$self.optimizer = optimizer<br>\n","$\\qquad$def fit(self, x, t, max_epoch=10, batch_size=32, max_grad=None, eval_interval=20):<br>\n","$\\qquad$$\\qquad$data_size = len(x)<br>\n","$\\qquad$$\\qquad$max_iters = data_size // batch_size<br>\n","$\\qquad$$\\qquad$model, optimizer = self.model, self.optimizer<br>\n","$\\qquad$$\\qquad$for epoch in range(max_epoch):<br>\n","$\\qquad$$\\qquad$$\\qquad$idx = numpy.random.permutation(numpy.arange(data_size))<br>\n","$\\qquad$$\\qquad$$\\qquad$x = x[idx]<br>\n","$\\qquad$$\\qquad$$\\qquad$t = t[idx]<br>\n","$\\qquad$$\\qquad$$\\qquad$for iters in range(max_iters):<br>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$batch_x = x[iters*batch_size:(iters+1)*batch_size]<br>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$batch_t = t[iters*batch_size:(iters+1)*batch_size]<br>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$loss = model.forward(batch_x, batch_t)<br>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$model.backward()<br>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$params, grads = remove_duplicate(model.params, model.grads) <font color=\"silver\"> # 共有された重みを1つに集約<br></font>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$if max_grad is not None:<br>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$$\\qquad$clip_grads(grads, max_grad)<br>\n","$\\qquad$$\\qquad$$\\qquad$$\\qquad$optimizer.update(params, grads)<br>\n","$\\qquad$$\\qquad$$\\qquad$self.current_epoch += 1<br>\n","<br>\n","model.train()  <font color=\"silver\"># モデルを学習モードに変更</font><br>\n","for src, trg in train_dataloader:<br>\n","$\\qquad$src = src.to(device)<br>\n","$\\qquad$trg = trg.to(device)<br>\n","$\\qquad$output = model(src, trg)  <font color=\"silver\"># 教師強制 オン</font><br>\n","$\\qquad$output = output[1:].view(-1, output.shape[-1])  <font color=\"silver\"># 出力単語のIDを取り出す</font><br>\n","$\\qquad$trg = trg[1:].view(-1)<br>\n","$\\qquad$loss = criterion(output, trg)<br>\n","$\\qquad$optimizer.zero_grad()  <font color=\"silver\"># 勾配を0で初期化</font><br>\n","$\\qquad$loss.backward()<br>\n","$\\qquad$torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  <font color=\"silver\"># 勾配クリッピング</font><br>\n","$\\qquad$optimizer.step()<br>\n","model.eval()<br>\n","with torch.no_grad():  <font color=\"silver\"># 勾配を更新しない</font><br>\n","$\\qquad$for src, trg in tmp_dataloader:<br>\n","$\\qquad$$\\qquad$src = src.to(device)<br>\n","$\\qquad$$\\qquad$trg = trg.to(device)<br>\n","$\\qquad$$\\qquad$output = model(src, trg, 0)  <font color=\"silver\"># 教師強制 オフ</font><br>\n","$\\qquad$$\\qquad$output = output[1:].view(-1, output.shape[-1])  <font color=\"silver\"># 出力単語のIDを取り出す</font><br>\n","$\\qquad$$\\qquad$trg = trg[1:].view(-1)<br>\n","$\\qquad$$\\qquad$loss = criterion(output, trg)<br>\n","model.eval()  <font color=\"silver\"># モデルを推論モードに変更</font><br>\n","with torch.no_grad():  <font color=\"silver\"># 勾配を更新しない</font><br>\n","$\\qquad$src, trg = next(iter(tmp_dataloader))  <font color=\"silver\"># データの取り出し</font><br>\n","$\\qquad$src = src.to(device)<br>\n","$\\qquad$trg = trg.to(device)<br>\n","$\\qquad$output = model(src, trg, 0)  <font color=\"silver\"># 教師強制をオフ</font><br>"],"metadata":{"id":"a69hnaYl1G-E"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│TrainerGAN</font>\n","GANを学習する際は，binary cross entopyを用いて、実画像は1に，生成画像は0に近似するように学習をする。<br>\n","実画像は1、生成画像は0と設定して、binary cross entopyを用いて損失を求める。<br>\n","Discriminatorは、実画像は1生成画像は0と識別するとように学習をする。<br>\n","Generatorは生成した画像を実画像であるとDiscriminatorに誤識別をさせたいので，1と識別されるように学習をする。<br><br>\n","discriminator = make_discriminator_model()<br>\n","generator = make_generator_model()<br>\n","discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-4)<br>\n","generator_optimizer = torch.optim.Adam(generator.parameters(), lr=1e-4)<br>\n","cross_entropy = torch.nn.BCEWithLogitsLoss()<br>\n","def discriminator_loss(real_output, fake_output):<br>\n","$\\qquad$loss1 = cross_entropy(real_output, torch.ones_like( real_output ))<br>\n","$\\qquad$loss2 = cross_entropy(fake_output, torch.zeros_like( fake_output ))<br>\n","$\\qquad$return loss1 + loss2<br>\n","def generator_loss(output):<br>\n","$\\qquad$return cross_entropy(output, torch.ones_like(output) )<br>\n","def train_step(images):<br>\n","$\\qquad$<font color=\"silver\"># discriminatorの計算, 勾配を0で初期化</font><br>\n","$\\qquad$discriminator.zero_grad()<br>\n","$\\qquad$<font color=\"silver\"># lossの計算, 順伝播</font><br>\n","$\\qquad$real_output = discriminator(images).view(-1)<br>\n","$\\qquad$noise = torch.randn(BATCH_SIZE, noise_dim, 1, 1)<br>\n","$\\qquad$generated_images = generator(noise)<br>\n","$\\qquad$fake_output = discriminator(generated_images.detach()).view(-1)<br>\n","$\\qquad$disc_loss = discriminator_loss(real_output, fake_output)<br>\n","$\\qquad$<font color=\"silver\"># モデルの更新, 逆伝播＋パラメータ更新</font><br>\n","$\\qquad$disc_loss.backward()<br>\n","$\\qquad$discriminator_optimizer.step()<br>\n","$\\qquad$<font color=\"silver\"># generatorの計算, 勾配を0で初期化</font><br>\n","$\\qquad$generator.zero_grad()<br>\n","$\\qquad$<font color=\"silver\"># lossの計算, 順伝播</font><br>\n","$\\qquad$fake_output = discriminator(generated_images).view(-1)<br>\n","$\\qquad$gen_loss = generator_loss(fake_output)<br>\n","$\\qquad$<font color=\"silver\"># モデルの更新, 逆伝播＋パラメータ更新</font><br>\n","$\\qquad$gen_loss.backward()<br>\n","$\\qquad$generator_optimizer.step()<br>\n","if __ name __ == '__ main __':<br>\n","$\\qquad$dataset = get_dataset()<br>\n","$\\qquad$dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)<br>\n","$\\qquad$for epoch in range(EPOCHS):<br>\n","$\\qquad$$\\qquad$for image_batch, _ in dataloader:<br>\n","$\\qquad$$\\qquad$$\\qquad$train_step(image_batch)<br>"],"metadata":{"id":"DSMOWlHTDVmm"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│Grad-CAM</font>\n","Grad-CAM\n","ターゲットレイヤ<br>\n","FasterRCNN ➡ model.backbone<br>\n","Resnet18 and 50 ➡ model.layer4[-1]<br>\n","VGG and densenet161 ➡ model.features[-1]<br><br>\n","input_tensor = preprocess_image(rgb_img, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])<br>\n","model = vgg16(pretrained=True)<br>\n","target_layer = [model.features[-1]] <font color=\"Silver\"> # モデルによりターゲットレイヤが異なる</font><br>\n","target_category = [ClassifierOutputTarget(243)] <font color=\"Silver\"> # 分類したクラス</font><br>\n","gradcam = GradCAM(model=model, target_layer=target_layer)<br>\n","grayscale_cam = gradcam(input_tensor=input_tensor, target_category=target_category)<br><br>\n","grayscale_cam = grayscale_cam[0, :]<br>\n","cam_image = show_cam_on_image(rgb_img, grayscale_cam)<br>\n","cam_image = cv2.cvtColor(cam_image, cv2.COLOR_BGR2RGB)<br>\n","plt.imshow(cam_image, cmap='jet')<br>\n","plt.colorbar()<br>\n","plt.savefig('result.png')<br>"],"metadata":{"id":"m1ClMnbDhFVd"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│BatchNorm</font>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://konchangakita.hatenablog.com/entry/2021/01/12/210000)<br></font>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/k/konchangakita/20210111/20210111154320.png\" width=\"800\"><br>\n","N, D = x.shape<br>\n","mu = np.mean(x, axis=0) <font color=\"silver\"> # 入力xをNの方向に平均 (D, ) <font color=\"blue\">axis=0</font><br></font>\n","mu = np.broadcast_to(mu, (N, D)) <font color=\"silver\"> # Nの方向にブロードキャスト (N, D)<br></font>\n","x_mu = x - mu <font color=\"silver\"> # 入力xから平均値を引く (N, D)<br></font>\n","var = np.mean(x_mu ** 2, axis=0) <font color=\"silver\"> # 入力xの分散, 分散は(x - mu) ** 2を平均したもの, (D, )  <font color=\"blue\">axis=0</font> <br></font>\n","std = np.sqrt(var + epsilon) <font color=\"silver\"> # 入力xの標準偏差, 標準偏差は分散の平方根, (D, ) <br></font>\n","std_inv = 1 / std <font color=\"silver\"> # 標準偏差の逆数 (D, ) <br></font>\n","std_inv = np.broadcast_to(std_inv, (N, D)) <font color=\"silver\"> # Nの方向にブロードキャスト (N, D)  <br></font>\n","x_std = x_mu * std_inv <font color=\"silver\"> # 標準化 (N, D)<br></font>\n","out = gamma * x_std + beta <font color=\"silver\"> # gammaでスケール、betaでシフト (N, D)<br><br></font>\n","moving_mean = rho * moving_mean + (1-rho) * mu<br>\n","moving_var = rho * moving_var + (1-rho) * var<br>\n","x_mu = x - moving_mean <font color=\"silver\"> # (N, D)<br></font>\n","x_std = x_mu / np.sqrt(moving_var + epsilon)  # (N, D)<br></font>\n","out = gamma * x_std + beta <font color=\"silver\"> # gammaでスケール、betaでシフト (N, D)<br><br></font>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://rikei-logistics.com/batch-normalization1)<br></font>\n","<img src=\"https://rikei-logistics.com/wp-content/uploads/2021/11/1-3-5.png\" height=\"240\">\n","<img src=\"https://rikei-logistics.com/wp-content/uploads/2021/11/1-5-5.png\" height=\"240\"><br><br>\n","out = self.gamma * x_std + self.beta <font color=\"silver\"> # gammaでスケール、betaでシフト (N, D)<br></font>\n","<font color=\"red\">dbeta = np.sum(dout, axis=0) </font><font color=\"silver\"> # (D, )<br></font></font>\n","<font color=\"red\">dgamma = np.sum(self.x_std * dout, axis=0)<font color=\"silver\"># (D, )<br></font></font>\n","<font color=\"red\">dx_std = self.gamma * dout  </font><font color=\"silver\">  # (N, D)<br></font></font>\n","x_std = x_mu * std_inv <font color=\"silver\"> # 標準化 (N, D)<br></font>\n","<font color=\"red\">dx_mu_1 = dx_std / std  </font><font color=\"silver\"> # a2, Xmuの勾配(1つ目)<br></font></font>\n","<font color=\"red\">dstd_inv = dx_std * x_mu  </font><font color=\"silver\">  # a3, 標準偏差の逆数の勾配<br></font></font>\n","std_inv = np.broadcast_to(std_inv, (N, D)) <font color=\"silver\"> # Nの方向にブロードキャスト (N, D)  <br></font>\n","<font color=\"red\">dstd_inv = np.sum(dstd_inv, axis=0)  </font><font color=\"silver\">  #  a3, Nの方向に合計<br></font></font>\n","std_inv = 1 / std <font color=\"silver\"> # 標準偏差の逆数 (D, ) <br></font>\n","<font color=\"red\">dstd = -(dstd_inv) / (std * std)  </font><font color=\"silver\">  #   a4, 標準偏差の勾配<br></font></font>\n","std = np.sqrt(var + epsilon) <font color=\"silver\"> # 入力xの標準偏差 (D, ) <br></font>\n","<font color=\"red\">dvar = 0.5 * dstd / std  </font><font color=\"silver\">  # a5, 分散の勾配<br></font></font>\n","var = np.mean(x_mu**2, axis=0) <font color=\"silver\"> # 入力xの分散 (D, )  <br></font>\n","<font color=\"red\">a6 = dvar / batch_size  </font><font color=\"silver\">  # Xmuの2乗の勾配<br></font></font>\n","<font color=\"red\">a6 = np.broadcast_to(a6, (N, D))  </font> </font><font color=\"silver\"> # Nの方向にブロードキャスト\" <br></font></font>\n","<font color=\"red\">dx_mu_2 = 2.0  * x_mu * a6  </font><font color=\"silver\">  # a7, Xmuの勾配(2つ目)<br></font></font>\n","x_mu = x - mu <font color=\"silver\"> # 入力xから平均値を引く (N, D)<br></font>\n","<font color=\"red\">dmu = -(dx_mu_1+dx_mu_2)  </font><font color=\"silver\"> # a8, a2+a7, muの勾配<br></font></font>\n","mu = np.broadcast_to(mu, (N, D)) <font color=\"silver\"> # Nの方向にブロードキャスト (N, D)<br></font>\n","<font color=\"red\">dmu = np.sum(dmu, axis=0)  </font><font color=\"silver\">   a8, # Nの方向に合計<br></font></font>\n","<font color=\"black\">mu = np.mean(x, axis=0) <font color=\"silver\"> # 入力xをNの方向に平均 (D, )<br></font>\n","<font color=\"red\">a9 = dmu / batch_size  </font><font color=\"silver\">  # Xの勾配<br></font></font>\n","<font color=\"red\">a9 = np.broadcast_to(a9, (N, D))  </font><font color=\"silver\">  # Nの方向にブロードキャスト<br></font></font>\n","<font color=\"red\">dx = a2 + a7 + a9<br><br></font>\n","class BatchNormalization:<br>\n","$\\qquad$def __ init __ (self,<br>\n","$\\qquad$$\\qquad$$\\qquad$gamma,<br>\n","$\\qquad$$\\qquad$$\\qquad$beta,<br>\n","$\\qquad$$\\qquad$$\\qquad$ rho=0.9,<br>\n","$\\qquad$$\\qquad$$\\qquad$ moving_mean=None,<br>\n","$\\qquad$$\\qquad$$\\qquad$ moving_var=None<br>\n","$\\qquad$$\\qquad$$\\qquad$ ):<br>\n","$\\qquad$$\\qquad$self.gamma = gamma <font color=\"silver\"># スケールさせるためのパラメータ, 学習によって更新させる<br></font>\n","$\\qquad$$\\qquad$self.beta = beta <font color=\"silver\"> # シフトさせるためのパラメータ, 学習によって更新させる<br></font>\n","$\\qquad$$\\qquad$self.rho = rho <font color=\"silver\"> # 移動平均を算出する際に使用する係数<br></font>\n","$\\qquad$$\\qquad$self.moving_mean = moving_mean <font color=\"silver\"> # 予測時に使用する平均の移動平均<br></font>\n","$\\qquad$$\\qquad$self.moving_var = moving_var <font color=\"silver\"> # 予測時に使用する分散の移動平均<br></font>\n","$\\qquad$$\\qquad$self.batch_size = None<br>\n","$\\qquad$$\\qquad$self.x_mu = None<br>\n","$\\qquad$$\\qquad$self.x_std = None<br>\n","$\\qquad$$\\qquad$self.std = None<br>\n","$\\qquad$$\\qquad$self.dgamma = None<br>\n","$\\qquad$$\\qquad$self.dbeta = None<br>\n","$\\qquad$def forward(self, x, train_flg=True):<br>\n","$\\qquad$$\\qquad$if x.ndim == 4:<br>\n","$\\qquad$$\\qquad$$\\qquad$N, C, H, W = x.shape<br>\n","$\\qquad$$\\qquad$$\\qquad$x = x.transpose(0, 2, 3, 1) <font color=\"silver\"> # NHWCに入れ替え<br></font>\n","$\\qquad$$\\qquad$$\\qquad$x = x.reshape(N * H * W, C) <font color=\"silver\"> # (N * H * W,C)の2次元配列に変換<br></font>\n","$\\qquad$$\\qquad$$\\qquad$out = self. __ forward(x, train_flg)<br>\n","$\\qquad$$\\qquad$$\\qquad$out = out.reshape(N, H, W, C) <font color=\"silver\"> # 4次元配列に変換<br></font>\n","$\\qquad$$\\qquad$$\\qquad$out = out.transpose(0, 3, 1, 2) <font color=\"silver\"> # 軸をNCHWに入れ替え<br></font>\n","$\\qquad$$\\qquad$elif x.ndim == 2:<br>\n","$\\qquad$$\\qquad$$\\qquad$out = self. __ forward(x, train_flg)   <br>\n","$\\qquad$$\\qquad$return out<br>\n","$\\qquad$def __ forward(self, x, train_flg, epsilon=1e-8):<br>\n","$\\qquad$$\\qquad$if (self.moving_mean is None) or (self.moving_var is None):<br>\n","$\\qquad$$\\qquad$$\\qquad$N, D = x.shape<br>\n","$\\qquad$$\\qquad$$\\qquad$self.moving_mean = np.zeros(D)<br>\n","$\\qquad$$\\qquad$$\\qquad$self.moving_var = np.zeros(D)<br>\n","$\\qquad$$\\qquad$if train_flg: <font color=\"silver\"> # 学習時<br></font>\n","$\\qquad$$\\qquad$$\\qquad$mu = np.mean(x, axis=0) <font color=\"silver\"> # 入力xをNの方向に平均 (D, ) <font color=\"blue\">axis=0</font><br></font>\n","$\\qquad$$\\qquad$$\\qquad$mu = np.broadcast_to(mu, (N, D)) <font color=\"silver\"> # Nの方向にブロードキャスト (N, D)<br></font>\n","$\\qquad$$\\qquad$$\\qquad$x_mu = x - mu <font color=\"silver\"> # 入力xから平均値を引く (N, D)<br></font>\n","$\\qquad$$\\qquad$$\\qquad$var = np.mean(x_mu ** 2, axis=0) <font color=\"silver\"> # 入力xの分散 (D, )  <font color=\"blue\">axis=0</font> <br></font>\n","$\\qquad$$\\qquad$$\\qquad$std = np.sqrt(var + epsilon) <font color=\"silver\"> # 入力xの標準偏差 (D, ) <br></font>\n","$\\qquad$$\\qquad$$\\qquad$std_inv = 1 / std <font color=\"silver\"> # 標準偏差の逆数 (D, ) <br></font>\n","$\\qquad$$\\qquad$$\\qquad$std_inv = np.broadcast_to(std_inv, (N, D)) <font color=\"silver\"> # Nの方向にブロードキャスト (N, D)  <br></font>\n","$\\qquad$$\\qquad$$\\qquad$x_std = x_mu * std_inv <font color=\"silver\"> # 標準化 (N, D)<br></font>\n","$\\qquad$$\\qquad$$\\qquad$self.batch_size = x.shape[0]<br>\n","$\\qquad$$\\qquad$$\\qquad$self.x_mu = x_mu<br>\n","$\\qquad$$\\qquad$$\\qquad$self.x_std = x_std<br>\n","$\\qquad$$\\qquad$$\\qquad$self.std = std<br>\n","$\\qquad$$\\qquad$$\\qquad$self.moving_mean = self.rho * self.moving_mean + (1-self.rho) * mu<br>\n","$\\qquad$$\\qquad$$\\qquad$self.moving_var = self.rho * self.moving_var + (1-self.rho) * var<br>\n","$\\qquad$$\\qquad$else: <font color=\"silver\"> # 予測時<br></font>\n","$\\qquad$$\\qquad$$\\qquad$x_mu = x - self.moving_mean <font color=\"silver\"> # (N, D)<br></font>\n","$\\qquad$$\\qquad$$\\qquad$x_std = x_mu / np.sqrt(self.moving_var + epsilon)  # (N, D)<br></font>\n","$\\qquad$$\\qquad$out = self.gamma * x_std + self.beta <font color=\"silver\"> # gammaでスケール、betaでシフト (N, D)<br></font>\n","$\\qquad$$\\qquad$return out<br>\n","$\\qquad$def backward(self, dout):<br>\n","$\\qquad$$\\qquad$if dout.ndim == 4:   <br>\n","$\\qquad$$\\qquad$$\\qquad$N, C, H, W = dout.shape<br>\n","$\\qquad$$\\qquad$$\\qquad$dout = dout.transpose(0, 2, 3, 1) <font color=\"silver\"> # NHWCに入れ替え<br></font>\n","$\\qquad$$\\qquad$$\\qquad$dout = dout.reshape(N * H * W, C)  <font color=\"silver\"> # (N * H * W,C)の2次元配列に変換<br></font>\n","$\\qquad$$\\qquad$$\\qquad$dx = self. __ backward(dout)<br>\n","$\\qquad$$\\qquad$$\\qquad$dx = dx.reshape(N, H, W, C) <font color=\"silver\"> # 4次元配列に変換<br></font>\n","$\\qquad$$\\qquad$$\\qquad$dx = dx.transpose(0, 3, 1, 2) <font color=\"silver\"> # 軸をNCHWに入れ替え<br></font>\n","$\\qquad$$\\qquad$elif dout.ndim == 2:<br>\n","$\\qquad$$\\qquad$$\\qquad$dx = self. __ backward(dout)<br>\n","$\\qquad$$\\qquad$return dx<br>\n","$\\qquad$def __backward(self, dout):<br>\n","$\\qquad$$\\qquad$N, D = self.x_mu.shape<br>\n","$\\qquad$$\\qquad$dbeta = np.sum(dout, axis=0) <font color=\"silver\"> # (D, )<br> </font>\n","$\\qquad$$\\qquad$dgamma = np.sum(self.x_std * dout, axis=0)  # (D, )<br></font>\n","$\\qquad$$\\qquad$dx_std = self.gamma * dout <font color=\"silver\"> # (N, D)<br></font>\n","$\\qquad$$\\qquad$a2 = dx_std / self.std <font color=\"silver\"> # Xmuの勾配(1つ目)<br></font>\n","$\\qquad$$\\qquad$a3 = dx_std * self.x_mu <font color=\"silver\"> # 標準偏差の逆数の勾配<br></font>\n","$\\qquad$$\\qquad$a3 = np.sum(a3, axis=0) <font color=\"silver\"> # Nの方向に合計<br></font>\n","$\\qquad$$\\qquad$a4 = -(a3) / (self.std * self.std) <font color=\"silver\"> # 標準偏差の勾配   <br></font>\n","$\\qquad$$\\qquad$a5 = 0.5 * a4 / self.std <font color=\"silver\"> # 分散の勾配<br></font>\n","$\\qquad$$\\qquad$a6 = a5 / self.batch_size <font color=\"silver\"> # Xmuの2乗の勾配<br></font>\n","$\\qquad$$\\qquad$a6 = np.broadcast_to(a6, (N, D)) <font color=\"silver\"> # Nの方向にブロードキャスト<br></font>\n","$\\qquad$$\\qquad$a7 = 2.0  * self.x_mu * a6 <font color=\"silver\"> # Xmuの勾配(2つ目)<br></font>\n","$\\qquad$$\\qquad$a8 = -(a2+a7) <font color=\"silver\"> # muの勾配<br></font>\n","$\\qquad$$\\qquad$a8 = np.sum(a8, axis=0) <font color=\"silver\"> # Nの方向に合計<br></font>\n","$\\qquad$$\\qquad$a9 = a8 / self.batch_size <font color=\"silver\"> # Xの勾配<br></font>\n","$\\qquad$$\\qquad$a9 = np.broadcast_to(a9, (N, D)) <font color=\"silver\"> # Nの方向にブロードキャスト<br></font>\n","$\\qquad$$\\qquad$dx = a2 + a7 + a9<br>\n","$\\qquad$$\\qquad$self.dgamma = dgamma<br>\n","$\\qquad$$\\qquad$self.dbeta = dbeta<br>\n","$\\qquad$$\\qquad$return dx<br>"],"metadata":{"id":"opg5lnv1Fnw6"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│Attention [<font color=\"silver\">…</font>](https://colab.research.google.com/drive/1tqh8oCQAKO5MHZrigyFbRjOjkAgO3tO7) [<font color=\"silver\">…</font>](https://www.anarchive-beta.com/entry/2021/03/26/150000)</font>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/jun40vn/items/ac86f1992b7beefa1f0c)</font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F209705%2F1a019fc5-7cc8-5c24-f896-78c5ac20b478.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=7999c583133fcf245a0449025b3cbaa2\" width=\"480\"><br><br>\n","hr = h.reshape(N, 1, H).repeat(T, axis=1)<br>\n","t = hs × hr<br>\n","s = np.sum(t, axis=2)<br>\n","a = softmax.forward(s)<br>\n","ar = a.reshape(N, T, 1).repeat(H, axis=2)<br>\n","t = hs * ar<br>\n","c = np.sum(t, axis=1)<br>\n","<br>\n","c = np.sum(t, axis=1)<br>\n","<font color=\"red\">dt = dc.reshape(N, 1, H).repeat(T, axis=1)</font><br>\n","t = hs * ar<br>\n","<font color=\"red\">dar = dt * hs</font><br>\n","<font color=\"red\">dhs = dt * ar</font><br>\n","ar = a.reshape(N, T, 1).repeat(H, axis=2)<br>\n","<font color=\"red\">da = np.sum(dar, axis=2)</font><br>\n","a = softmax.forward(s)<br>\n","<font color=\"red\">ds = softmax.backward(da)</font><br>\n","s = np.sum(t, axis=2)<br>\n","<font color=\"red\">dt = ds.reshape(N, T, 1).repeat(H, axis=2)</font><br>\n","t = hs × hr<br>\n","<font color=\"red\">dhs = dt * hr</font><br>\n","<font color=\"red\">dhr = dt * hs</font><br>\n","hr = h.reshape(N, 1, H).repeat(T, axis=1)<br>\n","<font color=\"red\">dh = np.sum(dhr, axis=1)<br></font><br>\n","class AttentionWeight:<br>\n","$\\qquad$def __ init __ (self):<br>\n","$\\qquad$$\\qquad$self.params, self.grads = [], []<br>\n","$\\qquad$$\\qquad$self.softmax = Softmax()<br>\n","$\\qquad$$\\qquad$self.cache = None<br>\n","$\\qquad$def forward(self, hs, h):<br>\n","$\\qquad$$\\qquad$N, T, H = hs.shape<br>\n","$\\qquad$$\\qquad$hr = h.reshape(N, 1, H).repeat(T, axis=1)<font color=\"blue\"> repeat, axis=1</font><br>\n","$\\qquad$$\\qquad$t = hs * hr<br>\n","$\\qquad$$\\qquad$s = np.sum(t, axis=2)<font color=\"blue\"> np.sum, axis=2</font><br>\n","$\\qquad$$\\qquad$a = self.softmax.forward(s)<br>\n","$\\qquad$$\\qquad$self.cache = (hs, hr)<br>\n","$\\qquad$$\\qquad$return a<br>\n","$\\qquad$def backward(self, da):<br>\n","$\\qquad$$\\qquad$hs, hr = self.cache<br>\n","$\\qquad$$\\qquad$N, T, H = hs.shape<br>\n","$\\qquad$$\\qquad$ds = self.softmax.backward(da)<br>\n","$\\qquad$$\\qquad$dt = ds.reshape(N, T, 1).repeat(H, axis=2)<font color=\"blue\"> repeat, axis=2</font><br>\n","$\\qquad$$\\qquad$dhs = dt * hr<br>\n","$\\qquad$$\\qquad$dhr = dt * hs<br>\n","$\\qquad$$\\qquad$dh = np.sum(dhr, axis=1)<font color=\"blue\"> np.sum, axis=1</font><br>\n","$\\qquad$$\\qquad$return dhs, dh<br>class WeightSum:<br>\n","$\\qquad$def __ init __ (self):<br>\n","$\\qquad$$\\qquad$self.params, self.grads = [], []<br>\n","$\\qquad$$\\qquad$self.cache = None<br>\n","$\\qquad$def forward(self, hs, a):<br>\n","$\\qquad$$\\qquad$N, T, H = hs.shape<br>\n","$\\qquad$$\\qquad$ar = a.reshape(N, T, 1).repeat(H, axis=2)<font color=\"blue\"> repeat, axis=2</font><br>\n","$\\qquad$$\\qquad$t = hs * ar<br>\n","$\\qquad$$\\qquad$c = np.sum(t, axis=1)<font color=\"blue\"> np.sum, axis=1</font><br>\n","$\\qquad$$\\qquad$self.cache = (hs, ar)<br>\n","$\\qquad$$\\qquad$return c<br>\n","$\\qquad$def backward(self, dc):<br>\n","$\\qquad$$\\qquad$hs, ar = self.cache<br>\n","$\\qquad$$\\qquad$N, T, H = hs.shape<br>\n","$\\qquad$$\\qquad$dt = dc.reshape(N, 1, H).repeat(T, axis=1)<font color=\"blue\"> repeat, axis=1</font><br>\n","$\\qquad$$\\qquad$dar = dt * hs<br>\n","$\\qquad$$\\qquad$dhs = dt * ar<br>\n","$\\qquad$$\\qquad$da = np.sum(dar, axis=2)<font color=\"blue\"> np.sum, axis=2</font><br>\n","$\\qquad$$\\qquad$return dhs, da<br>\n","class Attention:<br>\n","$\\qquad$def __ init __ (self):<br>\n","$\\qquad$$\\qquad$self.params, self.grads = [], []<br>\n","$\\qquad$$\\qquad$self.attention_weight_layer = AttentionWeight()<br>\n","$\\qquad$$\\qquad$self.weight_sum_layer = WeightSum()<br>\n","$\\qquad$$\\qquad$self.attention_weight = None<br>\n","$\\qquad$def forward(self, hs, h):<br>\n","$\\qquad$$\\qquad$a = self.attention_weight_layer.forward(hs, h)<br>\n","$\\qquad$$\\qquad$out = self.weight_sum_layer.forward(hs, a)<br>\n","$\\qquad$$\\qquad$self.attention_weight = a<br>\n","$\\qquad$$\\qquad$return out<br>\n","$\\qquad$def backward(self, dout):<br>\n","$\\qquad$$\\qquad$dhs0, da = self.weight_sum_layer.backward(dout)<br>\n","$\\qquad$$\\qquad$dhs1, dh = self.attention_weight_layer.backward(da)<br>\n","$\\qquad$$\\qquad$dhs = dhs0 + dhs1<font color=\"blue\"> dhs0 + dhs1</font><br>\n","$\\qquad$$\\qquad$return dhs, dh<br>"],"metadata":{"id":"3LctiH_gGUGe"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│活性化関数</font>\n","x = np.array([-2, -1, 0, 1, 2, 3])<br>\n","mask = (x <= 0) <font color=\"silver\"> # array([ True,  True,  True, False, False, False])</font><br>\n","x[mask] = 0 <font color=\"silver\"> # array([0, 0, 0, 1, 2, 3])</font><br>\n","<font color=\"red\">dout = np.array([1, 1, 1, 1, 1, 1])<br>\n","dout[mask] = 0</font><font color=\"silver\"> # array([0, 0, 0, 1, 1, 1])</font><br><br>\n","out = 1 / (1 + np.exp(-x))<br>\n","<font color=\"red\">dx = dout * (1.0 - out) * out</font><br><br>\n","out = np.tanh(x)<br>\n","<font color=\"red\">dx = dout * (1.0 - out ** 2)</font><br><br>\n","x = np.exp(x) / np.sum(np.exp(x))<br>\n","<font color=\"red\">dx = out * dout</font><br>\n","<font color=\"red\">sumdx = np.sum(dx, axis=1, keepdims=True)</font><br>\n","<font color=\"red\">dx -= out * sumdx</font><br><br><font>\n","class ReLU:<br>\n","$\\qquad$def __ init __(self):<br>\n","$\\qquad$$\\qquad$self.mask = None<br>\n","$\\qquad$def forward(self, x):<br>\n","$\\qquad$$\\qquad$self.mask = (x <= 0)<br>\n","$\\qquad$$\\qquad$out = x.copy()<br>\n","$\\qquad$$\\qquad$out[self.mask] = 0<br>\n","$\\qquad$$\\qquad$return out<br>\n","$\\qquad$def backward(self, dout):<br>\n","$\\qquad$$\\qquad$dout[self.mask] = 0<br>\n","$\\qquad$$\\qquad$dx = dout<br>\n","$\\qquad$$\\qquad$return dx<br>\n","class LeakyReLU:<br>\n","$\\qquad$def __ init __(self, alpha=0.1):<br>\n","$\\qquad$$\\qquad$self.mask = None<br>\n","$\\qquad$$\\qquad$self.alpha = alpha<br>\n","$\\qquad$def forward(self, x):<br>\n","$\\qquad$$\\qquad$self.mask = (x <= 0)<br>\n","$\\qquad$$\\qquad$out = x.copy()<br>\n","$\\qquad$$\\qquad$out[self.mask] *= self.alpha<br>\n","$\\qquad$$\\qquad$return out<br>\n","$\\qquad$def backward(self, dout):<br>\n","$\\qquad$$\\qquad$dout[self.mask] *= self.alpha<br>\n","$\\qquad$$\\qquad$dx = dout<br>\n","$\\qquad$$\\qquad$return dx<br>\n","class Sigmoid:<br>\n","$\\qquad$def __ init __(self):<br>\n","$\\qquad$$\\qquad$self.params, self.grads = [], []<br>\n","$\\qquad$$\\qquad$self.out = None<br>\n","$\\qquad$def forward(self, x):<br>\n","$\\qquad$$\\qquad$out = 1 / (1 + np.exp(-x))<br>\n","$\\qquad$$\\qquad$self.out = out<br>\n","$\\qquad$$\\qquad$return out<br>\n","$\\qquad$def backward(self, dout):<br>\n","$\\qquad$$\\qquad$dx = dout * (1.0 - self.out) * self.out<br>\n","$\\qquad$$\\qquad$return dx<br>\n","<font color=\"silver\"># 黒本, ゼロつく2</font><br>\n","def softmax(x):<br>\n","$\\qquad$if x.ndim == 2:<br>\n","$\\qquad$$\\qquad$x = x - x.max(axis=1,keepdims=True) <font color=\"blue\">axis=1</font><br>\n","$\\qquad$$\\qquad$x = np.exp(x)<br>\n","$\\qquad$$\\qquad$x /= x.sum(axis=1,keepdims=True) <font color=\"blue\">axis=1</font><br>\n","$\\qquad$elif x.ndim == 1:<br>\n","$\\qquad$$\\qquad$x = x - np.max(x)<br>\n","$\\qquad$$\\qquad$x = np.exp(x) / np.sum(np.exp(x))<br>\n","$\\qquad$return x<br>\n","<font color=\"silver\"># skillupai</font><br>\n","def softmax(x):<br>\n","$\\qquad$if x.ndim == 2:<br>\n","$\\qquad$$\\qquad$x = x.T<br>\n","$\\qquad$$\\qquad$x = x - np.max(x, axis=0) <font color=\"blue\">axis=0</font><br>\n","$\\qquad$$\\qquad$y = np.exp(x) / np.sum(np.exp(x), axis=0) <font color=\"blue\">axis=0</font><br>\n","$\\qquad$$\\qquad$return y.T <br>\n","$\\qquad$x = x - np.max(x) <br>\n","$\\qquad$return np.exp(x) / np.sum(np.exp(x))<br>\n","class Softmax:<br>\n","$\\qquad$def __ init __(self):<br>\n","$\\qquad$$\\qquad$self.params, self.grads = [], []<br>\n","$\\qquad$$\\qquad$self.out = None<br>\n","$\\qquad$def forward(self, x):<br>\n","$\\qquad$$\\qquad$self.out = softmax(x)<br>\n","$\\qquad$$\\qquad$return self.out<br>\n","$\\qquad$def backward(self, dout):<br>\n","$\\qquad$$\\qquad$dx = self.out * dout<br>\n","$\\qquad$$\\qquad$sumdx = np.sum(dx, axis=1, keepdims=True) <font color=\"blue\">axis=1</font><br>\n","$\\qquad$$\\qquad$dx -= self.out * sumdx<br>\n","$\\qquad$$\\qquad$return dx<br>"],"metadata":{"id":"FWYupD5WpSno"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│Dropout</font>\n","torch.nn.Dropout(p=0.5, inplace=False)<br><br>\n","class Dropout:<br>\n","$\\quad$def __ init __(self, dropout_ratio=0.5):<br>\n","$\\quad$$\\quad$self.dropout_ratio = dropout_ratio<br>\n","$\\quad$$\\quad$self.mask = None<br>\n","$\\quad$def forward(self, x, train_flg=True):<br>\n","$\\quad$$\\quad$if train_flg: <font color=\"silver\"> # 0〜1の乱数で x.shape の行列を生成</font><br>\n","$\\quad$$\\quad$$\\quad$self.mask = np.random.rand(*x.shape) > self.dropout_ratio <font color=\"blue\">$~\\leftarrow\\ast$</font><br>\n","$\\quad$$\\quad$$\\quad$return x * self.mask<br>\n","$\\quad$$\\quad$else:<br>\n","$\\quad$$\\quad$$\\quad$return x * (1.0 - self.dropout_ratio) <font color=\"blue\">$~\\leftarrow\\ast$</font><br>\n","$\\quad$ def backward(self, dout):<br>\n","$\\quad$$\\quad$return dout * self.mask <font color=\"blue\">$~\\leftarrow\\ast$</font><br>"],"metadata":{"id":"6vtdIzlUkcdL"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│重みの初期値</font>\n","torch.nn.init.normal_(tensor, mean=0.0, std=1.0)<br>\n","torch.nn.init.xavier_normal_(tensor, gain=1.0)<br>\n","torch.nn.init.kaiming_normal_(tensor, a=0, mode=\"fan_in\", nonlinearity=\"leaky_relu\") <br><br>\n","Xavierの初期値</font><br>\n","sigmoid関数やtanh関数のように点対称で中央付近で線形関数としてみなせる活性化関数に向いている。<br><br>\n","$\\sqrt {\\dfrac {1}{n}},\\quad\\displaystyle \\sqrt \\frac{2}{n1+n2}$を標準偏差とするガウス分布<br><br>\n","n1：<font color=\"silver\">前の層のノード数,</font> n2：<font color=\"silver\">後ろの層のノード数</font><br><br>\n","Heの初期値</font><br>\n","Xavierより広がりを持った初期値<br><br>\n","<font color=\"Black\">$\\sqrt {\\dfrac {2}{n}},\\quad\\displaystyle \\sqrt \\frac{2}{n1}$を標準偏差とするガウス分布<br><br>\n","n1：<font color=\"silver\">前の層のノード数</font><br><br>\n","def init_weights(m: nn.Module):<br>\n","$\\qquad$for name, param in m.named_parameters():<br>\n","$\\qquad$$\\qquad$if 'weight' in name:<br>\n","$\\qquad$$\\qquad$$\\qquad$nn.init.normal_(param.data, mean=0, std=0.01)<br>\n","$\\qquad$$\\qquad$else:<br>\n","$\\qquad$$\\qquad$$\\qquad$nn.init.constant_(param.data, 0)<br>\n","model.apply(init_weights)<br>\n","<font color=\"silver\"># パラメータ初期化する関数</font><br>\n","def __ init_weight(self, weight_init_std):<br>\n","$\\qquad$all_size_list = [self.input_size] + self.hidden_size_list + [self.output_size]<br>\n","$\\qquad$for idx in range(1, len(all_size_list)):<br>\n","$\\qquad$$\\qquad$scale = weight_init_std<br>\n","$\\qquad$$\\qquad$if str(weight_init_std).lower() in ('relu', 'he'):<br>\n","$\\qquad$$\\qquad$$\\qquad$scale = np.sqrt(2.0 / all_size_list[idx - 1])<br>\n","$\\qquad$$\\qquad$elif str(weight_init_std).lower() in ('sigmoid', 'xavier'):<br>\n","$\\qquad$$\\qquad$$\\qquad$scale = np.sqrt(1.0 / all_size_list[idx - 1])<br>\n","$\\qquad$$\\qquad$self.params['W' + str(idx)] = scale * np.random.randn(all_size_list[idx-1], all_size_list[idx])<br>\n","$\\qquad$$\\qquad$self.params['b' + str(idx)] = np.zeros(all_size_list[idx])<br>"],"metadata":{"id":"IUJJXbPfxYL9"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│WeightDecay</font>\n","l2_loss = l2_loss + torch.norm(w) ** 2<br>\n","l1_loss = l1_loss + torch.norm(w, 1)<br><br>\n","$\\displaystyle L = L' + \\frac{1}{2} \\lambda \\sum_{l=1}^{layers} \\sum_{i, ~~j} (w_{ij}^{l})^2$<br>  \n","$\\displaystyle \\frac{\\partial L}{\\partial {\\bf W}_t} = \\frac{\\partial L'}{\\partial {\\bf W}_t} + \\lambda {\\bf W}_{t}$<br>  \n","$\\bf W$ :  <font color=\"silver\">重み行列  </font><br>$w_{i,j}^l$ :<font color=\"silver\"> $l$層目の重み行列${\\bf W}$の$i, j $成分<br></font>\n","$L$ :<font color=\"silver\"> 正則化項を加えた後の損失<br></font>\n","$L'$ : <font color=\"silver\">正則化項を加える前の損失 <br></font>\n","$layers$ :<font color=\"silver\"> 層番号<br></font>\n","$\\lambda$ :<font color=\"silver\"> 係数<br></font><br>\n","def loss(self, x, t):<br>\n","$\\qquad$y = self.predict(x)<br>\n","$\\qquad$lmd = self.weight_decay_lambda<br>\n","$\\qquad$weight_decay = 0<br>\n","$\\qquad$for idx in range(1, self.hidden_layer_num + 2):<br>\n","$\\qquad$$\\qquad$W = self.params['W' + str(idx)]<br>\n","$\\qquad$$\\qquad$weight_decay += 0.5 * lmd * np.sum(W**2) <font color=\"silver\"> # 全ての行列Wについて積算していく</font><br>\n","$\\qquad$return self.lastLayer.forward(y, t) + weight_decay <br>\n","def gradient(self, x, t):<br>\n","$\\qquad$self.loss(x, t)<br>\n","$\\qquad$dout = self.lastLayer.backward(dout=1) <br>\n","$\\qquad$layers = list(self.layers.values())<br>\n","$\\qquad$layers.reverse()<br>\n","$\\qquad$for layer in layers:<br>\n","$\\qquad$$\\qquad$dout = layer.backward(dout)<br>\n","$\\qquad$lmd = self.weight_decay_lambda<br>\n","$\\qquad$grads = {}<br>\n","$\\qquad$for idx in range(1, self.hidden_layer_num+2):<br>\n","$\\qquad$$\\qquad$grads['W' + str(idx)] = self.layers['Affine' + str(idx)].dW + lmd * self.layers['Affine' + str(idx)].W<br>\n","$\\qquad$$\\qquad$grads['b' + str(idx)] = self.layers['Affine' + str(idx)].db<br>\n","$\\qquad$return grads<br>\n","<br>\n","lam = 1e-3<br>\n","model_l2.train()  <font color=\"silver\"># モデルを学習モードに切り替え</font><br>\n","for epoch in range(1, epoch_num+1):<br>\n","$\\qquad$for image, label in train_loader:<br>\n","$\\qquad$$\\qquad$if use_cuda:<br>\n","$\\qquad$$\\qquad$$\\qquad$image = image.cuda()<br>\n","$\\qquad$$\\qquad$$\\qquad$label = label.cuda()<br>\n","$\\qquad$$\\qquad$y = model_l2(image)<br>\n","$\\qquad$$\\qquad$loss = criterion(y, label)<br>\n","$\\qquad$$\\qquad$l2_loss = torch.tensor(0., requires_grad=True)  <font color=\"silver\"># ノルムを格納する受け皿, 零テンソル, 勾配を更新する</font><br>\n","$\\qquad$$\\qquad$for w in model_l2.parameters():<br>\n","$\\qquad$$\\qquad$$\\qquad$l2_loss = l2_loss + torch.norm(w) ** 2<br>\n","$\\qquad$$\\qquad$loss = loss + lam * l2_loss<br>\n","$\\qquad$$\\qquad$model_l2.zero_grad()  <font color=\"silver\"># 勾配を0で初期化</font><br>\n","$\\qquad$$\\qquad$loss.backward()<br>\n","$\\qquad$$\\qquad$optimizer_l2.step()<br>\n","model_l2.eval()  <font color=\"silver\"># モデルを評価モードに切り替え</font><br>\n","with torch.no_grad():  <font color=\"silver\"># 勾配計算を行わない</font><br>\n","$\\qquad$for image, label in test_loader:<br>\n","$\\qquad$$\\qquad$if use_cuda:<br>\n","$\\qquad$$\\qquad$$\\qquad$image = image.cuda()<br>\n","$\\qquad$$\\qquad$$\\qquad$label = label.cuda()<br>\n","$\\qquad$$\\qquad$y = model_l2(image)<br>\n","$\\qquad$$\\qquad$pred = torch.argmax(y, dim=1)<br>"],"metadata":{"id":"LWyboWJMl5w7"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│勾配クリッピング</font>\n","torch.nn.utils.clip_grad_norm_(parameters, max_norm, norm_type=2.0, error_if_nonfinite=False)<br>\n","torch.nn.utils.clip_grad_norm_(model.parameters(), clip)<br><br> \n","勾配のL2ノルムがしきい値を超えた場合に、$g$ に$\\cfrac{v}{\\|g\\|}$を掛けて勾配を修正する。<br>\n","<br>\n","$if \\parallel{g}\\parallel > v:$<br><br>\n","$\\displaystyle g← \\frac{v}{\\|g\\|}g$<br><br>\n","$g$ ：<font color=\"silver\">すべてのパラメータに対する勾配をひとひとつにまとめたもの。</font><br><br>\n","$\\rm -threshold < \\parallel gradient \\parallel < threshold$<br><br>\n","$\\displaystyle\\|g\\|= \\sqrt{ \\Bigl(\\frac{\\partial L}{\\partial \\mathbf{W}_1}\\Bigr)^2  + \\Bigl(\\frac{\\partial L}{\\partial \\mathbf{W}_2}\\Bigr)^2}$<br><br>\n","def clip_grads(grads, max_norm):<br>\n","$\\quad$total_norm = 0<br>\n","$\\quad$for key, grad in grads.items():<br>\n","$\\quad$$\\quad$total_norm += np.sum(grad ** 2, axis=None)<br>\n","$\\quad$total_norm = np.sqrt(total_norm)<br>\n","$\\quad$rate = max_norm / (total_norm + 1e-6)<br>\n","$\\quad$if rate < 1:<br>\n","$\\quad$$\\quad$for key, grad in grads.items():<br>\n","$\\quad$$\\quad$$\\quad$grads[key] *= rate<br>\n","def gradient_clipping(grad, threshold):<br>\n","$\\quad$norm = np.linalg.norm(grad)<br>\n","$\\quad$rate = threshold / norm<br>\n","$\\quad$if rate < 1:<br>\n","$\\quad$$\\quad$return grad * rate<br>\n","$\\quad$return grad<br>\n","<font color=\"silver\"># returnを指定しない関数のため値を返さず、引数に渡したgradsの値を直接更新する</font><br><br>\n","model.train()  <font color=\"silver\"># モデルを学習モードに変更</font><br>\n","for src, trg in train_dataloader:<br>\n","$\\qquad$src = src.to(device)<br>\n","$\\qquad$trg = trg.to(device)<br>\n","$\\qquad$output = model(src, trg)  <font color=\"silver\"># 教師強制 オン</font><br>\n","$\\qquad$output = output[1:].view(-1, output.shape[-1])  <font color=\"silver\"># 出力単語のIDを取り出す</font><br>\n","$\\qquad$trg = trg[1:].view(-1)<br>\n","$\\qquad$loss = criterion(output, trg)<br>\n","$\\qquad$optimizer.zero_grad()  <font color=\"silver\"># 勾配を0で初期化</font><br>\n","$\\qquad$loss.backward()<br>\n","$\\qquad$torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  <font color=\"silver\"># 勾配クリッピング</font><br>\n","$\\qquad$optimizer.step()<br>"],"metadata":{"id":"SVpjQaLvII81"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│torch.utils</font>\n","<font color=\"Blue\">$\\tiny{\\rm Link}$ [<font color=\"Blue\">…</font>](https://qiita.com/takurooo/items/e4c91c5d78059f92e76d)</font><br><br>\n","class MyDataset(torch.utils.data.Dataset):<br>\n","$\\quad$def __ init __ (self, data_num, transform=None):<br>\n","$\\quad$$\\quad$self.transform = transform<br>\n","$\\quad$$\\quad$self.data_num = data_num<br>\n","$\\quad$$\\quad$self.data = []<br>\n","$\\quad$$\\quad$self.label = []<br>\n","$\\quad$$\\quad$for x in range(self.data_num):<br>\n","$\\quad$$\\quad$$\\quad$self.data.append(x) <font color=\"silver\"># 0 から (data_num-1) までのリスト<br></font>\n","$\\quad$$\\quad$$\\quad$self.label.append(x%2 == 0) <font color=\"silver\"># 偶数ならTrue 奇数ならFalse<br></font>\n","$\\quad$def __ len __ (self):<br>\n","$\\quad$$\\quad$return self.data_num<br>\n","$\\quad$def __ getitem __ (self, idx):<br>\n","$\\quad$$\\quad$out_data = self.data[idx]<br>\n","$\\quad$$\\quad$out_label =  self.label[idx]<br>\n","$\\quad$$\\quad$if self.transform:<br>\n","$\\quad$$\\quad$$\\quad$out_data = self.transform(out_data)<br>\n","$\\quad$$\\quad$return out_data, out_label<br><br>\n","torch.utils.data.DataLoader(<br>\n","$\\qquad$dataset, <br>\n","$\\qquad$batch_size=1, <br>\n","$\\qquad$shuffle=False,  <font color=\"silver\"># シャッフルするかどうか</font><br>\n","$\\qquad$sampler=None,<br>\n","$\\qquad$batch_sampler=None, <br>\n","$\\qquad$num_workers=0, <font color=\"silver\"># 並列実行数</font><br>\n","$\\qquad$collate_fn=None,  <font color=\"silver\"># ミニバッチ作成前に使用されるコールバック関数</font><br>\n","$\\qquad$pin_memory=False, <br>\n","$\\qquad$drop_last=False,  <font color=\"silver\"># 最後の余りのミニバッチは切り捨てるかどうか</font><br>\n","$\\qquad$timeout=0,   <font color=\"silver\"># ミニバッチを作成する時間制限</font><br>\n","$\\qquad$worker_init_fn=None  <font color=\"silver\"># ミニバッチ作成前に呼ばれるコールバック関数</font><br>\n","$\\qquad$)<br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/mathlive/items/8e1f9a8467fff8dfd03c)</font><br></font>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F499474%2F2a9a8306-c84d-c941-9d4e-52e60e2a1b0f.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=b817dd1a22b570e0991103a0f062a008\" width=\"480\"><br>\n"],"metadata":{"id":"S7HZpYMXsO5K"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│torch.nn</font><br>\n","torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)<br>\n","torch.nn.LayerNorm(normalized_shape, eps=1e-05, elementwise_affine=True, device=None, dtype=None)<br>\n","torch.nn.InstanceNorm2d(num_features, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None)<br>\n","torch.nn.GroupNorm(num_groups, num_channels, eps=1e-05, affine=True, device=None, dtype=None)<br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://cvml-expertguide.net/terms/dl/layers/convolution-layer/grouped-convolution/)</font></font><br>\n","<img src=\"https://i0.wp.com/cvml-expertguide.net/wp-content/uploads/2022/05/ac755532ff53c6fe84815b4b0bf83ac0.png?resize=1024%2C615&ssl=1\" width=\"320\"><br>\n","[<font color=\"silver\">$\\tiny{…}$</font>](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)<br>\n","torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, …)<br>\n","Shape：input$\\rm (N, C_{in}, H_{in}, W_{in})$<br>\n","Shape：output$\\rm (N, C_{out}, H_{out}, W_{out})$<br>\n","Variables：weight$\\rm (out_{channels}, in_{channels}/groups, kernel[0],kernel[1])$<br>\n","Variables：bias$\\rm (out_{channels})$<br>\n","[<font color=\"silver\">$\\tiny{…}$</font>](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)<br>\n","torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1,…)<br>\n","Shape：input$\\rm (N, C_{in}, H_{in}, W_{in})$<br>\n","Shape：output$\\rm (N, C_{out}, H_{out}, W_{out})$<br>\n","Variables：weight$\\rm (out_{channels}, in_{channels}/groups, kernel[0],kernel[1])$<br>\n","Variables：bias$\\rm (out_{channels})$<br>\n","[<font color=\"silver\">$\\tiny{…}$</font>](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d)<br>\n","torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)<br>\n","Shape：input$\\rm (N, C_{in}, H_{in}, W_{in})$<br>\n","Shape：output$\\rm (N, C_{out}, H_{out}, W_{out})$<br>\n","[<font color=\"silver\">$\\tiny{…}$</font>](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)<br>\n","torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)<br>\n","Shape：input$\\rm (N, in_{features})$<br>\n","Shape：output$\\rm (N, out_{features})$<br>\n","Variables：weight$\\rm (out_{features}, in_{features})$<br>\n","Variables：bias$\\rm (out_{features})$<br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/jun40vn/items/35f6f0d26f9e58f01e4e)</font><br>\n","<img src=\"https://camo.qiitausercontent.com/32654fed87f53f2b82b773d50c36e94a97f9bec0/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3230393730352f31363033633765302d653532392d346237632d653936312d3039396561653661663433632e706e67\" width=\"400\">\n","<img src=\"https://camo.qiitausercontent.com/3d6925879a4d36d8cd7562a9adf75d76f43f281e/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3230393730352f65363761373333612d623134662d373232362d646262382d3061393135396663396434312e706e67\" width=\"480\"><br>\n","[<font color=\"silver\">$\\tiny{…}$</font>](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)<br>\n","torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None, device=None, dtype=None)<br>\n","Shape：input$\\rm (N,)$, (T, N) <font color=\"silver\"> # (sequence length, batch size) </font><br>\n","Shape：output$\\rm (N, embedding_{dim})$, (T, N, D) <font color=\"silver\"> # (sequence length, batch size, embedding_dim) </font><br>\n","Variables：weight$\\rm (num_{embeddings}, embedding_{dim})$, (V, D) <font color=\"silver\"> # (num_embeddings, embedding_dim) </font><br>\n","[<font color=\"silver\">$\\tiny{…}$</font>](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN)<br>\n","torch.nn.RNN(*args, **kwargs)<br>\n","input_size <font color=\"silver\">各時刻における入力ベクトルのサイズ<br></font>\n","hidden_size <font color=\"silver\">隠れ層ベクトルのサイズ<br></font>\n","num_layers = 1<br></font>\n","nonlinearity = 'tanh'<br></font>\n","bias = True<br></font>\n","batch_first = False <font color=\"silver\">テンソルのTNDをNTDで入力する<br></font>\n","dropout = 0<br></font>\n","bidirectional = False<br></font><br>\n","Shape：input$\\rm (L, N, H_{in})$ (T, N, D) <font color=\"silver\"> # (sequence length, batch size, embedding_dim) </font><br>\n","Shape：h_0$\\rm (num_{layers}, N, H_{out})$ <font color=\"silver\"> # (num_layers, batch size, hidden_size) </font><br>\n","Shape：h_n$\\rm (num_{layers}, N, H_{out})$ <font color=\"silver\"> # (num_layers, batch size, hidden_size) </font><br>\n","Shape：output$\\rm (L, N, H_{out})$ (T, N, H) <font color=\"silver\"> # (sequence length, batch size, hidden_size) </font><br>\n","<br>\n","Shape：input$\\rm (L, N, H_{in})$ (T, N, D) <font color=\"silver\"> # (sequence length, batch size, embedding_dim) </font><br>\n","Shape：h_0$\\rm (2×num_{layers}, N, H_{out})$ (Bidirectional×num_layers, N, H) <font color=\"silver\"> # (Bidirectional×num_layers, batch size, hidden_size) </font><br>\n","Shape：h_n$\\rm (2×num_{layers}, N, H_{out})$ (Bidirectional×num_layers, N, H) <font color=\"silver\"> # (Bidirectional×num_layers, batch size, hidden_size) </font><br>\n","Shape：output$\\rm (L, N, 2×H_{out})$ (T, N, Bidirectional×H) <font color=\"silver\"> # (sequence length, batch size, 2×hidden_size) </font><br><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F209705%2F19b35dea-8cc6-35f1-da5f-9849395053c3.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=3de1c04d0aca2bc134b64bff46c63d40\" width=\"400\"><br>"],"metadata":{"id":"9bGvHJxV_lzZ"}},{"cell_type":"markdown","source":["# <font color=\"silver\">実装│torch.nn</font><br>\n"," - BatchNorm</font><br>\n","- torch.nn.BatchNorm2d(<br>\n","$\\qquad$num_features, <br>\n","$\\qquad$eps=1e-05, <br>\n","$\\qquad$momentum=0.1, <br>\n","$\\qquad$affine=True, <br>\n","$\\qquad$track_running_stats=True, <br>\n","$\\qquad$device=None, <br>\n","$\\qquad$dtype=None<br>\n","$\\qquad$)\n"," - LayerNorm</font><br>\n","- torch.nn.LayerNorm(<br>\n","$\\qquad$normalized_shape, <br>\n","$\\qquad$eps=1e-05, <br>\n","$\\qquad$elementwise_affine=True, <br>\n","$\\qquad$device=None, <br>\n","$\\qquad$dtype=None<br>\n","$\\qquad$)<br>\n"," - InstanceNorm</font><br>\n","- torch.nn.InstanceNorm2d(<br>\n","$\\qquad$num_features, <br>\n","$\\qquad$eps=1e-05, <br>\n","$\\qquad$momentum=0.1, <br>\n","$\\qquad$affine=False, <br>\n","$\\qquad$track_running_stats=False, <br>\n","$\\qquad$device=None, <br>\n","$\\qquad$dtype=None<br>\n","$\\qquad$)<br>\n"," - GroupNorm</font><br>\n","- torch.nn.GroupNorm(<br>\n","$\\qquad$num_groups, <br>\n","$\\qquad$num_channels, <br>\n","$\\qquad$eps=1e-05, <br>\n","$\\qquad$affine=True, <br>\n","$\\qquad$device=None, <br>\n","$\\qquad$dtype=None<br>\n","$\\qquad$)\n"," - Conv2d [<font color=\"silver\">$\\tiny{\\rm pytorch.org}…$</font>](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)<br>\n","- torch.nn.Conv2d(<br>\n","$\\qquad$in_channels, <br>\n","$\\qquad$out_channels, <br>\n","$\\qquad$kernel_size, <br>\n","$\\qquad$stride=1, <br>\n","$\\qquad$padding=0, <br>\n","$\\qquad$dilation=1, <br>\n","$\\qquad$groups=1, <br>\n","$\\qquad$bias=True, <br>\n","$\\qquad$padding_mode='zeros', <br>\n","$\\qquad$device=None, <br>\n","$\\qquad$dtype=None<br>\n","$\\qquad$)<br>\n"," - ConvTranspose2d<br>\n","- torch.nn.ConvTranspose2d(<br>\n","$\\qquad$in_channels, <br>\n","$\\qquad$out_channels, <br>\n","$\\qquad$kernel_size, <br>\n","$\\qquad$stride=1, <br>\n","$\\qquad$padding=0, <br>\n","$\\qquad$output_padding=0, <br>\n","$\\qquad$groups=1, <br>\n","$\\qquad$bias=True, <br>\n","$\\qquad$dilation=1, <br>\n","$\\qquad$padding_mode='zeros', <br>\n","$\\qquad$device=None, <br>\n","$\\qquad$dtype=None<br>\n","$\\qquad$)<br>\n"," - MaxPool2d<br>\n","- torch.nn.MaxPool2d(<br>\n","$\\qquad$kernel_size, <br>\n","$\\qquad$stride=None, <br>\n","$\\qquad$padding=0, <br>\n","$\\qquad$dilation=1, <br>\n","$\\qquad$return_indices=False, <br>\n","$\\qquad$ceil_mode=False<br>\n","$\\qquad$)<br>\n"," - Linear<br>\n","- torch.nn.Linear(<br>\n","$\\qquad$in_features, <br>\n","$\\qquad$out_features, <br>\n","$\\qquad$bias=True, <br>\n","$\\qquad$device=None, <br>\n","$\\qquad$dtype=None<br>\n","$\\qquad$)<br>\n"," - Embedding, [<font color=\"silver\">$\\tiny{\\rm pytorch.org}…$</font>](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) <br>\n","- torch.nn.Embedding(<br>\n","$\\qquad$num_embeddings, <br>\n","$\\qquad$embedding_dim, <br>\n","$\\qquad$padding_idx=None, <br>\n","$\\qquad$max_norm=None, <br>\n","$\\qquad$norm_type=2.0, <br>\n","$\\qquad$scale_grad_by_freq=False, <br>\n","$\\qquad$sparse=False, <br>\n","$\\qquad$_weight=None, <br>\n","$\\qquad$device=None, <br>\n","$\\qquad$dtype=None<br>\n","$\\qquad$)<br>\n"," - RNN, [<font color=\"silver\">$\\tiny{\\rm pytorch.org}…$</font>](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN) <br>\n","- <font color=\"black\">torch.nn.RNN(*args, kwargs)<br>\n","<font color=\"black\">$\\qquad$input_size <font color=\"silver\">各時刻における入力ベクトルのサイズ<br>\n","<font color=\"black\">$\\qquad$hidden_size <font color=\"silver\">隠れ層ベクトルのサイズ<br>\n","<font color=\"black\">$\\qquad$num_layers = 1<br>\n","<font color=\"black\">$\\qquad$nonlinearity = 'tanh'<br>\n","<font color=\"black\">$\\qquad$bias = True<br>\n","<font color=\"black\">$\\qquad$batch_first = False <font color=\"silver\">テンソルのTNDをNTDで入力する<br>\n","<font color=\"black\">$\\qquad$dropout = 0<br>\n","<font color=\"black\">$\\qquad$bidirectional = False<br>\n"," - LSTM, [<font color=\"silver\">$\\tiny{\\rm pytorch.org}…$</font>](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM) <br>\n","- torch.nn.LSTM(*args, kwargs)<br>\n","<font color=\"black\">$\\qquad$input_size <font color=\"silver\">各時刻における入力ベクトルのサイズ<br>\n","<font color=\"black\">$\\qquad$hidden_size <font color=\"silver\">隠れ層ベクトルのサイズ<br>\n","<font color=\"black\">$\\qquad$num_layers = 1<br>\n","<font color=\"black\">$\\qquad$bias = True<br>\n","<font color=\"black\">$\\qquad$batch_first = False <font color=\"silver\">テンソルのTNDをNTDで入力する<br>\n","<font color=\"black\">$\\qquad$dropout = 0<br>\n","<font color=\"black\">$\\qquad$bidirectional = False<br>\n","<font color=\"black\">$\\qquad$proj_size = 0<br>"],"metadata":{"id":"_0KuQpIkVQQK"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SVM [<font color=\"silver\">…</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!5770&cid=b0f01606242a6ed3&CT=1670918614524&OR=ItemsView)</font>"],"metadata":{"id":"iHVqYV5vgmaT"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SVM│SVM</font>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://laid-back-scientist.com/soft-svm-theory)</font><br>\n","<img src=\"https://laid-back-scientist.com/wp-content/uploads/2022/05/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88-2022-05-04-14.48.47-768x451.jpg\" width=\"480\"><br><br>\n","> - 推論<br>\n"," - $ \\hat{y} = \\text{sgn}(\\pmb{w}^\\top\\pmb{x} + b)\n","= \n","\\begin{cases} \n"," 1,  & \\pmb{w}^\\top\\pmb{x} + b \\geqq 0 \\\\ \n"," -1, & \\pmb{w}^\\top\\pmb{x} + b< 0 \n","\\end{cases}$\n","<br><br>\n","$ \\mathcal{D} = \\left\\{({\\pmb x_i}, y_i , y_i \\in \\{ -1, 1 \\}\\right\\}_{i=1}^{N}$<br><br>\n","> - 目的関数と制約条件<br>\n"," - 境界線$\\,\\pmb{w}^\\top\\pmb{x}_i+b\\,$とサポートベクタ$\\,\\,\\pmb{x}^*\\,$とのマージン$\\,d\\,$が最大となる$\\,\\pmb{w}^*, b^* \\,$を求める<br>\n"," - 境界に最も近いデータ点と境界の距離が、なるべく離れるようにしたいというモチベーション<br><br>\n","$ \\begin{align} \n","\\pmb{w}^*, b^* &=\\mathop{\\rm argmax}\\limits_{\\pmb{w},b}d+C\\displaystyle\\sum_{i=1}^{n}ξ_i =\\mathop{\\rm argmax}\\limits_{\\pmb{w},b}\\cfrac{|\\pmb{w}^\\top\\pmb{x}^*+b|}{\\|\\pmb{w}\\|} +C\\displaystyle\\sum_{i=1}^{n}ξ_i\n","\\end{align}$\n","<br><br>\n","$\\begin{cases}\n","\\pmb{w}^\\top\\pmb{x}^*+b \\ge +1, \\quad y_i = +1の場合\\\\\n","\\pmb{w}^\\top\\pmb{x}^*+b \\le -1, \\quad y_i = -1の場合\\\\\n","\\end{cases}$\n","<br><br>\n","$y_i(\\pmb{w}^\\top\\pmb{x}^*+b)-1 \\ge 0, \\quad i \\in \\{1...n\\}$\n","<br><br>\n","$y_i(\\pmb{w}^\\top\\pmb{x}^*+b) - 1 + \\xi_i \\ge 0 $<br><br>\n"," - 主問題<br><br>\n","$\\pmb{w}^*, b^*, \\pmb{\\xi} ^* = \\displaystyle\\mathop{\\rm argmin} _{\\pmb{w},b,\\pmb{\\xi} }\\frac{1}{2}{{\\|\\pmb{w}\\|}^2+C\\displaystyle\\sum_{i=1}^{n}ξ_i  }$\n","<br><br>\n","$\\mbox{ s.t. } y_i(\\pmb{w^{\\top}x_i}+b) \\geq 1-ξ_i, \\quad ξ_i \\geq 0, \\quad i \\in \\{1...n\\}$<br><br>\n","> - SVMの課題<br><br>"],"metadata":{"id":"KuluRGc7eMnD"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SVM│スラック変数</font>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://watlab-blog.com/2019/12/22/svm/)</font><br>\n","<img src=\"https://watlab-blog.com/wp-content/uploads/2019/12/Regularization-parameter.png\" width=\"320\">\n","<br><br>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://qiita.com/c60evaporator/items/8864f7c1384a3c6e9bd9)</font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F610167%2Fbf06348a-15e8-1326-8165-920864deadc7.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=d0b811826e6789435d7fd67ddad609f4\" width=\"480\"><br><br>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://svm.michalhaltuf.cz/support-vector-machines/)</font><br>\n","<img src=\"https://svm.michalhaltuf.cz/wp-content/uploads/2017/10/slack.png\" width=\"480\"><br><br>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://www.xiaowenying.com/machine-learning/2019/11/18/svm.html)</font><br>\n","<img src=\"https://www.xiaowenying.com/assets/post_img/svm/7824BB24CA8355AFBD5B9BF42521096D.jpg\" width=\"320\"><br><br>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://qiita.com/ironball/items/6acb3546312f4c65ec54)</font></font><br>\n","<img src=\"https://camo.qiitausercontent.com/4b2a8b68fcf74c56350ef368cdbc7b5e4ef73f2e/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3438383537372f35333564336439302d343035302d313862392d316263372d3465373066346666623233322e706e67\" width=\"480\">\n","<br><br>"],"metadata":{"id":"H55FScyeOz3a"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SVM│カーネルトリック</font>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://qiita.com/c60evaporator/items/8864f7c1384a3c6e9bd9)</font><br></font>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F610167%2F4c2abed8-fe74-4d98-1d38-19da4e1619ca.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=2d6889c770dfc55d02303507aa4ee2f0\" width=\"560\"><br><br>\n"," - 線形カーネル<br><br>\n","$K(\\pmb X_i,\\pmb X_j)= x_1^{\\mathsf{T}}x_2$<br><br>\n"," - 多項式カーネル<br><br>\n","$K(\\pmb X_i,\\pmb X_j)= \\left(a + \\pmb{X}_{i}^\\top\\pmb{X}_{j}\\right)^{b}$<br><br>\n"," - RBFカーネル<br><br>\n","$K(\\pmb X_i,\\pmb X_j) = \\exp\\left( - \\cfrac{||\\pmb{X}_{i} – \\pmb{X}_{j} || ^{2}}{2\\sigma^{2}} \\right)$<br><br>\n"," - シグモイドカーネル<br><br>\n",">$K(\\pmb X_i,\\pmb X_j)= \\tanh \\left( a\\pmb{X\n","}_{i}^\\top\\pmb{X}_{j} + b \\right)$"],"metadata":{"id":"-CPrFpsl9YVP"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SVM│主問題と双対問題</font>\n","> - 主問題<br><br>\n",">$\\pmb{w}^*, b^*, \\pmb{\\xi} ^* = \\displaystyle\\mathop{\\rm argmin} _{\\pmb{w},b,\\pmb{\\xi} }\\frac{1}{2}{{\\|\\pmb{w}\\|}^2+C\\displaystyle\\sum_{i=1}^{n}ξ_i  }$\n","<br><br>\n","$\\mbox{ s.t. } y_i(\\pmb{w^{\\top}x_i}+b) \\geq 1-ξ_i, \\quad ξ_i \\geq 0, \\quad i \\in \\{1...n\\}$\n","<br><br>\n","> - 双対問題（ラグランジュ関数＋KKT条件）<br><br>\n","$\\pmb{\\alpha}^* =\\mathop{\\rm argmin}\\limits_{\\pmb{\\alpha}} \\displaystyle\\sum_{i=1}^{n} \\alpha_i - \\frac{1}{2} \\displaystyle\\sum_{i=1}^{n}\\sum_{j=1}^{n} \\alpha_i \\alpha_j y_i y_j \\pmb X_i^\\top \\pmb X_j $<br><br>\n","$\\mbox{ s.t. } \\displaystyle\\sum_{i=1}^{n} \\alpha_i y_i = 0 , \\quad C \\geq \\alpha_i \\geq 0 , \\quad i \\in \\{1...n\\}$<br><br>\n","> - カーネルトリック<br><br>\n",">$\\pmb{\\alpha}^* =\\mathop{\\rm argmin}\\limits_{\\pmb{\\alpha}} \\displaystyle\\sum_{i=1}^{n} \\alpha_i - \\frac{1}{2} \\displaystyle\\sum_{i=1}^{n}\\sum_{j=1}^{n} \\alpha_i \\alpha_j y_i y_j K(\\pmb X_i,\\pmb X_j)$<br><br>\n",">$\\mbox{ s.t. } \\displaystyle\\sum_{i=1}^{n} \\alpha_i y_i = 0 ,\\quad C \\geq \\alpha_i \\geq 0 \\quad i \\in \\{1...n\\}$<br><br>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://cochineal19.hatenablog.com/entry/2021/05/20/193516)</font><br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/c/cochineal19/20210520/20210520021551.png\" width=\"800\"></font><br><br>\n","> - ラグランジュ関数<br><br>\n","$ \\begin{align} \n","\\rm{minimize} \\quad &f(x)\\\\\n","\\rm{subject~to} \\quad &g_i(x) \\leqq 0, \\quad  i=1, \\ldots, k,\\\\\n","&h_i(x) =0, \\quad  i=1, \\ldots, m, \n","\\end{align}$<br><br>\n","> - KKT条件<br><br></font>\n",">$ \\nabla_{x}\\mathcal{L}(x, \\alpha, \\beta)=0$\n","<br><br>\n","$ \\nabla_{\\alpha}\\mathcal{L}(x, \\alpha, \\beta)=0$\n","<br><br>\n","$ \\alpha_ig_i(x)=0,\\quad i=1,\\ldots,k,$\n","<br><br>\n","$ g_i(x)\\leqq 0,\\quad i=1,\\ldots,k,$\n","<br><br>\n","$ \\alpha_i\\geqq 0,\\quad i=1,\\ldots,k, $"],"metadata":{"id":"vO9f-N4Fe3sx"}},{"cell_type":"markdown","source":["# <font color=\"silver\">近傍法 [<font color=\"silver\">…</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!5781&cid=b0f01606242a6ed3&CT=1670937149587&OR=ItemsView)</font>\n"],"metadata":{"id":"BuUfXlLUtYDV"}},{"cell_type":"markdown","source":["# <font color=\"silver\">近傍法│近傍法</font>\n","> - <font color=\"silver\">Description</font><br>\n"," - <font color=\"Blue\">KNN</font>\n","   - K-Nearest Neighbors<br>\n","   - 次元の呪いに弱い<br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://www.jeremyjordan.me/k-nearest-neighbors/)</font></font><br> \n","<img src=\"https://www.jeremyjordan.me/content/images/2017/06/Screen-Shot-2017-06-17-at-5.39.17-PM.png\" width=\"640\"><br><br>\n","<img src=\"https://www.jeremyjordan.me/content/images/2017/06/Screen-Shot-2017-06-17-at-9.30.39-AM-1.png\" width=\"640\"><br><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F40159%2F1183d3a7-f34c-8be2-065d-13862c2b8143.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=2a6b067c4a266f191f8c2aaf0f60deab\" width=\"240\"><br><br>\n"," - <font color=\"Blue\">KNNとkの数</font><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://ml-explained.com/blog/k-nearest-neighbors-explained)</font></font><br> \n","<img src=\"https://ml-explained.com/articles/k-nearest-neighbors-explained/effect_of_k.png\" width=\"640\"><br><br>\n"],"metadata":{"id":"JzmYXVd75SwM"}},{"cell_type":"markdown","source":["# <font color=\"silver\">決定木"],"metadata":{"id":"j2wQjSDImnB1"}},{"cell_type":"markdown","source":["# <font color=\"silver\">決定木│推定</font>\n","><font color=\"Black\">※ 情報利得が最大になる＝子ノードの不純度が最小になるように分割する\n","<br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://qiita.com/y_itoh/items/943fd69057aa6148f44d)</font><br>\n","<img src=\"https://camo.qiitausercontent.com/94c03e87716d8ba4ecdd32ec2e34691b3eecc739/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3530323130392f66613031323033352d643261382d323830632d306439362d3332653132306633303562372e706e67\" width=\"640\">\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://darden.hatenablog.com/entry/2016/12/09/221630)</font><br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/d/darden/20161212/20161212200144.png\" width=\"640\">\n","\n","\n","\n"],"metadata":{"id":"rEqpNQCm2bwU"}},{"cell_type":"markdown","source":["# <font color=\"silver\">決定木│情報利得</font>\n",">※ ある変数を使ってデータを分割したとき、分割の前後でどれだけ不純度$ I(D_{p})$が減少したかを表す。<br>\n","※ 分類では完全に分類できれば、不純度はゼロとなる。<br>\n","※ 回帰では1つのノードに対応するデータの分散がゼロであれば、不純度はゼロとなる。\n","<br><br>\n","$\\displaystyle IG(D_p,f) = I_G(D_p) - \\frac{N_{left}}{N_p} I_G(D_{left}) - \\frac{N_{right}}{N_p} I_G(D_{right})$\n","<br><br>\n","$N_p$：<font color=\"silver\">親ノードのサンプルサイズ<br></font>\n","$N_{left},\\;N_{right}$：<font color=\"silver\">子ノード内のトサンプルサイズ<br></font>\n","$f$：<font color=\"silver\">分割する特徴量<br></font>\n","$ I(D_{p})$：<font color=\"silver\">不純度はデータがどれだけばらついているかを表す指標</font>\n","\n"],"metadata":{"id":"Tmflw9mF2bjY"}},{"cell_type":"markdown","source":["# <font color=\"silver\">決定木│ジニ不純度</font>\n",">$I_G(t) = 1 - \\displaystyle\\sum_{i=1}^c {p(i|t)}^2$\n","<br><br>\n","ノード$t$のサンプルサイズ$n$個<br>\n","クラス数$c$個<br>\n","ノード$t$のクラス$i$のサンプルサイズが$n_i$個<br>\n","$n_i$の割合を、$p(i|t) = \\displaystyle\\frac{n_i}{n} $<br>\n","誤分類する確率を平均化した指標<br>"],"metadata":{"id":"M-Hc4YNz2b-r"}},{"cell_type":"markdown","source":["# <font color=\"silver\">決定木│情報エントロピー</font>\n",">$\\displaystyle I_H(t) = -\\sum_{i=1}^c p(i|t) \\log_2 p(i|t)$\n","<br><br>\n","ノード$t$のサンプルサイズ$n$個<br>\n","クラス数$c$個<br>\n","ノード$t$のクラス$i$のサンプルサイズが$n_i$個<br>\n","$n_i$の割合を、$p(i|t) = \\displaystyle\\frac{n_i}{n} $<br>\n","情報量を平均化したもので事象のばらつき具合を表す<br>"],"metadata":{"id":"bj_0nMco3Uu7"}},{"cell_type":"markdown","source":["# <font color=\"silver\">k-ｍeans [<font color=\"silver\">…</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!5771&cid=b0f01606242a6ed3&CT=1670918694926&OR=ItemsView)</font></font>\n","\n"],"metadata":{"id":"wyVuKOQKzmSU"}},{"cell_type":"markdown","source":["# <font color=\"silver\">k-ｍeans│k-ｍeans</font>\n","\n","https://zenn.dev/robes/articles/d8cef1c1e8ea8d\n","> - Description<br>\n"," - k-ｍeansの推論<br> \n","   - ${q_{ik} = \\left\\{\n","\\begin{array}{ll}\n","1 & \\boldsymbol{x_i} \\in M(\\boldsymbol{\\mu_k})\\\\\n","0 & {\\rm otherwize}\n","\\end{array}\n","\\right.}$\n","<br><br>\n","$\\mathcal{D} = \\{\\pmb{x}_1, \\pmb{x}_2, \\dots, \\pmb{x}_N\\} = \\{\\pmb{x}_i\\}_{i=1}^N,\\quad x_i \\in \\mathbb R^d$\n","<br><br>\n","$\\mu_k$：<font color=\"silver\">セントロイド, 代表クラスタ</font><br>\n","$M = \\{ \\mu_i, \\ldots, \\mu_K \\}$：<font color=\"silver\">セントロイドの集合</font><br>\n","$q_{ik}$：<font color=\"silver\">$i$番目のデータがk番目の代表ベクトルが支配するクラスタ$M(\\mu_k)$への帰属有無を表す帰属変数（属していれば１、そうでなければ０）<br><br></font>\n"," - k-ｍeansの目的関数<br></font><br>\n","   - クラスタ内誤差平方和を最小化する$\\pmb{\\mu_k}^*$を求める<br><br>\n","$\\begin{align}\\pmb{\\mu_k}^*&=\\mathop{\\rm argmin}\\limits_{\\pmb{u}}J(q_{ik}, \\mu_k)\\\\&= \\mathop{\\rm argmin}\\limits_{\\pmb{u}}\\displaystyle \\sum_{i=1}^{N}\\sum_{k=1}^{K}q_{ik}||x_i-\\mu_k||^2 \n","\\end{align}$\n","<br><br>\n","$\\mu_k$：<font color=\"silver\">セントロイド, 代表クラスタ</font><br>\n","$q_{ik}$：<font color=\"silver\">$i$番目のデータがk番目の代表ベクトルが支配するクラスタ$M(\\mu_k)$への帰属有無を表す帰属変数（属していれば１、そうでなければ０）</font><br><br>\n"," - LloydのAlgorithm</font><br>\n","   - $\\pmb{\\mu_k}^*$は解析的に求められないので、Lloydのアルゴリズムで近似解を求める<br><br>\n","❶ 初期化</font><br>\n","> $N$個のデータをランダムに$K$個のクラスタに振り分け、それぞれのクラスタの平均ベクトルを求め、$\\mu_k(k=1, \\ldots, K)$とする。<br><br>\n","❷ $q_k$の最適化</font><br>\n","> $\\mu_k$固定し、帰属変数$q_k$を以下に従って決定する。<br>\n","$q_{ik} = \\left\\{\n","\\begin{array}{ll}\n","1 & k = \\mathop{\\rm argmin}\\limits_{k}||\\boldsymbol{x_i}-\\boldsymbol{\\mu_j}||^2\\\\\n","0 & {\\rm otherwize}\n","\\end{array}\n","\\right.$<br><br>\n","❸$\\mu_k$の最適化</font><br>\n",">  極値条件により$\\mu_k$を求める<br>\n","$\\cfrac{\\partial J(q_{ik}, \\mu_k)}{\\partial \\mu_k} = 0$<br><br>\n","$2\\sum_{i=1}^Nq{ik}(x_i-\\mu_k) =0$<br><br>\n","$\\mu_k =\\cfrac{\\sum_{i=1}^Nq_{ik} x_i}{\\sum_{i=1}^N q_{ik}}$<br><br>\n"," - k-ｍeansのAlgorithm</font><br>\n","   - クラスタ数$\\,k\\,$と各クラスタに対応するセントロイド$\\,\\mu_k\\,$の初期値を設定する<br>\n","  while：do<br>\n","  $\\quad$各入力データ$\\,x_i\\,$とセントロイド$\\,\\mu_k\\,$との距離を求める<br>\n","  $\\quad$距離が最も小さいクラスタを求めて、データ$\\,x_i\\,$の新しいクラスタを割り当てる<br>\n","  $\\quad$クラスタ内のデータ$\\,x_i\\,$の平均ベクトルを求めて、新しいセントロイド$\\,\\mu_k\\,$を設定する<br>\n","  $\\quad$新旧クラスタを比較して、クラスタが変わらなかったら終了する<br>\n","  end while：<br><br>\n"," - k-ｍeansの<font color=\"blue\">課題</font></font><br> \n","   - 初期値に依存する。➡ k-ｍeans++で改善<br>\n","   - 外れ値の影響を受けやすい。<br>\n","   - 各データが1つのクラスタにしか所属できない。<br>\n","   - クラスタの個数をあらかじめ決定しなければならない。➡ X-ｍeansで改善<br>"],"metadata":{"id":"OMvxYtnM3VR2"}},{"cell_type":"markdown","source":["# <font color=\"silver\">k-ｍeans│k-ｍeans++</font>\n","> - Description<br>\n"," - k-ｍeans++のAlgorithm<br>\n","   - ❶ データ$\\,x_i\\,$からランダムに1つデータを選び、それをセントロイド$\\,\\mu_1\\,$とする<br>\n","   - ❷ データ$\\,x_i\\,$とセントロイド$\\,\\mu_1\\,$との一番近い距離$\\,D(x)\\,$をとる<br>\n","   - ❸ 重み付き確率からセントロイドをランダムに設定する<br>\n","$\\phi(x) = \\cfrac{D(x_i)}{\\sum_k D(x_k)}$<br>\n","   - ❹ 代表点の合計数が$\\,k\\,$個集まればk-meansを実行する<br>"],"metadata":{"id":"3Du1XBf4q5O6"}},{"cell_type":"markdown","source":["# <font color=\"silver\">k-ｍeans│X-ｍeans</font><br>\n","> - Description<br>\n"," - クラスタの個数を決定するAlgorithm<br>\n"," - X-ｍeansのAlgorithm<br>\n","   - ❶ 2個のセントロイドをk-means++で決める<br>\n","   - ❷ 上記セントロイドによりクラスタリング<br>\n","   - ❸ クラスタに対してk-meansでクラスタリングして分割前と後のＢＩＣを計算する<br>\n","   - ❹ 分割前のＢＩＣよりも分割後のＢＩＣの方が大きければ分割を適用する<br>\n","   - ❺ クラスタサイズが一定より小さくなるか、分割するクラスタが無くなったら終了<br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://qiita.com/sotoattanito/items/b885ef2dd3fe11cb817d)</font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F388485%2Fc585335f-bb53-39d6-c5b0-33e67e5af412.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=5c2a5801150dcdf5ee56eef877cf139e\" width=\"640\">"],"metadata":{"id":"0ZmMYZzs_fbi"}},{"cell_type":"markdown","source":["# <font color=\"silver\">PCA [<font color=\"silver\">…</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!5766&cid=b0f01606242a6ed3&CT=1670918751592&OR=ItemsView)</font></font>"],"metadata":{"id":"whrQ0FxkhGI4"}},{"cell_type":"markdown","source":["# <font color=\"silver\">PCA│射影</font>\n",">$\\pmb Y_{[n \\times q]} = \\pmb X_{[n \\times p]} \\pmb W_{[p \\times q]}$"],"metadata":{"id":"pTdUsY50estq"}},{"cell_type":"markdown","source":["# <font color=\"silver\">PCA│PCAの学習定式化</font>\n","> <font color=\"silver\">目的関数<br></font><br>\n","> $N$個のデータ点$\\pmb{x}_1, \\dots, \\pmb{x}_N$をベクトル$\\pmb{u}$で射影したデータ点$\\pmb{u}^\\top\\pmb{x}_i$の分散$s_y^2$が最大となる$\\pmb{u}^{*}$を求める<br><br>\n","$\\begin{align}\\pmb{u}^*&=\\mathop{\\rm argmax}\\limits_{\\pmb{u}}s_y^2\\\\&= \\mathop{\\rm argmax}\\limits_{\\pmb{u}}\\cfrac{1}{N} \\sum_{i=1}^N \\left(\\pmb{u}^\\top \\pmb{x}_i - \\pmb{u}^\\top \\pmb{\\bar{x}}\\right)^2 \\\\\n","&=\\mathop{\\rm argmax}\\pmb{u}^\\top \\left[\\frac{1}{N} \\sum_{i=1}^N (\\pmb{x}_i - \\pmb{\\bar{x}})(\\pmb{x}_i - \\pmb{\\bar{x}})^\\top\\right] \\pmb{u} \\\\\n","&=\\mathop{\\rm argmax}\\limits_{\\pmb{u}}\\pmb{u}^\\top \\pmb{S} \\pmb{u}\n","\\end{align}$\n"],"metadata":{"id":"wcTsT0Jue_BV"}},{"cell_type":"markdown","source":["# <font color=\"silver\">PCA│固有値問題</font>\n","> 固有値問題に帰着する<br><br>\n","$\\pmb{u}^*=\\mathop{\\rm argmax}\\limits_{\\pmb{u}}\\pmb{u}^\\top \\pmb{S} \\pmb{u},\\qquad\\pmb{u}^\\top\\pmb{u}=1$\n","<br><br>\n","$\\hat{\\mathcal{L}}(\\pmb{u}) = \\pmb{u}^\\top \\pmb{S} \\pmb{u} - \\lambda (\\pmb{u}^\\top\\pmb{u} - 1)$\n","<br><br>\n","$ \\begin{align}\\nabla \\hat{\\mathcal{L}}(\\pmb{u})&=0\\\\\n","\\frac{\\partial}{\\partial \\pmb{u}}\\left\\{\\pmb{u}^\\top \\pmb{S} \\pmb{u} - \\lambda (\\pmb{u}^\\top\\pmb{u} - 1)\\right\\} &=0\\\\\n","\\pmb{S} \\pmb{u} &= \\lambda \\pmb{u}\n","\\end{align}$\n"],"metadata":{"id":"HkyYzi76iT64"}},{"cell_type":"markdown","source":["# <font color=\"silver\">PCA│主成分得点</font>\n","> ※ $p$個の固有値および固有ベクトルが求まると、行列$\\pmb{X}$を回転させたあとの座標も計算できるようになる。$k$番目の固有ベクトルを用いると、$\\pmb{z}_{k} = \\pmb{X}\\pmb{w}_{k}$回転後の座標が得られる。これを、第$k$主成分の主成分得点（主成分スコア）という。"],"metadata":{"id":"QKoH-aUpp0MI"}},{"cell_type":"markdown","source":["# <font color=\"silver\">PCA│主成分負荷量</font>\n","> ※  主成分負荷量 ≒ 固有ベクトル。<br>\n","> ※ 観測データ特徴量と主成分得点$\\pmb{z}_{k} = \\pmb{X}\\pmb{w}_{k}$との相関係数を表現したもの。<br>\n","> ※ 単位や値の範囲の影響を受けないため主成分軸の解釈がしやすい。<br>\n","$ {\\rm Cov}(x^{'}_{j}, z^{'}_{k}) = \\cfrac{\\frac{1}{n}\\sum_{i=1}^{n}(x_{i}-\\bar{x}) (y_{i}-\\bar{y})}\n","{\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}(x_{i}-\\bar{x})^{2}} \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}(y_{i}-\\bar{y})^{2}}}$\n","<br>\n"],"metadata":{"id":"0LVAlgDEqQzR"}},{"cell_type":"markdown","source":["# <font color=\"silver\">PCA│寄与率</font>\n","> ※ 寄与率とは、データ全体の情報量（分散=固有値）に占める主成分の分散=固有値の割合を表したもの主成分軸一つが、データの何割を説明することができているかを表したもの<br>\n","> ※ 各主成分の寄与率は、その主成分がデータが持つ全情報量のうち、どれぐらいの割合を説明できるのかを示している割合<br>\n","> ※ 主成分分析における固有値は、主成分の分散のことで、主成分の情報量の大きさを表す\n","<br>\n","$\\cfrac{\\lambda_{k}}{\\lambda_{1}+\\lambda_{2}+\\dots+\\lambda_{p}}=\\cfrac{\\lambda_k}{\\sum_{p=1}\\lambda_p}$<br><br>\n","<img src=\"https://logics-of-blue.com/wp-content/uploads/2017/07/pca-4-intro.jpg\" width=\"320\">\n","\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://logics-of-blue.com/principal-components-analysis/)<br></font></font>\n"],"metadata":{"id":"1r-F3Y7BipWY"}},{"cell_type":"markdown","source":["# <font color=\"silver\">PCA│累積寄与率</font>\n","> ※ 累積寄与率とは、第１主成分から第i主成分までの寄与率の和のこと。<br>\n","> ※ これにより、第１主成分から第i主成分での削減がデータの散らばり具合をどの程度カバーしているかの説明する割合がわかる。<br>\n","$\\cfrac{\\lambda_{1}+\\lambda_{2}+\\dots+\\lambda_{k}}{\\lambda_{1}+\\lambda_{2}+\\dots+\\lambda_{p}}= \\cfrac{\\lambda_1+\\lambda_2+\\dots+\\lambda_k}{\\sum_{p=1}\\lambda_p}$\n"],"metadata":{"id":"7uKfZKES6fM7"}},{"cell_type":"markdown","source":["# <font color=\"silver\">VAE  [<font color=\"silver\">…</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4799&cid=b0f01606242a6ed3&CT=1666706035585&OR=ItemsView)</font><br>\n","\n"],"metadata":{"id":"NyWIzKMnJvCF"}},{"cell_type":"markdown","source":["# <font color=\"silver\">VAE│Autoencoder</font>\n","> - <font color=\"silver\">Description</font><br>\n"," -  <font color=\"silver\">VAE</font>\n","   -  Autoencoder\n","       - f2は恒等関数とし、損失関数は二乗誤差の和を取ると、出力$y$は入力$x$を再現する様に学習が進む<br>\n","       - $W_1, b_1$はデータを表す特徴と呼ばれる。$x$が$W_1$の各行ベクトルの持つ特徴をどれだけ持っているかが、一層目の写像により得られる。<br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://qiita.com/jun40vn/items/374763f478ee094c5041)</font></font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F209705%2F34631f62-6999-2f11-16c6-ab7033835f2b.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=d970cf3b3f288d381c76c7be742347f5\" width=\"480\"><br><br>\n",">$\\mathbf{x} \\approx \\mathbf{x}'$\n","<br><br>\n",">$\\mathbf{x}' = f_\\theta(g_\\phi(\\mathbf{x}))$\n","<br><br>\n","$\\mathbf{x} \\approx f_\\theta(g_\\phi(\\mathbf{x}))$\n","<br><br>\n","$\\displaystyle L_\\text{AE}(\\theta, \\phi) = \\frac{1}{n}\\sum_{i=1}^n (\\mathbf{x}^{(i)} - f_\\theta(g_\\phi(\\mathbf{x}^{(i)})))^2$\n","<br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://lilianweng.github.io/posts/2018-08-12-vae/)</font></font><br>\n","<img src=\"https://lilianweng.github.io/posts/2018-08-12-vae/autoencoder-architecture.png\" width=\"480\"><br>\n","\n","\n","\n","\n"],"metadata":{"id":"o_0o3jd0GhyN"}},{"cell_type":"markdown","source":["# <font color=\"silver\">VAE│Denoising Autoencoder</font>\n","> - <font color=\"silver\">Description</font><br>\n"," -  <font color=\"silver\">VAE</font>\n","   -  Denoising Autoencoder\n","       -  元画像からノイズを除去できるオートエンコーダ<br>\n","       -  学習サンプルにランダムノイズを与え入力とする<br>\n","       -  少ない学習データでより良い学習成果を得られる<br>\n","       -  入力した情報を維持したまま、よりよい特徴を抽出できる<br>\n","       -  破損した$\\mathbf{x}$のコピーを$\\tilde{\\mathbf{x}}$とする<br><br>\n",">$\\mathbf{x} \\approx \\mathbf{x}'$\n","<br><br>\n",">$\\mathbf{x}' = f_\\theta(g_\\phi(\\tilde{\\mathbf{x}}^{(i)}))$\n","<br><br>\n","$\\mathbf{x} \\approx f_\\theta(g_\\phi(\\tilde{\\mathbf{x}}^{(i)}))$\n","<br><br>\n",">$\\tilde{\\mathbf{x}}^{(i)} \\sim \\mathcal{M}_\\mathcal{D}(\\tilde{\\mathbf{x}}^{(i)} \\vert \\mathbf{x}^{(i)})$<br><br>\n","$\\displaystyle L_\\text{DAE}(\\theta, \\phi) = \\frac{1}{n} \\sum_{i=1}^n (\\mathbf{x}^{(i)} - f_\\theta(g_\\phi(\\tilde{\\mathbf{x}}^{(i)})))^2$\n","<br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://lilianweng.github.io/posts/2018-08-12-vae/)</font></font><br>\n","<img src=\"https://lilianweng.github.io/posts/2018-08-12-vae/denoising-autoencoder-architecture.png\" width=\"480\"><br>"],"metadata":{"id":"NPmwlRCeYYHV"}},{"cell_type":"markdown","source":["# <font color=\"silver\">VAE│Contractive Autoencoder</font>"],"metadata":{"id":"RvHLmQD_tsQ4"}},{"cell_type":"markdown","source":["# <font color=\"silver\">VAE│VAEとAutoencoder構造</font>\n","> - <font color=\"silver\">Description</font><br>\n"," -  <font color=\"silver\">VAE</font>\n","   -  <font color=\"blue\">VAE</font>\n","       -  通常のAEでは、入力ベクトルの次元を潜在変数の次元に削減することはできるが、潜在変数自体の構造を把握することは難しいため、VAEでは、潜在変数がガウス分布に従っていると仮定して学習をする。<br>\n","       -  潜在変数付き確率グラフィカルモデルとして構成されている，オートエンコーダネットワーク構造の深層生成モデル<br>\n","       -  中間のボトルネック層を潜在変数化した「潜在変数付きEncoder-Decoder」であるゆえ，ベイズ的な「解釈性の高い潜在確率変数」も学習できる利点がある<br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://qiita.com/jun40vn/items/374763f478ee094c5041)</font></font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F209705%2F4f8f3e75-2e0e-4227-d57a-dfa68b7b7abb.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=a9708240b2dee2d56738603ba4e985bc\" width=\"320\">　　\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F209705%2F38694365-f85c-3050-94b9-ad1fcbbb7cd8.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=d06c7d09372e49fd2586c52b6b3db854\" width=\"320\"><br><br>\n","   -  <font color=\"blue\">VAEとAutoencoder</font><br><br>\n","$\\mathbf{x} \\approx \\mathbf{x}' \\qquad \\mathbf{x}' = f_\\theta(g_\\phi(\\mathbf{x}))$\n","<br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://lilianweng.github.io/posts/2018-08-12-vae/)</font></font><br>\n","<img src=\"https://lilianweng.github.io/posts/2018-08-12-vae/autoencoder-architecture.png\" width=\"480\"><br><br>\n","事前分布$p_\\theta(\\mathbf{z})$から$\\mathbf{z}$をサンプリングしたあと、デコーダーの尤度分布$p_\\theta(\\mathbf{x}\\vert\\mathbf{z})$から$\\mathbf{x}$をサンプリングする。$\\mathbf{z}$がサンプリングされる空間を絞るために$\\mathbf{z} \\sim p(\\mathbf{z})=  \\mathcal{N}(\\mathbf{0},\\mathbf{I})$とする。<br><br>\n","<img src=\"https://lilianweng.github.io/posts/2018-08-12-vae/vae-gaussian.png\" width=\"480\"><br><br>\n","<img src=\"https://lilianweng.github.io/posts/2018-08-12-vae/VAE-graphical-model.png\" width=\"480\"><br>\n","   - <font color=\"blue\">Reparametrization Trick</font><br><br>\n","   <font color=\"black\">$\\mathbf{z} = \\boldsymbol{\\mu} + \\boldsymbol{\\sigma} \\odot \\boldsymbol{\\epsilon} $\n","<br><br>\n","<font color=\"black\">$\\text{where } \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(0, \\boldsymbol{I}) $\n","<br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://cvml-expertguide.net/terms/dl/deep-generative-model/autoencoder/)</font></font><br>\n","<img src=\"https://cvml-expertguide.net/wp-content/uploads/2021/09/02b1a984ee4435b0527bd28ad62364b9-2-768x319.png\" width=\"640\"><br><br>\n","   - VAEの<font color=\"blue\">課題</font><br><br>\n","><font color=\"Blue\">生成画像がぼやける</font><br>\n",">  ※</font> VAEの近似推論、勾配の近似、及び、生成画像がぼやける問題 ➡ GAN<br><br>\n"," ><font color=\"Blue\">posterior collapse</font><br>\n",">  ※ 学習初期に再構成誤差よりもKLダイバージェンスの方が相対的に大きいと、潜在変数が無視されて、潜在変数の事後分布と事前分布が一致して、再構成がうまくいかない問題<br>\n",">  ➡ 学習初期はKLダイバージェンスの項を小さく重みづけをして、徐々に大きくしていく。<br>\n",">  ➡ VQ-VAEは、潜在変数$\\bf{z}$をベクトル量子化で埋め込みベクトルに最も近い場所になるように離散化する。<br>"],"metadata":{"id":"_YQMJITbg1o3"}},{"cell_type":"markdown","source":["# <font color=\"silver\">VAE│VAEと生成モデル</font>\n","> - <font color=\"silver\">Description</font><br>\n"," -  <font color=\"silver\">VAE</font>\n","   -  <font color=\"blue\">VAEの目的関数</font><br>\n","       -  潜在変数 $\\mathbf{z}$ から画像を生成する確率分布$p_{\\theta}(\\mathbf{x})$の最大化としての最尤推定を考える。<br>\n","       -  潜在変数$\\bf{x}$から画像を生成する確率分布$p_\\theta(\\mathbf{x})$を最大にする$\\theta$を求める<br><br>\n","$\\displaystyle\\theta^{*} = \\arg\\max_\\theta \\prod_{i=1}^n p_\\theta(\\mathbf{x})= \\arg\\max_\\theta \\sum_{i=1}^n \\log p_\\theta(\\mathbf{x})$<br><br>\n","   -  <font color=\"blue\">生成モデルのアプローチ</font><br>\n","       -  <font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://lilianweng.github.io/posts/2018-08-12-vae/)</font></font><br>\n","<img src=\"https://lilianweng.github.io/posts/2018-08-12-vae/VAE-graphical-model.png\" width=\"480\"><br>\n","       -  ベイズの定理を考える<br><br>\n","         -  事後分布$p_\\theta(\\mathbf{z}\\vert\\mathbf{x})$をベイズ推論をしようとすると大量なサンプリングが必要となる。また、$\\log p_\\theta(\\mathbf{x})$は解析的に解けない。<br><br>\n","$\\begin{equation}\n","\\displaystyle p_{\\theta}(\\mathbf{z} \\mid \\mathbf{x}) \n","= \\frac{p_{\\theta}(\\mathbf{x} \\mid \\mathbf{z})p_{\\theta}(\\mathbf{z})}{p_{\\theta}(\\mathbf{x})}\n","\\end{equation}$<br><br>\n","$p_\\theta(\\mathbf{z})$：<font color=\"silver\">事前分布, 多変量標準正規分布$\\mathcal{N}(\\mathbf{z} \\mid \\mathbf{0},\\mathbf{I})$</font><br>\n","$p_\\theta(\\mathbf{x}\\vert\\mathbf{z})$：<font color=\"silver\">尤度</font><br>\n","$p_\\theta(\\mathbf{z}\\vert\\mathbf{x})$：<font color=\"silver\">事後分布, $\\mathcal{N}({\\mathbf{z}}; {\\bf{\\mu}}, \\Sigma)$分散共分散行列を対角行列に制限した多変量正規分布</font><br><br>\n","       -  周辺化を考える<br><br>\n","         -  ニューラルネットワークのため解析的には解けない。また、zの次元が高いと積分も困難。<br><br>\n","$\\begin{align} \n","p_{\\mathbf{\\theta}}(\\mathbf{x}) =  \\int  p_{\\mathbf{\\theta}}(\\mathbf{x} \\mid \\mathbf{z}) p_{\\mathbf{\\theta}}(\\mathbf{z}) d \\mathbf{z}\n","\\end{align}$<br><br>\n","$\\begin{align} \n","\\log p_{\\mathbf{\\theta}}(\\mathbf{x}) \n","= \\log \\int  p_{\\mathbf{\\theta}}  (\\mathbf{x} \\mid \\mathbf{z}) p_{\\mathbf{\\theta}}(\\mathbf{z}) d \\mathbf{z}\n","\\end{align}$<br><br>\n","       - 変分ベイズ推論<br><br>\n","         -  解析的には解けないため、$p_\\theta(\\mathbf{z}\\vert\\mathbf{x})$を$q_\\phi(\\mathbf{z}\\vert\\mathbf{x})$で近似して変分ベイズ推論を採用する<br>\n","         -  KLダイバージェンス項は、その定義より非負であるため、$p_{\\mathbf{\\theta}}(\\mathbf{z} \\mid \\mathbf{x}) = q_{\\mathbf{\\phi}}(\\mathbf{z} \\mid \\mathbf{x})$のときは０の値となる。すなわち、対数尤度 $\\log p_\\theta({\\bf{x}})$ を最大化は、変分下限 $\\mathcal{L}_{\\mathbf{\\theta},\\mathbf{\\phi}}(\\mathbf{x})$ を最大化である<br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24)</font></font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F50670%2F2fe60ff8-2015-2b3a-0b78-ce5d7ce8f79a.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=9b431fe5bfafe35667f88432821b9a67\" width=\"240\"><br>\n","$\\begin{align} \\log p_\\theta({\\bf{x}})&=\\int_{\\bf{z}} q_\\phi({\\bf{z}}|{\\bf{x}}) \\log p_\\theta({\\bf{x}}) d{\\bf{z}} \\end{align}$<br><br>\n","$\\log p_{\\mathbf{\\theta}}(\\mathbf{x}) \n","= \\underbrace{\\mathcal{L}_{\\mathbf{\\theta},\\mathbf{\\phi}}(\\mathbf{x})}_{\\text{ELBO}} \n","+\\underbrace{\\mathcal{D}_{KL}( q_{\\mathbf{\\phi}}(\\mathbf{z} \\mid \\mathbf{x}) || p_{\\mathbf{\\theta}}(\\mathbf{z} \\mid \\mathbf{x}))}_{\\text{KLダイバージェンス}}$<br><br>\n","$q_\\phi(\\mathbf{z}\\vert\\mathbf{x})$：<font color=\"silver\">事後分布の近似分布</font><br>\n","$\\phi$：<font color=\"silver\">変分パラメータ</font><br>\n","<img src=\"https://lilianweng.github.io/posts/2018-08-12-vae/VAE-graphical-model.png\" width=\"480\"><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24)</font></font><br>\n","><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F50670%2F4a9a6957-e0c3-3dad-1b33-926b08b21519.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=5fd7c3da4cd56f49bc37fed69fa49a30\" width=\"320\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F50670%2Fae08eb76-aaca-7b26-1b4b-d31bc4a4fceb.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=6633a6584999b6ce70768282fd4a5347\" width=\"320\"><br>\n","   -  <font color=\"blue\">ELBOの解き方</font><br><br>\n","$\\mathcal{L}({\\bf{x}}, \\phi, \\theta) =\\mathbb{E}_{z \\sim q_\\phi (z|x)}\\left[\\log p_\\theta({\\bf{x}}|{\\bf{z}})\\right] -D_{KL}\\left( q_\\phi({\\bf{z}}|{\\bf{x}})||p_\\theta({\\bf{z}}) \\right)$<br><br>\n","$\\mathcal{L}({\\bf{x}}, \\phi, \\theta) \n","= \\underbrace{\\mathbb{E}_{z \\sim q_\\phi (z|x)}\\left[\\log p_\\theta({\\bf{x}}|{\\bf{z}})\\right]}_{\\text{再構成誤差項、大きくする}} \n","-\\underbrace{D_{KL}\\left( q_\\phi({\\bf{z}}|{\\bf{x}})||p_\\theta({\\bf{z}}) \\right)}_{\\text{正則化項、小さくする}}$<br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24)</font></font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F50670%2F2fe60ff8-2015-2b3a-0b78-ce5d7ce8f79a.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=9b431fe5bfafe35667f88432821b9a67\" width=\"240\"><br>\n","   -  <font color=\"blue\">再構成誤差項</font><br>\n","       -  再構成した$p(x|z_q(x))$を入力の$x$に近づける<br>\n","       -  符号化してから復号化したときに、元データと生成データの一致度。<br>\n","       -  潜在変数の近似事後分布q(z|x)の下での可視変数xの対数尤度の期待値。<br>\n","       -  デコーダから再構成されたデータに関する対数尤度<br><br>\n","$\\displaystyle\\mathbb{E}_{z \\sim q_\\phi (z|x))}\\left[\\log p_\\theta({\\bf{x}}|{\\bf{z}})\\right]\\simeq \\frac{1}{L}\\sum_{l=1}^L \\log p_\\theta({\\bf{x}}|{\\bf{z}}^{(l)}), \\hspace{10pt}{\\bf{z}}^{(l)}～q_\\phi({\\bf{z}}|{\\bf{x}})$<br><br>\n","<font color=\"black\">$\\mathbb{E}_{z \\sim q_\\phi (z|x)} \\left[\\log p_\\theta({\\bf{x}}|{\\bf{z}})\\right] =\\displaystyle\\sum_{i = 1}^D x_{i} \\log (f(z_{i}))+(1-x_{i}) \\log(1-f(z_{i}))$\n","<br><br>\n","$D$：<font color=\"silver\">出力層のノード数<br></font><br>\n","   -  <font color=\"blue\">正則化項</font><br>\n","       -  $p(z)$が想定している確率分布$p(z|x)$とかけ離れたものにしないための正則化<br>\n","       -  正則化項の存在により、VAEによって次元削減されたベクトルの集合の中心は原点付近になる。<br>\n","       -  エンコーダーにデータを入力したときの潜在変数が事後分布が潜在変数の事前分布に近づくように機能する。<br>\n","       -  符号化,エンコーダされた, 近似された zの分布N(μ, σ)と復号化,デコーダにおけるzの分布,モデルの分布 N(0, 1)の差異。<br>\n","       -  右辺第一項(DKL)は近似事後分布のエントロピー。<br><br>\n","$\\displaystyle\\begin{align} D_{KL}\\left(q(z|x)||p_\\theta(z) \\right) &=D_{KL} (N(μ,Σ) || N(0,\\boldsymbol{I}))\\\\\\\\&= -\\displaystyle \\cfrac{1}{2}\\sum_{j = 1}^J(1 + \\log(\\sigma_{j}^2)-\\mu_{j}^2 - \\sigma_{j}^2) \n","\\\\\\\\&= -\\frac{1}{2}(1+2\\log \\sigma_{j}-\\mu_{j}^{2} - \\sigma_{j}^{2})\\end{align}$<br><br>\n","$J$：<font color=\"silver\">正規分布の次元数<br><br></font>\n","   -  <font color=\"blue\">VAEの損失関数</font><br><br>\n","$\\mathcal{L}({\\bf{x}}, \\phi, \\theta) \n","= \\underbrace{\\mathbb{E}_{z \\sim q_\\phi (z|x)}\\left[\\log p_\\theta({\\bf{x}}|{\\bf{z}})\\right]}_{\\text{再構成誤差項、大きくする}} \n","-\\underbrace{D_{KL}\\left( q_\\phi({\\bf{z}}|{\\bf{x}})||p_\\theta({\\bf{z}}) \\right)}_{\\text{正則化項、小さくする}}$<br>\n","<font color=\"black\">$L = -\\displaystyle\\sum_{i = 1}^D x_{i} \\log (f(z_{i}))+(1-x_{i}) \\log(1-f(z_{i}))  -\\displaystyle \\frac{1}{2}\\sum_{j = 1}^J(1 + \\log(\\sigma_{j}^2)-\\mu_{j}^2 - \\sigma_{j}^2)$\n","<br><br>\n","$D$：<font color=\"silver\">出力層のノード数<br></font>\n","$J$：<font color=\"silver\">正規分布の次元数"],"metadata":{"id":"xY6B66y-iU3Y"}},{"cell_type":"markdown","source":["# <font color=\"silver\">VAE│VQ-VAE</font><br>\n","<font color=\"silver\">Vector Quantised-VAE, ベクトル量子化VAE</font><br>\n","> - <font color=\"silver\">Description</font><br>\n"," -  <font color=\"silver\">VQ-VAE</font>\n","   -  <font color=\"blue\">VQ-VAE</font>\n","       -  潜在変数zをベクトル量子化で埋め込みベクトルに最も近い場所になるように離散化する手法<br>\n","       -  潜在変数を量子化（離散化）し、事前分布 $p(x)$（特徴マップ）は一様分布を仮定する<br>\n","       -  高品質な画像生成やビデオ生成、音声生成を可能にする<br>\n","<img src=\"https://lilianweng.github.io/posts/2018-08-12-vae/VQ-VAE.png\" width=\"800\">\n","❶ EncorderからエンコーダされたD次元ベクトルの潜在変数$z_e(x)$を出力<br><br>\n","<img src=\"https://data-analytics.fun/wp-content/uploads/2021/10/image-34.png\" width=\"200\"><br><br>\n","❷ コードブックの中から潜在変数$z_e(x)$と最も距離が近い埋め込み表現（one-hotベクトル）を選んで事後分布とする。$\\,\\small q_\\phi(\\mathbf{z}\\vert\\mathbf{x}^{(i)})\\,$。<br><br>\n","<img src=\"https://data-analytics.fun/wp-content/uploads/2021/10/image-44.png\" width=\"640\"><br><br>\n","❸ one-hotベクトルをその位置の潜在表現$z_q(x)$として設定する<br><br>\n","<img src=\"https://data-analytics.fun/wp-content/uploads/2021/10/image-35.png\" width=\"120\"><br><br>\n","<img src=\"https://lilianweng.github.io/posts/2018-08-12-vae/VQ-VAE.png\" width=\"800\"><br>\n","<font color=\"black\">$\\begin{align} q(z=k|x)=\\left\\{\\begin{array}{ll}1&\\text{for }k=\\arg \\min_j \\| z_e(x)-e_j \\|_2, \\\\ 0&\\text{otherwise}\\end{array}\\right. \\end{align}$<br><br>\n","$z_q(x)=e_k, \\hspace{10pt}\\text{where   } k=\\arg\\min_j\\|z_e(x)-e_j\\|_2$\n","<br><br>$j$：<font color=\"silver\">インデックス<br></font>\n","$k$：<font color=\"silver\">インデックス、$K$は埋め込み空間のサイズ<br></font>\n","$e_j$：</font><font color=\"silver\">インデックス$j$の埋め込みベクトル</font><br><br>\n","   - <font color=\"blue\">VQ-VAEの損失関数</font><br>\n","       -  <font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24)</font></font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F50670%2F2fe60ff8-2015-2b3a-0b78-ce5d7ce8f79a.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=9b431fe5bfafe35667f88432821b9a67\" width=\"240\"><br><br>\n","$\\mathcal{L}({\\bf{x}}, \\phi, \\theta) =\\mathbb{E}_{z \\sim q_\\phi (z|x)}\\left[\\log p_\\theta({\\bf{x}}|{\\bf{z}})\\right] -D_{KL}\\left( q_\\phi({\\bf{z}}|{\\bf{x}})||p_\\theta({\\bf{z}}) \\right)$<br><br>\n","$\\mathcal{L}({\\bf{x}}, \\phi, \\theta) \n","= \\underbrace{\\mathbb{E}_{z \\sim q_\\phi (z|x)}\\left[\\log p_\\theta({\\bf{x}}|{\\bf{z}})\\right]}_{\\text{再構成誤差項、大きくする}} \n","-\\underbrace{D_{KL}\\left( q_\\phi({\\bf{z}}|{\\bf{x}})||p_\\theta({\\bf{z}}) \\right)}_{\\text{正則化項、定数なので無視できる}}$<br>\n","   - <font color=\"blue\">正則化項</font><br><br>\n","   <font color=\"black\">事前分布 $p(x)$（は一様分布を仮定することにより、正則化は、定数となるため、計算上は無視できる<br><br>\n","$\\begin{align} D_{KL}\\left(q(z|x)||p_\\theta(z) \\right) &= \\sum_z q(z|x)\\log \\frac{q(z|x)}{p(z)} \\\\ &=-\\sum_z q(z|x)\\log p(z) + \\sum_z q(z|x)\\log q(z|x) \\\\ &=-\\sum_z q(z|x)\\log \\frac{1}{K}  + \\sum_z q(z|x)\\log q(z|x) \\\\ &=-\\log\\cfrac{1}{K} = \\log K \\end{align}$<br><br>\n","   - <font color=\"blue\">VQ-VAEの損失関数</font><br><br>\n","><font color=\"black\">$L=\\log p\\left(x|z_q(x)\\right) + \\left\\|\\text{sg}[z_e(x)]-e \\right \\|^2_2 + \\beta \\left\\|z_e(x)-\\text{sg}[e]\\right\\|^2_2$\n","<br><br>\n","第１項：再構成誤差項, 再構成した$p(x|z_q(x))$を入力$x$に近づけるための項。デコーダの出力に基づいて計算される第一項の勾配は、VQ 処理後の勾配をエンコーダの出力の勾配としてコピーする形で、エンコーダまで逆伝播される。<br><br>\n","第２項：埋め込みベクトル$e$をエンコーダの出⼒$z_e(x)$に近づけるための項。勾配は潜在埋め込みベクトルの更新にのみ用いる。<br><br>\n","第３項：エンコーダの出⼒$z_e(x)$を埋め込みベクトル$e$に近づけるための項。勾配はエンコーダのパラメータ更新にのみ使われる。\n","<br><br>\n","<font color=\"black\">$\\text{sg}$ ：<font color=\"silver\">Stop Gradient、勾配伝播停⽌を意味するオペレータ、入力に対して恒等演算を行い、勾配は0とする<br>\n","<font color=\"black\">$\\beta$ ：<font color=\"silver\">埋め込みベクトル$e$よりもエンコーダのパラメータが先にどんどん更新されていくことを防ぐためのハイパーパラメータ<br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://velog.io/@crosstar1228/%EC%83%9D%EC%84%B1%EB%AA%A8%EB%8D%B8VQ-VAE-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-Deeper-to-equation)</font></font><br>\n","<img src=\"https://velog.velcdn.com/images%2Fcrosstar1228%2Fpost%2F1111ddff-602a-4d53-aed5-cfe5b8c4f449%2Fimage.png\" width=\"640\"><br></font>\n","   - <font color=\"Blue\">Straight-Through</font><br><br>\n","離散化により、勾配の断絶が断絶する ➡ 量子化部分をスキップして勾配を伝える<br>\n","誤差逆伝播を対応させるために、逆伝播は$\\frac{\\partial z_q}{\\partial z_e}\\approx 1$と仮定して、そのまま流す。<br><br>\n","$\\cfrac{\\partial z_q}{\\partial z_e}\\approx 1$<br>\n","$\\cfrac{\\partial L}{\\partial z_e}=\\cfrac{\\partial L}{\\partial z_q}\\cfrac{\\partial z_q}{\\partial z_e}\\approx \\cfrac{\\partial L}{\\partial z_q}$<br>\n","       -  <font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://velog.io/@crosstar1228/%EC%83%9D%EC%84%B1%EB%AA%A8%EB%8D%B8VQ-VAE-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-Deeper-to-equation)</font></font><br>\n","<img src=\"https://velog.velcdn.com/images%2Fcrosstar1228%2Fpost%2Fbbfe43df-a2df-4963-9497-f9ce5091b047%2Fimage.png\" width=\"640\"><br><br>\n"],"metadata":{"id":"visYxVJTlLno"}},{"cell_type":"markdown","source":["# <font color=\"silver\">VAE│appendix, AEとVAEの構造</font>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://qiita.com/jun40vn/items/374763f478ee094c5041)</font></font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F209705%2F34631f62-6999-2f11-16c6-ab7033835f2b.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=d970cf3b3f288d381c76c7be742347f5\" width=\"480\"><br><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F209705%2F4f8f3e75-2e0e-4227-d57a-dfa68b7b7abb.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=a9708240b2dee2d56738603ba4e985bc\" width=\"320\">　　\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F209705%2F38694365-f85c-3050-94b9-ad1fcbbb7cd8.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=d06c7d09372e49fd2586c52b6b3db854\" width=\"320\"><br><br>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://lilianweng.github.io/posts/2018-08-12-vae/)</font></font><br>\n","<img src=\"https://lilianweng.github.io/posts/2018-08-12-vae/autoencoder-architecture.png\" width=\"480\">\n","<img src=\"https://lilianweng.github.io/posts/2018-08-12-vae/vae-gaussian.png\" width=\"480\"><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://cvml-expertguide.net/terms/dl/deep-generative-model/autoencoder/)</font></font><br>\n","<img src=\"https://cvml-expertguide.net/wp-content/uploads/2022/01/899fea34ef94c7105ec8be4debb88d85-768x425.png\" width=\"480\">\n","<img src=\"https://cvml-expertguide.net/wp-content/uploads/2021/09/VariationalAutoencoder-1-768x422.png\" width=\"480\">\n","<br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md)</font></font><br>\n","<img src=\"https://user-images.githubusercontent.com/25688193/65937058-98e6de00-e459-11e9-83f0-08ef15aa3ade.png\" width=\"640\">\n","<img src=\"https://user-images.githubusercontent.com/25688193/65937265-4fe35980-e45a-11e9-872c-0fc8cbaab59c.png\" width=\"640\">"],"metadata":{"id":"4sczFV_0coDc"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GAN  [<font color=\"silver\">…</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4803&cid=b0f01606242a6ed3&CT=1666705289496&OR=ItemsView)<br></font>\n"],"metadata":{"id":"hjSFOIDxNmul"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GAN│GAN<br></font>\n","<font color=\"silver\">GAN, generative adversarial network, 敵対的生成ネットワーク</font><br>\n","> - <font color=\"silver\">Description</font><br>\n"," -  <font color=\"silver\">GAN</font>\n","   -  <font color=\"blue\">GAN</font>\n","       - 生成者と識別者のスコアのミニマックスを考えることで、ナッシュ近衛に収束させる<br>\n","       -ゼロサムゲームのゲーム理論として定式化したもの<br>\n","       - <font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://medium.com/data-science-at-microsoft/synthetic-data-generation-using-generative-adversarial-networks-gans-part-2-9a078741d3ce)</font></font><br>\n","<img src=\"https://miro.medium.com/max/1400/1*HxPxyLmURaQIqYDeVD7ozQ.webp\" width=\"360\">　<img src=\"https://miro.medium.com/max/1100/1*QT9JxFvtX1R3RAbJ6wVvjw.webp\" width=\"360\"><br><br>\n","   -  <font color=\"blue\">GANの学習構造</font><br><br>\n","$\\displaystyle \\min_G \\max_D \\mathcal{V}(D, G) = \\displaystyle \\mathbb{E}_{\\boldsymbol{x} \\mathtt{\\sim} p_{data}(\\boldsymbol{x})}[\\log D(\\boldsymbol{x})] + \\displaystyle \\mathbb{E}_{\\boldsymbol{z} \\mathtt{\\sim} p_{\\boldsymbol{z}}(\\boldsymbol{z})}[\\log (1 - D(G(\\boldsymbol{z})))]$<br><br>\n","$p_z(\\boldsymbol{z})$：<font color=\"silver\">潜在変数$z$を生成するランダムノイズ分布<br></font>\n","$p_{data(\\boldsymbol{x})}$：<font color=\"silver\">データセット全体からランダムにミニバッチを生成する際の分布<br></font>\n","$\\mathbb{E}_{\\boldsymbol{x} \\mathtt{\\sim} p_{data}(\\boldsymbol{x})}[\\log D(\\boldsymbol{x})]\\;$：<font color=\"silver\">本物が本物である期待値</font>\n","<br>\n","$\\displaystyle \\mathbb{E}_{\\boldsymbol{z} \\mathtt{\\sim} p_{\\boldsymbol{z}}(\\boldsymbol{z})}[\\log (1 - D(G(\\boldsymbol{z})))]\\;$：<font color=\"silver\">偽物が偽物である期待値 → Gが小さくしたい</font><br><br>\n","     -  <font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://cvml-expertguide.net/terms/dl/deep-generative-model/gan/)</font></font><br>\n","<img src=\"https://i0.wp.com/cvml-expertguide.net/wp-content/uploads/2021/09/GAN_Adversarial-Training.png?resize=768%2C647&ssl=1\" width=\"480\"><br><br>\n","$\\min_{G}\\max_{D} \\mathcal{V}(D,G) = \n","\\underbrace{\\mathbb{E}_{\\mathbb{x} \\sim p_{data(\\mathbb{x})}} [\\log (D(\\mathbb{x}))]}_{\\text{正解データをよく識別できるようにする項}} +\n"," \\underbrace{\\mathbb{E}_{z \\sim p_z(\\mathbb{z})} \\log [1-D(G(\\mathbb{z})))]}_{\\text{生成データをよく識別できるようにする項}}$<br><br>\n","     -  識別機$D$の学習（生成器$G$の重みを固定）</font><br>\n","         -  本物が入力された時に出力される「本物である確率」及び偽物が入力された時に出力される「偽物である確率」を最大化しようとする。<br>\n","         -  識別器は本物と偽物を区別できなくなり、$D(x)$= 0.5に行き着く（ナッシュ均衡）。<br>\n","         -  正解データセットからm個サンプリングして$x$のミニバッチを用意、全てラベルを1(真)に設定。\n","         -  ランダムノイズから$z$をm個サンプリングし，m個の$\\hat{\\mathbb{x}} = G(\\mathbb{z})$を生成、全てラベルを0(偽)に設定。\n","         -  2値交差エントロピー損失を用いて、SGDで$D$を学習($D(\\hat{\\mathbb{x}})$を0に近づける)<br><br>\n","     -  生成機$G$の学習（識別器$D$の重みを固定）</font><br>\n","         -  Discriminatorに生成データを入力した時に出力される「偽物である確率」を最小化しようとする。<br>\n","         -  ランダムノイズから$z$をm個サンプリングし，m個の$\\hat{\\mathbb{x}} = G(\\mathbb{z})$を生成、全てラベルを1(真)に設定。<br>\n","         -  JSダイバージェンスを損失に用いて、SGDで$G$を学習($D(\\hat{\\mathbb{x}})$を1に近づける)<br><br>\n","   -  <font color=\"blue\">GANの目的関数</font><br>\n","<font color=\"silver\">GAN</font><br>\n","$\\displaystyle \\min_G \\max_D V(D, G) = \\displaystyle \\mathbb{E}_{\\boldsymbol{x} \\mathtt{\\sim} p_{data}(\\boldsymbol{x})}[\\log D(\\boldsymbol{x})] + \\displaystyle \\mathbb{E}_{\\boldsymbol{z} \\mathtt{\\sim} p_{\\boldsymbol{z}}(\\boldsymbol{z})}[\\log (1 - D(G(\\boldsymbol{z})))]$<br><br>\n","<font color=\"silver\">CGAN<br></font>\n",">$\\displaystyle \\min_G \\max_D V(D, G) = \\displaystyle \\mathbb{E}_{\\boldsymbol{x} \\mathtt{\\sim} p_{data}(\\boldsymbol{x})}[\\log D(\\boldsymbol{x}|\\boldsymbol{y})] + \\displaystyle \\mathbb{E}_{\\boldsymbol{z} \\mathtt{\\sim} p_{\\boldsymbol{z}}(\\boldsymbol{z})}[\\log (1 - D(G(\\boldsymbol{z}|\\boldsymbol{y})))]$<br><br>\n","> <font color=\"silver\">Pix2Pix（CGAN）<br></font></font>\n",">$\\mathcal{L}_{cGAN}(G,D) = \\mathbb{E}_{x,y \\sim p_{data}(x,y)}[\\log D(x,y)] +  \\mathbb{E}_{x \\sim p_{data}(x), z \\sim p_z(z)}[\\log (1-D(x,G(x,z)))] \n","$<br><br>\n","> <font color=\"silver\">Pix2Pix<br></font></font>\n","$\\mathcal{L}_{L1}(G) = \\mathbb{E}_{x,y \\sim p_{data}(x,y),z \\sim p_z(z)}[||y-G(x,z)||_1]$<br><br>\n","$G^*={\\rm arg}\\displaystyle \\min_G \\max_D \\mathcal{L}_{cGAN}(G,D)+ \\lambda \\mathcal{L}_{L1}(G)$<br><br>\n","   -  GANの<font color=\"blue\">課題</font><br>\n","         -  勾配消失問題\n","         -  モード崩壊\n","         -  目的関数の収束性\n","         -  過剰な汎化\n","         -  訓練をいつ止めるべきかが不明<br><br>\n","         -  <font color=\"Blue\">損失関数の収束性</font><br>\n","           -  識別器と生成器の２人プレイヤーゼロサムゲームになっているが、このゲームの最適解は、ナッシュ均衡点になる。２人プレイヤーゼロサムゲームのナッシュ均衡点は、鞍点になる。<br>\n","           -  目的関数の勾配が、凸関数であれば、SGDによってナッシュ均衡点（＝鞍点）に収束されることが保証されるが、非凸関数の場合は、保証されない。<br>\n","         -  <font color=\"Blue\">モード崩壊・勾配消失 ➡ PGGAN</font><br>\n","           -  学習が不十分な識別器に対して、生成器を最適化した場合や、生成器への入力ノイズ z の潜在変数としての次元が足りたていない場合などにおいて、生成器による生成画像が、ある特定の画像に集中してしまい、学習用データが本来持っている多様な種類の画像を生成できなくなってしまう問題がある。<br>\n","           -  学習が十分でないと、モード崩壊が発生してしまうが、それを防ぐために、完全に学習すると、今度は勾配損失問題が発生してしまう。<br>\n","           -  GANでは、モード崩壊と勾配損失問題が互いに反して発生してしまうというジレンマがある。<br>\n","         -  <font color=\"Blue\">画像解像度</font><br>\n","           -  高解像度の画像では、（低解像度のときに比べて画像の詳細が分かるので、）正解画像と偽物画像の識別が簡単なタスクとなる。そのため、生成器と識別器の学習が十分に行えない。<br>\n","           -  高解像度の画像を扱うのにより多くのメモリを消費するので、より小さなミニバッチサイズで学習を行う必要がある。その結果として、学習が更に不安定になる。<br>\n","           -  GANはいきなり高解像度の画像を生成するのは難しい ➡ </font>LAPGANで改善<br>\n","           -  LAPGANは段階的に画像を生成する ➡ DCGANで改善<br>\n","         -  <font color=\"Blue\">その他</font><br>\n","           -  生成画像のクオリティーの評価が、損失関数から判断し難い<br>\n","           -  安定した学習条件についてまだ良くわかっていないことが多い<br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md)</font></font><br>\n","<img src=\"https://user-images.githubusercontent.com/25688193/57116628-5bd6cc80-6d91-11e9-9fa6-2089ffd7bbbc.png\" width=\"640\"><br><br>"],"metadata":{"id":"hqLbE-yDTt3C"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GAN│DCGAN</font></font>\n","<font color=\"silver\">DCGAN, Deep Convolutional GAN</font><br>\n","> - <font color=\"silver\">Description</font><br>\n"," -  <font color=\"silver\">GAN</font>\n","   -  <font color=\"blue\">DCGAN</font>\n","       - 物体認識では物体の細かな特徴よりも全体を表す特徴を捉えた方が効果的なため、畳み込みニューラルネットワークは、max poolingで特徴マップを縮小(集約)して被写体の並進移動や形状変化をある程度吸収できるようにしている。一方、GANでは細かな特徴が重要となるため、poolingで細かな情報が欠落しては困る。そこで、DCGANのDiscriminatorでは、poolingの代わりにstride 2の畳み込み処理を行うことで細かな特徴の欠落を防いでいる。<br>\n","         - Batch Normalizationを利用する．（Discriminatorの1層目とGeneratorの最終層は除く）<br>\n","         - Discriminatorの活性化関数は，Leaky ReLUを使用する．<br>\n","         - Generatorの最終層はtanh関数を使用する．（それ以外の層は全てReLU）<br>\n","         - Deconvolutionの使用，PoolingではなくConvolutionによるDownsampling<br>\n","         - 重みは平均0、標準偏差0.02の正規分布となるように初期化<br><br>\n","         - <font color=\"blue\">Generator</font><br>\n","           - Poolingは使用しない<br>\n","           - Transposed Convolutionでアップサンプリングする<br>\n","           - Relu関数を使用するが、出力層はtanh関数を使用する（オリジナルGANと同じ）。<br>\n","           - Batch norm を使用するが、出力層は使用しない。（学習が不安定になるため）<br><br>\n","class Generator(nn.Module):<br>\n","$\\quad$def __ init __ (self):<br>\n","$\\quad$$\\quad$super(). __ init __ ()<br>\n","$\\quad$$\\quad$self.main = nn.Sequential(<br>\n","$\\quad$$\\quad$$\\quad$nn.ConvTranspose2d(100, 256, 4, 1, 0, bias=False),<br>\n","$\\quad$$\\quad$$\\quad$nn.BatchNorm2d(256),<br>\n","$\\quad$$\\quad$$\\quad$nn.ReLU(inplace=True),<br>\n","$\\quad$$\\quad$$\\quad$nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),<br>\n","$\\quad$$\\quad$$\\quad$nn.BatchNorm2d(128),<br>\n","$\\quad$$\\quad$$\\quad$nn.ReLU(inplace=True),<br>\n","$\\quad$$\\quad$$\\quad$nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),<br>\n","$\\quad$$\\quad$$\\quad$nn.BatchNorm2d(64),<br>\n","$\\quad$$\\quad$$\\quad$nn.ReLU(inplace=True),<br>\n","$\\quad$$\\quad$$\\quad$nn.ConvTranspose2d(64, 32, 4, 2, 1, bias=False),<br>\n","$\\quad$$\\quad$$\\quad$nn.BatchNorm2d(32),<br>\n","$\\quad$$\\quad$$\\quad$nn.ReLU(inplace=True),<br>\n","$\\quad$$\\quad$$\\quad$nn.ConvTranspose2d(32, 3, 4, 2, 1, bias=False),<br>\n","$\\quad$$\\quad$$\\quad$nn.Tanh() <br>\n","$\\quad$$\\quad$$\\quad$)<br>\n","         - <font color=\"blue\">Discriminator</font><br>\n","           - Poolingは使用しない<br>\n","           - ストライド幅 2のConvolutionで、ダウンサンプリングする。<br>\n","           - Leaky ReLU 関数を使用する（※オリジナルGANと異なる）。<br>\n","           - Batch norm を使用するが、出力層は使用しない。（学習が不安定になるため）<br>\n","           - 全結合層を取り除き、DropoutとGlobal Average Pooling に置き換える。<br><br>\n","class Discriminator(nn.Module):<br>\n","$\\quad$def __ init __ (self):<br>\n","$\\quad$$\\quad$super(). __ init __ ()<br>\n","$\\quad$$\\quad$self.main = nn.Sequential(<br>\n","$\\quad$$\\quad$$\\quad$nn.Conv2d(3, 32, 4, 2, 1, bias=False),<br>\n","$\\quad$$\\quad$$\\quad$nn.LeakyReLU(0.2, inplace=True),<br>\n","$\\quad$$\\quad$$\\quad$nn.Conv2d(32, 64, 4, 2, 1, bias=False),<br>\n","$\\quad$$\\quad$$\\quad$nn.BatchNorm2d(64),<br>\n","$\\quad$$\\quad$$\\quad$nn.LeakyReLU(0.2, inplace=True),<br>\n","$\\quad$$\\quad$$\\quad$nn.Conv2d(64, 128, 4, 2, 1, bias=False),<br>\n","$\\quad$$\\quad$$\\quad$nn.BatchNorm2d(128),<br>\n","$\\quad$$\\quad$$\\quad$nn.LeakyReLU(0.2, inplace=True),<br>\n","$\\quad$$\\quad$$\\quad$nn.Conv2d(128, 256, 4, 2, 1, bias=False),<br>\n","$\\quad$$\\quad$$\\quad$nn.BatchNorm2d(256),<br>\n","$\\quad$$\\quad$$\\quad$nn.LeakyReLU(0.2, inplace=True),<br>\n","$\\quad$$\\quad$$\\quad$nn.Conv2d(256, 1, 4, 1, 0, bias=False),<br>\n","$\\quad$$\\quad$$\\quad$)<br><br>\n","<img src=\"https://user-images.githubusercontent.com/25688193/57172563-c0129280-6e5c-11e9-941a-dc29501e74a3.png\" width=\"640\"><br>\n","<img src=\"https://user-images.githubusercontent.com/25688193/57172588-226b9300-6e5d-11e9-8c40-d7e348a3debe.png\" width=\"640\">\n","\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md)</font></font><br>"],"metadata":{"id":"rKjveJF_ucQF"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GAN│pix2pix</font>\n","> - <font color=\"silver\">Description</font><br>\n"," -  <font color=\"silver\">GAN</font>\n","   -  <font color=\"blue\">CGAN</font>\n","       - Conditional GAN, 条件付き敵対的生成ネットワーク<br>\n","       - CGANは、生成する画像のクラスラベルなどの条件 y で指定した特定の画像のみを生成する。<br><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F113129%2Fa1c7924d-198f-9d75-32b0-24f4ed09dc7a.jpeg?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=79f4147c048f3e54a318d832bfa363f9\" Height=\"240\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F113129%2Feb0ca770-b8c7-de06-8e60-0ccc859d95d3.jpeg?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=c0b9b230247886c51b289c85bbb471b9\" Height=\"240\">\n","   -  <font color=\"blue\">pix2pix</font>\n","       - Generatorは条件画像xとノイズベクトルzから画像G(x, z)を生成する。Discriminatorは「条件画像xと本物画像yのペア」と「条件画像xと生成した偽物画像G(x, z)のペア」がそれぞれ本物かどうかを識別する。<br><br>\n","<img src=\"https://static.packt-cdn.com/products/9781789139907/graphics/b68163d1-b306-4ace-9422-1b7419f83ca8.png\" width=\"480\"><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md#ConditionalGAN%EF%BC%88cGAN%EF%BC%89)</font></font><br>\n","<img src=\"https://www.gabrielemirra.com/wp-content/uploads/2020/08/p2p_Architecture-2048x563.png\" width=\"640\"><br><br>\n","       -  <font color=\"Blue\">U-Net</font><br>\n","         -  Generator は U-Net を採用することで、「局所的な特徴量と、画像全体の特徴の両方を捉えること」 を同時に実現。変換前画像の顕著なエッジの位置といった消失しやすい低レベルの特徴を変換後画像に伝える<br>\n","         -  Encoder 側の浅い層から、画像全体の大域的な特徴量を skip connection 経由で、Decoder 側に送り、Encoder 側の深い層からの、画像の局所的な特徴量を skip connection 経由で、Decoder 側に送る。そして、Decoder 側で、これら skip connection で送られてきた大域的特徴量と局所的特徴量を保持したたま、アップサンプリングを行い、変換前と同じ解像度の画像を出力する。<br>\n","       -  <font color=\"Blue\">Patch GAN</font><br>\n","         -  x Nのパッチだけで正解画像か生成画像か判定するのを繰り返す。Discriminatorに入力された画像をより小さな（＝局所的な）複数の小領域（＝パッチ）に分解した上で、これら各バッチに対して、本物か偽物かの判定を行い、最後に、全ての応答を平均化して、Discriminatorの最終的な出力とする。<br>\n","         -  これにより、Discriminatorがある程度大域的な判定を残しつつ、局所的な特徴量でのみ判定に専念できる。そのため、学習パラメーター数を大幅に減らすことができ、結果として、学習を効率的に進めることができる。<br>\n","         -  DiscriminatorにおけるPatch GANは、画像の局所的なパッチ構造に注意をむけ、画像パッチ構造のみ注目する。パッチ径よりも離れた場所にあるピクセル間は独立であると仮定し。Discriminatorはパッチそれぞれが、本物か偽物化を識別する。<br>\n","       -  <font color=\"Blue\">L1正則化</font><br>\n","         -  画像の大域的な情報を捉えられるようになり、より違和感のない画像を生成する<br>\n","         -  L1正則化項は、変換後の本物画像y と生成器が生成した偽物画像G(x, z) が、”ピクセル単位” でどの程度異なるのか（＝局所的な特徴量）を表している。<br>\n","         -  L1損失やL2損失は、画像の低周波数の構造（画像の実空間では、画像の全体的な構造）を良く捉えるが、画像の高周波の構造（画像の実空間では、画像の細かい構造）を良く捉えられず、画像がぼやける欠点がある。<br>\n","         -  L2正則化も考えられるが、L2よりL1のほうが、生成画像のぼやけが少ない傾向があるので、pix2pix では、L1を採用している。<br>\n","       -  <font color=\"Blue\">Dropout</font><br>\n","         -  入力ノイズ z は、Dropout を採用することで、従来の確率分布 U(0,1) or N(0,1) からのサンプリングではなく、Generatorの複数の中間層に Dropout をしてノイズとする。<br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md#ConditionalGAN%EF%BC%88cGAN%EF%BC%89)</font></font><br>\n","<img src=\"https://user-images.githubusercontent.com/25688193/57006356-11cbda80-6c1b-11e9-9f92-98c5ee2b175c.png\" width=\"720\"><br>\n","<img src=\"https://blog.acolyer.org/wp-content/uploads/2018/05/pix2pix-fig-2.jpeg?w=520\" width=\"320\"><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://blog.negativemind.com/portfolio/generative-adversarial-network/)</font></font><br>\n","<img src=\"https://blog.negativemind.com/wp-content/uploads/2019/10/cgan_architecture.jpg\" width=\"320\">\n","<img src=\"https://blog.negativemind.com/wp-content/uploads/2019/12/pix2pix_architecture.jpg\" width=\"320\"><br><br>"],"metadata":{"id":"9UQO7M5aOU1v"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GAN│appendix, 様々なGAN</font><br>\n","><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F113129%2Fa1c7924d-198f-9d75-32b0-24f4ed09dc7a.jpeg?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=79f4147c048f3e54a318d832bfa363f9\" Height=\"200\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F113129%2Feb0ca770-b8c7-de06-8e60-0ccc859d95d3.jpeg?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=c0b9b230247886c51b289c85bbb471b9\" Height=\"200\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F113129%2Fbfe528e7-24ad-d7ba-bc73-6061d0baa2cb.jpeg?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=f86c2a30cbd342a2aeca01f0a3c435ae\" Height=\"200\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F113129%2F9ddffe02-daf2-8369-13ac-f4446d1bcb00.jpeg?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=3326b0b6e8272fdf4e59ba0e83075e4f\" Height=\"200\"><br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://www.researchgate.net/figure/Different-GAN-architectures-DCGAN-CGAN-ACGAN-InfoGAN-and-SGAN_fig1_358503554)</font></font><br>\n","<img src=\"https://www.researchgate.net/publication/358503554/figure/fig1/AS:1127459609165825@1645818726790/Different-GAN-architectures-DCGAN-CGAN-ACGAN-InfoGAN-and-SGAN.png\" width=\"640\"><br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://mafda.medium.com/gans-wasserstein-gan-with-mnist-part-6-7f796a0cea47)</font></font><br>\n","<img src=\"https://miro.medium.com/max/828/1*oFQeRHsxqe69WOdpIbA0NA.webp\" width=\"640\">\n","\n"],"metadata":{"id":"FZxfdFfrMlBY"}},{"cell_type":"markdown","source":["# <font color=\"silver\">CTC [<font color=\"silver\">…](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4775&cid=b0f01606242a6ed3&CT=1666701376382&OR=ItemsView) "],"metadata":{"id":"WTIdrGVQVSjB"}},{"cell_type":"markdown","source":["# <font color=\"silver\">CTC│CTC</font>\n","> - <font color=\"silver\">Description</font><br>\n"," -  <font color=\"silver\">CTC</font>\n","   -  <font color=\"blue\">集約関数</font><br><br>\n","パスを文字列へ変換する関数<br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…](https://distill.pub/2017/ctc/)</font></font><br>\n","<img src=\"https://distill.pub/2017/ctc/assets/ctc_alignment_steps.svg\" width=\"480\"><br>\n","<img src=\"https://androidkt.com/wp-content/uploads/2018/08/Differen-Version-of-Hello-e1533987189276.png\" width=\"480\">\n","   -  <font color=\"blue\">定義</font><br><br>\n","$\\boldsymbol{x}$：<font color=\"silver\">入力音声系列<br></font>\n","$\\boldsymbol{l}$：<font color=\"silver\"> ブランクを含まないラベル系列（教師）</font><br>\n","$\\pi$：<font color=\"silver\"> パス<br></font>\n","$\\pi_t$：<font color=\"silver\"> あるパスにおける時刻$t$のクラス番号<br></font>\n","$y_{\\pi_t}^ t$：<font color=\"silver\">$\\boldsymbol \\pi_t$のクラスに対する RNN の出⼒（確率）\n","<br></font>\n","$\\mathcal{B}$：<font color=\"silver\">パスを⽂字列に変換する縮約関数\n","</font><br><br>\n","   -  <font color=\"blue\">パス$\\boldsymbol \\pi$の確率</font><br><br>\n","各パスに存在するノードの確率を全て掛ける<br><br>\n","$\\displaystyle p(\\boldsymbol \\pi \\mid \\boldsymbol {x}) = \\prod_{t=1}^T y_{\\pi_t}^t$<br><br>\n","<img src=\"http://musyoku.github.io/images/post/2017-06-16/path_cat.png\" width=\"320\"><br><br>\n","   -  <font color=\"blue\">ラベル列$\\boldsymbol l$の確率</font><br><br>\n","パス$\\boldsymbol \\pi$の確率を取りうるパス全てについて足す<br><br>\n","$\\displaystyle p(\\boldsymbol{l} \\mid \\boldsymbol{x})=\\sum_{\\pi \\in \\mathcal{B}^{-1}(\\boldsymbol{l})}p(\\pi \\mid \\boldsymbol{x}) ＝\\sum_{\\pi \\in \\mathcal{B}^{-1}(\\boldsymbol{l})}\\prod_{t=1}^ T y_{\\pi_t}^ t$\n","<br><br>\n","<img src=\"http://musyoku.github.io/images/post/2017-06-16/path_cat.png\" width=\"320\">\n","<img src=\"http://musyoku.github.io/images/post/2017-06-16/label_cat.png\" width=\"320\"><br><br>\n","   -  <font color=\"blue\">損失関数</font><br><br>\n","最尤推定より$\\mathcal{L}$の最小化は、すなわち、$p(\\boldsymbol{l} \\mid  \\boldsymbol{x})$の最大化<br><br>\n","$\\mathcal{L} =\\displaystyle -\\log(p(\\boldsymbol{l} \\mid  \\boldsymbol{x}))$<br><br>\n","   -  <font color=\"blue\">勾配</font><br><br>\n","RNNの出力（確率）$y_k^t$に対する勾配<br><br>\n","$\\cfrac{\\partial L}{\\partial y_k^t} = \\cfrac{-\\log(p(\\boldsymbol{l} \\mid  \\boldsymbol{x}))}{\\partial y_k^t} = -\\cfrac{1}{p(\\boldsymbol{l} \\mid \\boldsymbol{x})}\\cfrac{\\partial p(\\boldsymbol{l} \\mid  \\boldsymbol{x})}{\\partial y_k^t}$<br>\n"],"metadata":{"id":"2njjgwSoZ8bg"}},{"cell_type":"markdown","source":["# <font color=\"silver\">CTC│確率の導出</font>\n","> - <font color=\"silver\">Description</font><br>\n"," -  <font color=\"silver\">CTC</font>\n","   -  <font color=\"blue\">ラベル列$\\boldsymbol{l}'$の定義</font><br><br>\n","   ラベル列$\\boldsymbol{l}'$は、ラベル系列$\\boldsymbol{l}$の各文字の前後に「_(ブランク)」を配置したもの\n"," <br>\n"," <img src=\"http://musyoku.github.io/images/post/2017-06-16/extended_label.png\" width=\"400\">\n","<br>\n","$\\boldsymbol{l}'$：<font color=\"silver\"> $\\boldsymbol{l}$の両端と各ラベルの間にブランクを追加したブランク入りラベル系列<br></font>\n","$|\\boldsymbol{l}'|$：<font color=\"silver\"> $2|\\boldsymbol{l}|+1$<br></font>\n","$\\cal B(\\boldsymbol \\pi_{1:t}) = \\boldsymbol l_{1:\\lfloor s/2 \\rfloor}$：<font color=\"silver\"> $\\alpha_t(s)$の総和の範囲<br></font>\n","$\\cal B(\\boldsymbol \\pi_{t:T}) = \\boldsymbol l_{\\lfloor s/2 \\rfloor:\\mid \\boldsymbol l \\mid}$：<font color=\"silver\">$\\beta_t(s)$の総和の範囲</font><br><br>\n","   -  <font color=\"blue\">前向き後ろ向きアルゴリズム</font><br>\n","       - $\\alpha_t(s)$の総和の範囲<br>\n","         - 「時刻 1」から「時刻$t$の$s$番目の拡張ラベル」へ到達するまでの全てのパスの確率の総和<br>\n","         - 取りうるパスのうち、時刻$t$までのパスが拡張ラベルの$s$番目までと一致するパス について全て足す<br><br>\n","$\\cal B(\\boldsymbol \\pi_{1:t}) = \\boldsymbol l_{1:\\lfloor s/2 \\rfloor}$<br><br>\n","       - $\\beta_t(s)$の総和の範囲<br>\n","         - 「時刻$t$の$s$番目の拡張ラベル」から「最終時刻」へ到達するまでの全てのパスの確率の総和<br>\n","         - 取りうるパスのうち、時刻$t$以降のパスが拡張ラベルの$s$番目以降と一致するパス について全て足す<br><br>\n","$\\cal B(\\boldsymbol \\pi_{t:T}) = \\boldsymbol l_{\\lfloor s/2 \\rfloor:\\mid \\boldsymbol l \\mid}$<br><br>\n","       - 再帰的性質<br><br>\n","$\\begin{align}\t\n","  \t\\alpha_t(s) = \n","\t  \\begin{cases}\n","\t    (\\alpha_{t-1}(s) + \\alpha_{t-1}(s-1)) y_{\\boldsymbol l'_s}^t & \\text{if } \\boldsymbol l'_s = blank \\text{ or } \\boldsymbol l'_{s-2} = \\boldsymbol l'_s\\\\\n","\t    \\left( \\alpha_{t-1}(s) + \\alpha_{t-1}(s-1) + \\alpha_{t-1}(s-2) \\right)y_{\\boldsymbol l'_s}^t & \\text{otherwise}\n","\t  \\end{cases}\n","  \\end{align}$<br><br>\n","  $\\boldsymbol l’_{s-2} = \\boldsymbol l’_s$ は例外のケースに相当する。例えば、cutter の tt ような同じ文字が続く場合は、間に必ずブランクを入れる。<br><br>\n","       - パス$\\boldsymbol \\pi$の確率の総和<br><br>\n","$\\displaystyle \\alpha_t(s) \\overset{\\rm def}{=} \\sum_{\\cal B(\\boldsymbol \\pi_{1:t}) = \\boldsymbol l_{1:\\lfloor s/2 \\rfloor}} \\prod_{t'=1}^t y_{\\boldsymbol \\pi_{t'}}^{t'}$\n","<br><br>\n","$\\displaystyle\\beta_t(s) \\overset{\\rm def}{=} \\sum_{\\cal B(\\boldsymbol \\pi_{t:T}) = \\boldsymbol l_{\\lfloor s/2 \\rfloor:\\mid \\boldsymbol l \\mid}} \\prod_{t'=t}^T y_{\\boldsymbol \\pi_{t'}}^{t'}$<br><br>\n","$\\displaystyle\\alpha_t(s)\\beta_t(s) = \\sum_{\\boldsymbol \\pi \\in {\\cal B}^{-1}(\\boldsymbol l) \\pi_t = l'_s} y_{l'_s}^t \\prod_{t=1}^T y_{\\pi_t}^t$\n","<br><br>\n","<img src=\"http://musyoku.github.io/images/post/2017-06-16/forward.png\" width=\"320\">\n","<img src=\"http://musyoku.github.io/images/post/2017-06-16/backward.png\" width=\"320\"><br><br></font>\n","       - パス$\\boldsymbol \\pi$の確率の導出<br><br>\n","$\\displaystyle\\alpha_t(s)\\beta_t(s) = \\sum_{\\boldsymbol \\pi \\in {\\cal B}^{-1}(\\boldsymbol l) \\pi_t = l'_s} y_{l'_s}^t \\prod_{t=1}^T y_{\\pi_t}^t$\n","<br><br>\n","$\\displaystyle p(\\boldsymbol \\pi \\mid \\boldsymbol {x}) = \\prod_{t=1}^T y_{\\pi_t}^t$<br><br>\n","$\\displaystyle\\frac{\\alpha_t(s)\\beta_t(s)}{y_{l'_s}^t} = \\sum_{\\boldsymbol \\pi \\in {\\cal B}^{-1}(\\boldsymbol l) \\pi_t = l'_s}  p(\\boldsymbol \\pi \\mid \\boldsymbol { x})$<br><br>\n","       - ラベル列$\\boldsymbol l$の確率の導出<br><br>\n","$\\displaystyle\\frac{\\alpha_t(s)\\beta_t(s)}{y_{l'_s}^t} = \\sum_{\\boldsymbol \\pi \\in {\\cal B}^{-1}(\\boldsymbol l) \\pi_t = l'_s}  p(\\boldsymbol \\pi \\mid \\boldsymbol { x})$<br><br>\n","$\\displaystyle p(\\boldsymbol{l} \\mid \\boldsymbol{x})=\\sum_{\\boldsymbol{\\pi} \\in \\mathcal{B}^{-1}(\\boldsymbol{l})}p(\\boldsymbol{\\pi} \\mid \\boldsymbol{x}) $<br><br>\n","$\\displaystyle p(\\boldsymbol l \\mid \\boldsymbol {x}) = \\sum_{s=1}^{\\mid \\boldsymbol l' \\mid} \\frac{\\alpha_t(s)\\beta_t(s)}{y_{l'_s}^t}$"],"metadata":{"id":"xxbk2VvQm0E6"}},{"cell_type":"markdown","source":["#<font color=\"silver\">CTC│尤度の解き方<br></font>\n","拡張ラベル系列を作成して尤度を解く</font><br>\n","-  ブランクの確率は、そのままコピーする<br>\n","-  確率ゼロは無視する<br>\n","-  時刻１は「_」または「a」<br>\n","-  時刻４は「i」または「_」であるが、「_」はゼロなので無視でき、この場合の時刻4は「i」のみ<br>\n","<font color=\"black\">\n","\n","|ラベル|1|2|3|4|\n","| :---: | :---: | :---: | :---: | :---: | \n","|a|1/2|1/2|1/4|0|\n","|i|1/4|0|1/4|1|\n","|_|1/4|1/2|1/2|0|\n","\n","|ラベル|1|2|3|4|\n","| :---: | :---: | :---: | :---: | :---: | \n","|_|1/4|1/2|1/2|0|\n","|a|1/2|1/2|1/4|0|\n","|_|1/4|1/2|1/2|0|\n","|i|1/4|0|1/4|1|\n","|_|1/4|1/2|1/2|0|\n","\n","“ _ _ a i ”$\\qquad$“ _ a _ i ”$\\qquad$“ _ a i i” <br>\n","“ _ a a i ”$\\qquad$“ a a _ i ”$\\qquad$“ a a i i” <br>\n","“ a a a i ”$\\qquad$“ a _ _ i ”$\\qquad$“ a _ i i ”<br><br>\n","\n","拡張ラベル系列を作成して尤度を解く</font><br>\n","- ブランクの確率は、そのままコピーする<br>\n","- 確率ゼロは無視する<br>\n","- 時刻１は「_」または「a」であるが、「_」はゼロなので無視でき、この場合の時刻1は「a」のみ<br>\n","- 時刻４は「b」または「_」<br>\n","<font color=\"black\">\n","\n","|ラベル|1|2|3|4|\n","| :---: | :---: | :---: | :---: | :---: | \n","|a|2/3|0|0|1/4|\n","|b|1/2|1/3|2/3|1/2|\n","|_|0|2/3|1/3|1/4|\n","\n","|ラベル|1|2|3|4|\n","| :---: | :---: | :---: | :---: | :---: | \n","|_|0|2/3|1/3|1/4|\n","|a|2/3|0|0|1/4|\n","|_|0|2/3|1/3|1/4|\n","|b|1/2|1/3|2/3|1/2|\n","|_|0|2/3|1/3|1/4|\n","\n","abbb, $\\frac{2}{3}$×$\\frac{1}{3}$×$\\frac{2}{3}$×$\\frac{1}{2}$<br><br>\n","abb_, $\\frac{2}{3}$×$\\frac{1}{3}$×$\\frac{2}{3}$×$\\frac{1}{4}$<br><br>\n","ab__, $\\frac{2}{3}$×$\\frac{1}{3}$×$\\frac{1}{3}$×$\\frac{1}{4}$<br><br>\n","a_bb, $\\frac{2}{3}$×$\\frac{2}{3}$×$\\frac{2}{3}$×$\\frac{1}{2}$<br><br>\n","a_b_, $\\frac{2}{3}$×$\\frac{2}{3}$×$\\frac{2}{3}$×$\\frac{1}{4}$<br><br>\n","a__b, $\\frac{2}{3}$×$\\frac{2}{3}$×$\\frac{1}{3}$×$\\frac{1}{2}$<br>"],"metadata":{"id":"ZGTKK4jUSJv4"}},{"cell_type":"markdown","source":["# <font color=\"silver\">CTC│Best Path Decoding<br></font>\n","<font color=\"blue\">Best Path Decoding</font><br>\n","推論時は、近似解として、Best Path Decodingを行って求める。<br>\n","-  各時刻において最も確率の高いラベル(文字)を選んで、\n","それをつなげる<br>\n","-  同じラベルが連続した場合は 1 つにまとめる<br>\n","-  ブランクは削除する<br>\n","<font color=\"black\">\n","\n","|ラベル|1|2|3|4|5|6|7|8 |\n","| :---: | :---: | :---: | :---: | :---: | :---: |  :---: | :---: | :---: |\n","|a|0.1|0.6|0|0.1|0|0.2|0|0.1|\n","|i|0|0.1|0.4|0.7|0|0.3|0.1|0|\n","|u|0|0.3|0.3|0.1|0|0.4|0.1|0.1|\n","|_|0.9|0|0.3|0.1|1.0|0.0|0.8|0.8|\n","||||||||||\n","|パス|_|a|i|i|_|u|_|_|\n","文字列：aiu\n","\n","<br>1/2 ×1/2×1/2×1 ＝1/8<br>\n","\n","|ラベル|1|2|3|4|\n","| :---: | :---: | :---: | :---: | :---: | \n","|a|1/2|1/2|1/4|0|\n","|i|1/4|0|1/4|1|\n","|_|1/4|1/2|1/2|0|\n","\n","<br>2/3 ×2/3×2/3×1/2 ＝8/54＝4/27<br>\n","\n","|ラベル|1|2|3|4|\n","| :---: | :---: | :---: | :---: | :---: | \n","|a|2/3|0|0|1/4|\n","|b|1/2|1/3|2/3|1/2|\n","|_|0|2/3|1/3|1/4|\n","\n","\n"],"metadata":{"id":"Wtp38mFgVTYa"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MDP│[<font color=\"silver\">…](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!5847&cid=b0f01606242a6ed3&CT=1671280316064&OR=ItemsView)\n","\n","https://julien-vitay.net/lecturenotes-deeprl/intro.html\n","\n","https://wikidocs.net/175435\n","\n","https://lilianweng.github.io/posts/2018-02-19-rl-overview/\n","\n","https://lilianweng.github.io/posts/2018-04-08-policy-gradient/\n","\n"],"metadata":{"id":"zHYjJYcxoADv"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MDP│マルコフ決定過程</font><br>\n","<font color=\"silver\">マルコフ決定過程, Markov decision process, MDP</font>\n","> - <font color=\"silver\">Description</font><br>\n"," - マルコフ決定過程\n","   - 次の状態$\\,t+1\\,$が現時間ステップ$\\,t\\,$の値$\\,x_t\\,$のみに依存して、現時間ステップ$\\,t\\,$の値$\\,x_t\\,$が与えられれば  以前の値$\\,x_{t-1}\\,$には依存しない性質\n","   - 時刻$\\,t+1\\,$の収益$G_{t+1}$は、$S_{t+1}=s'$に依存する。<br>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://lilianweng.github.io/posts/2018-02-19-rl-overview/)</font><br>\n","<img src=\"https://lilianweng.github.io/posts/2018-02-19-rl-overview/agent_environment_MDP.png\" width=\"320\"><img src=\"https://lilianweng.github.io/posts/2018-02-19-rl-overview/bellman_equation.png\" width=\"320\">\n","<br><br>\n","$\\mathcal{S}$<font color=\"silver\">：状態集合</font><br>\n","$\\mathcal{A}$<font color=\"silver\">：行動集合</font><br>\n","$p_{s_{0}}$<font color=\"silver\">：初期状態確率関数</font><br>\n","$p(s′|s,a)$<font color=\"silver\">：状態遷移確率、どの状態に遷移するかを表す確率</font><br>\n","$r(s,a,s′):S×A×S→R$<font color=\"silver\">：報酬関数</font><br>\n","$\\pi$<font color=\"silver\">：確率的方策、状態$s$でとるべき行動$a$を表す確率</font><br><br>\n","$p(s'\\,|\\,s,\\,a)\\triangleq\\mathrm{Pr}(S_{t+1}=s'\\,|\\,S_{t}=s,\\,A_{t}=a) $\n","<br><br>\n","$\\pi(a\\mid s)\\triangleq\\mathrm{Pr}(A=a\\,|\\,S=s) \\quad \\displaystyle\\sum_{a\\in\\mathcal{A}}\\pi(a\\mid s)=1$<br><br>\n"," - 累積報酬和 $R_t$<br><br>\n","$\\displaystyle R_t = r_{t+1} + \\gamma \\, r_{t+2} +  \\gamma^2 \\, r_{t+3} + ... = \\sum_{k=0}^{\\infty} \\gamma^k \\, r_{t+k+1}$<br><br>\n","$\\displaystyle R_t =\\sum_{k=0}^T γ^k r_{t+k+1}$<br><br>\n","$\\displaystyle R_t=r_{t+1}+γR_{t+1}$<br><br>\n","$\\begin{split}\n","\\begin{eqnarray*}\n","    R_t &=& r_{t+1} + \\gamma \\, r_{t+2} +  \\gamma^2  \\, r_{t+3} + \\dots + \\gamma^k \\, r_{t+k+1} + \\dots \\\\\n","        &=& r_{t+1} + \\gamma \\, ( r_{t+2} +  \\gamma \\, r_{t+3} + \\dots + \\gamma^{k-1} \\, r_{t+k+1} + \\dots) \\\\\n","        &=& r_{t+1} + \\gamma \\,  R_{t+1} \\\\\n","\\end{eqnarray*}\n","\\end{split}$<br><br>\n","$\\displaystyle R_t = r_{t+1} + \\gamma r_{t+2} + \\dots = \\sum_{k=0}^{\\infty} \\gamma^k r_{t+k+1}$<br><br>\n","$r$<font color=\"silver\">：即時報酬<br></font>\n","$t$<font color=\"silver\">：時間ステップ<br></font>\n","$\\gamma\\in [0,1]$<font color=\"silver\">：割引率<br></font>\n","$k$<font color=\"silver\">：未来へ進む変数</font><br><br>\n"," - 割引率 $\\gamma$<br>\n","   - 割引率$\\gamma$は、短期的視点を大事にするか、長期的視点を大事にするかを調整する。<br>\n","   -  $\\gamma=0$であれば、$k=0$のときの報酬が収益になるため、エージェントは一次的な\n","収入(報酬)だけを考えて行動する。<br>\n","   - $\\gamma=1$に近いほど、エージェントは将来得られる報酬を考慮した行動をする。<br><br>\n","   累積報酬を考える際には直近に得られる報酬を重視するというのが基本スタンスです。なぜなら、ずっと先のステップのことはよく分からないため、いくら報酬が高そうであっても、本当に得られるかどうかが不明だからです。従って、将来の報酬の影響を小さくするために割引率$\\gamma$が導入されました。先のステップになればなるほど割引率$\\gamma$の累乗の指数が大きくなるので、その報酬値が小さく見積もられることがご理解いただけるかと思います。<br><br>\n"," - 状態価値と行動価値<br><br>\n",">$V^{\\pi}(s) ={\\mathbb E}^\\pi\\left[G_t|s_t = s\\right]$\n","<br><br>\n","$Q^{\\pi}(s,a) ={\\mathbb E}^\\pi\\left[G_t | s_t = s, a_t = a\\right]$\n","<br><br>\n","$V^{\\pi}(s) ：$<font color=\"silver\">ある方策$\\pi$の下でのある状態$s$の価値<br></font>\n","$Q^{\\pi}(s,a) ：$<font color=\"silver\">ある方策$\\pi$の下でのある行動$a$の価値<br></font><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://www.data-artist.com/contents/reinforcement-learning.html)</font><br>\n","<img src=\"https://www.data-artist.com/assets/images/contents/reinforcement-learning/reinforcement-learning-img05.jpg\" width=\"480\">"],"metadata":{"id":"7wMa68qYtj8U"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MDP│ベルマン方程式</font>\n","><font color=\"silver\">ベルマン方程式</font><br><br>\n","$ V^{\\pi}(s) = \\displaystyle\\sum_{a\\in A}\\pi(a|s)\\sum_{s'\\in S}P(s'|s, a)[r(s, a, s') + \\gamma V^{\\pi}(s') ]$\n","<br><br>\n","$ Q^\\pi (s, a) =  \\displaystyle\\sum_{s'\\in S} P(s'|s, a)\\left[r(s, a, s') + \\gamma V^{\\pi}(s') \\right]$<br><br>\n","><font color=\"silver\">ベルマン方程式</font><br><br>\n",">$ V^{\\pi}(s) = \\displaystyle\\sum_{a\\in A}\\pi(a|s)\\sum_{s'\\in S}P(s'|s, a)[r(s, a, s') + \\gamma V^{\\pi}(s') ]$<br><br>\n",">$ Q^\\pi (s, a) = \\displaystyle\\sum_{s'\\in S} P(s'|s, a)[r(s, a, s') + \\gamma \\displaystyle\\sum_{a'\\in\\mathcal{A}}\\pi(a'|s')Q^\\pi(s',a')]  $\n","<br><br>\n","><font color=\"silver\">ベルマン最適方程式</font><br><br>\n",">$ V^{*}(s)=\\displaystyle\\max_{a}\\sum_{s^{\\prime}} P(s^{\\prime}|s,a)\\left[r(s,a,s^{\\prime})+\\gamma V^{*}(s^{\\prime})\\right]$\n","<br><br>\n","$ Q^{*}(s,a)=\\displaystyle\\sum_{s^{\\prime}} P(s^{\\prime}|s,a)[r(s,a,s^{\\prime})+\\gamma \\max_{a^{\\prime}}Q^{*}(s^{\\prime},a^{\\prime})]$\n","<br><br>\n","> <font color=\"silver\">状態ベルマン方程式</font><br><br>\n",">$ V^{\\pi}(s) = \\displaystyle\\sum_{a\\in A}\\pi(a|s)\\sum_{s'\\in S}P(s'|s, a)[r(s, a, s') + \\gamma V^{\\pi}(s') ]$\n","<br><br>\n","$ V^{*}(s)=\\displaystyle\\max_{a}\\sum_{s^{\\prime}} P(s^{\\prime}|s,a)[r(s,a,s^{\\prime})+\\gamma V^{*}(s^{\\prime})]$\n","<br><br>\n",">$V^\\pi(s) = \\displaystyle\\sum_{a\\in\\mathcal{A}}\\pi(a|s)Q^\\pi(s,a)$<br><br>\n","> <font color=\"silver\">行動ベルマン方程式</font><br><br>\n","$Q^\\pi (s, a) =  \\displaystyle\\sum_{s'\\in S} P(s'|s, a)\\left[r(s, a, s') + \\gamma V^{\\pi}(s') \\right]$<br><br>\n",">$ Q^\\pi (s, a) = \\displaystyle\\sum_{s'\\in S} P(s'|s, a)[r(s, a, s') + \\gamma \\displaystyle\\sum_{a'\\in\\mathcal{A}}\\pi(a'|s')Q^\\pi(s',a')]  $\n","<br><br>\n","$ Q^{*}(s,a)=\\displaystyle\\sum_{s^{\\prime}} P(s^{\\prime}|s,a)[r(s,a,s^{\\prime})+\\gamma \\max_{a^{\\prime}}Q^{*}(s^{\\prime},a^{\\prime})]$"],"metadata":{"id":"ydChZ5B8FEjI"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MDP│方策関数</font><br>\n","><font color=\"Blue\">greedy方策</font><br><br>\n","> ※ これまでの経験に基づき、報酬和の期待値が最大になる行動を選択する。<br>\n","> ※ 最初にまとめて探索を行い、最大の報酬和が得られる最適行動を決定。以後探索を行わず「最適な」行動を常にとる。<br><br>\n","$\\pi(a \\mid s) = \n","\\begin{cases} \n","1 & (a = \\underset{a \\in \\mathcal{A}}{{\\rm argmax}}Q(s, a)), \\\\ \n","0 & ({\\rm otherwise}). \n","\\end{cases}$<br><br>\n","><font color=\"Blue\">$ε$-greedy方策</font><br><br>\n","> ※ 局所解に落ち込むリスクをとる<br>\n","> ※ 確率$\\,ε\\,$でランダムに行動$\\,a\\,$を選び、それ以外の確率$\\,(1-ε) \\,$で最も期待値の高い行動を選択する。<br><br>\n","${\\pi (a \\mid s) =\n","\\begin{cases}\n","1-\\epsilon+\\cfrac{\\epsilon}{\\vert \\mathcal{A} \\vert} & \\bigl(a=\\underset{a \\in \\mathcal{A}}{\\mathrm{argmax}}Q(s, a) \\bigr) \\\\\n","\\cfrac{\\epsilon}{\\vert \\mathcal{A} \\vert} & (\\text{otherwise})\n","\\end{cases}\n","}$\n","<br><br>\n","$ε$<font color=\"silver\">：探索率</font>\n","<br><br>\n","> グリーディ法の場合、常に「今のところ一番良さげなレバー」しか選ばないので、つまり「知識利用」のみを行って、「探査」は行わないことになる。それだと推定される行動の価値が改善されていかない可能性があるので、$ε(0<ε<1)$の確率で、ランダムに行動を選択するような方法も考えてみる。<br><br>\n","><font color=\"Blue\">Softmax方策</font><br><br>\n","> ※ 局所解に落ち込むリスクをとる<br>\n","> ※ 期待報酬値が高い選択肢の選択確率が高くなるように選択確率を決定する<br>\n","> ※ $Q(s, a)$が高いほど、$a$が選ばれる確率が高い<br><br>\n","$\\pi(a \\mid s)=\\dfrac{\\exp\\left( Q(s,\\,a)/T\\right)}{\\sum_{a'}\\exp\\left( Q(s,\\,a')/T\\right)}$<br><br>\n","$T$<font color=\"silver\">：温度、探索率のようなもの</font>\n","<br><br>\n","> 推定される行動の価値から、価値が高そうな行動はより選ばれやすく、価値が低そうな行動は選ばれにくく（けど、全く選ばれないわけではないように）なる確率にしたがって行動を選択する。そうすれば、基本的には価値が高いと思われる行動が選ばれ、たまに他の行動の探査も行われるようになる。\n","\n"],"metadata":{"id":"a1DT1jVSwHJP"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MDP│ベルマン方程式の導出</font><br>\n",">$\\begin{aligned}\n","V(s) &= \\mathbb{E}[G_t \\vert S_t = s] \\\\\n","&= \\mathbb{E} [R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\vert S_t = s] \\\\\n","&= \\mathbb{E} [R_{t+1} + \\gamma (R_{t+2} + \\gamma R_{t+3} + \\dots) \\vert S_t = s] \\\\\n","&= \\mathbb{E} [R_{t+1} + \\gamma G_{t+1} \\vert S_t = s] \\\\\n","&= \\mathbb{E} [R_{t+1} + \\gamma V(S_{t+1}) \\vert S_t = s]\n","\\end{aligned}$<br><br>\n",">$ \\begin{align}\n","V^\\pi(s)\n","&= E_\\pi\\left[G_t|s_t = s\\right]\\\\\\\\\n","&= E_\\pi\\left[\\sum_{k=0}^{\\infty}\\gamma^kr_{t+k+1}|s_t=s\\right]\\\\\\\\\n","&= E_\\pi\\left[r_{t+1}+\\gamma\\sum_{k=0}^{\\infty}\\gamma^kr_{t+k+2}|s_t=s\\right]\\\\\\\\\n","&=\\sum_a\\pi(a|s)\\sum_{s'}P(s'|s, a)\\left(r(s, a, s')  + \\gamma E_\\pi\\left[\\sum_{k=0}^\\infty\\gamma^kr_{t+k+2}|s_{t+1} = s'\\right]\\right)\\\\\\\\\n","&= \\displaystyle\\sum_{a\\in A}\\pi(a|s)\\sum_{s'\\in S}P(s'|s, a)\\left[r(s, a, s') + \\gamma V^{\\pi}(s') \\right]\n","\\end{align}$\n","<br><br>\n",">$Q^\\pi (s, a) =  \\displaystyle\\sum_{s'\\in S} P(s'|s, a)\\left[r(s, a, s') + \\gamma V^{\\pi}(s') \\right]$\n","<br><br>\n","$\\pi(a|s)$：<font color=\"silver\">方策関数</font><br>\n","$P(s'|s, a)$：<font color=\"silver\">状態遷移確率</font><br>\n","$r(s, a, s')$：<font color=\"silver\">報酬関数</font><br>\n"],"metadata":{"id":"mesFZTeuxTAL"}},{"cell_type":"markdown","source":["# <font color=\"silver\">価値推定 [<font color=\"silver\">…](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4543&cid=b0f01606242a6ed3&CT=1671286808229&OR=ItemsView)"],"metadata":{"id":"WCvGsEATw9c3"}},{"cell_type":"markdown","source":["# <font color=\"silver\">価値推定│動的計画法</font><br>\n","> - <font color=\"silver\">Description</font><br>\n"," - 動的計画法\n","   - 方策反復法\n","     - 方策反復法とは、方策評価と方策改善を繰り返して、よりよい方策を得ることを目指す方法。 状態価値$V(s)$を使って方策$\\pi$を改善し（方策改善）、その方策$\\pi$を用いて状態価値$V(s)$をを更新する（方策評価）。<br>\n","     - 方策$\\pi$が良い方策であるほど、状態価値$V(s)$は大きくなると考えられるため、状態価値$V(s)$によって方策$\\pi$の良さを評価できることになる。ある方策に対する状態価値$V(s)$を計算することを方策評価という。<br>\n",">$V_0 \\rightarrow V_1 \\rightarrow V_2 \\rightarrow \\ldots \\rightarrow V_k \\rightarrow V_{k+1} \\rightarrow \\ldots \\rightarrow V^\\pi$<br><br>\n",">$\\pi_0 \\xrightarrow[]{E} V^{\\pi_0} \\xrightarrow[]{I} \\pi_1 \\xrightarrow[]{E} V^{\\pi^1} \\xrightarrow[]{I}  ... \\xrightarrow[]{I} \\pi^* \\xrightarrow[]{E} V^{*}$<br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://julien-vitay.net/lecturenotes-deeprl/2-tabular/3-DP.html)</font><br><br>\n","> <img src=\"https://julien-vitay.net/lecturenotes-deeprl/_images/iterativepolicyevaluation2.png\" Height=\"160\">\n","> <img src=\"https://julien-vitay.net/lecturenotes-deeprl/_images/gpi.png\" Height=\"120\">　<img src=\"https://wikidocs.net/images/page/164384/dynamicprogramming.png\" Height=\"120\"><br><br><br>\n","     - 方策反復法の価値更新</font><br>\n","       - 方策評価, Policy evaluation</font><br>\n","状態ベルマン方程式で評価<br><br>\n","$\\displaystyle V^{\\pi} (s)  = \\sum_{a \\in \\mathcal{A}(s)} \\pi(s\\mid a) \\, \\sum_{s' \\in \\mathcal{S}} p(s' | s, a) \\, [ r(s, a, s') + \\gamma \\, V^{\\pi} (s') ]$<br><br>\n","       - 方策改善, Policy improvement</font><br>\n","行動ベルマン最適方程式で最大化<br><br>\n","$\\displaystyle \\pi(s) \\leftarrow \\text{argmax}_a Q^{\\pi} (s, a) = \\sum_{s' \\in \\mathcal{S}} p(s' | s, a) \\, [r(s, a, s') + \\gamma \\, V^{\\pi}(s') ] $<br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://www.data-artist.com/contents/reinforcement-learning.html)</font><br>\n","<img src=\"https://www.data-artist.com/assets/images/contents/reinforcement-learning/reinforcement-learning-img08.jpg\" width=\"480\">\n","   - 価値反復法\n","     - 価値反復法とは、状態価値$V(s)$の更新だけを行うことで、よりよい方策を得ることを目指す方法で、価値関数をもとに行動を選択し、試行を繰り返すことで価値関数を更新していく学習手法。<br>\n","     - 更新式は、maxが入ることで$V(s)$について解けないが、 価値関数を最大化する行動は最適な行動であることから、間接的に最適方策がわかる。<br>\n","     - 方策反復法における方策評価と方策改善の処理を1つに結合した考え方になっており、方策反復法に比べ、方策評価と方策改善の繰り返し処理がない分、計算コストが小さい。<br>\n","     - 状態価値$V(s)$の更新が終わったら、最後に最適方策$\\pi$を求める。\n","     - 価値反復法の価値更新</font><br>\n","状態ベルマン最適方程式で最大化<br><br>\n","     ><font color=\"black\">$\\displaystyle V_{k+1}(s) = \\max_a \\sum_{s'} p(s' | s,a) [r(s, a, s') + \\gamma \\, V_k(s') ]$</font><br><br>\n","   - 動的計画法の<font color=\"Blue\">課題</font><br>\n","     - 環境ダイナミクス（状態遷移確率$p$と報酬関数$r$）が既知の場合のみにしか使えない。迷路問題などで使用可能。例えば、車の運転ではそもそも未来の状態がわからないので、価値反復法は使えない。<br>\n","     - 環境ダイナミクス（状態遷移確率$p$と報酬関数$r$）が未知のときは、報酬関数$r$のサンプリングを行い、価値関数の更新を繰り返して、真の価値関数に近い推定価値関数を得る（モデルフリー）。<br><br>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://shirakonotempura.hatenablog.com/entry/2019/02/08/162541)</font><br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/shirakonotempura/20190208/20190208085231.png\" width=\"480\"><br>\n"],"metadata":{"id":"kIcMzIBhN1XF"}},{"cell_type":"markdown","source":["# <font color=\"silver\">価値推定│Monte-Carlo Methods</font><br>\n","> - <font color=\"silver\">Description</font><br>\n"," - モンテカルロ法\n","   - 遷移のサンプルを取得し、収益を平均化することによって、価値関数を推定する方法。サンプルを沢山取得し、そこから平均を求めるという計算を行うため、「モンテカルロ」という名前がついている。<br>\n","   - 推定した価値関数によって方策を評価する。価値関数の改善と方策の改善とを組み合わせることによって、最適方策を見つけることができる。<br>\n","   - 価値関数の改善または方策の改善は、エピソード終了後に行われる。<br>\n","   - サンプル取得においては、全ての状態行動対が無限回訪問されることを仮定する。これを開始点探査(exploring starts, ES)の仮定と呼ぶ。<br><br>\n","$\\displaystyle  V^π(s)= \\mathbb{E}_π[R_t|s_t=s] ≈  \\frac{1}{M} \\sum_{e=1}^M R_t^{(e)}$<br><br>\n","$V(s_t) = V(s_t) + \\alpha \\, (R_t - V(s_t))$<br><br>\n","$Q(s_t, a_t) = Q(s_t, a_t) + \\alpha \\, (R_t - Q(s_t, a_t))$<br><br>\n"," - 方策オンの価値更新</font><br>\n","   - 偏ったサンプリングによる局所解を取るリスクを回避するために、greedy方策ではなく、「ε-greedy方策」又は「ソフトマックス方策」を使用する。<br><br>\n","$\\begin{split}\\pi(s_t, a) = \\begin{cases} 1 - \\epsilon \\; \\text{if} \\; a = \\text{argmax}\\, Q(s, a) \\\\\n","\\frac{\\epsilon}{|\\mathcal{A(s_t)}-1|} \\; \\text{otherwise.} \\\\\n","\\end{cases}\\end{split}$<br><br>\n","$\\pi(s, a) = \\cfrac{\\exp Q(s, a) / \\tau}{ \\sum_b \\exp Q(s, b) / \\tau}$<br><br>\n"," - モンテカルロ法の課題</font><br>\n","   - エピソードが有限でないと使用できない。エピドートが終了を待たないと価値関数や方策を更新することができない。例えば、囲碁だと勝ち負けが決まると終了、テトリスだと負けなければ終わりがない。<br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://www.data-artist.com/contents/reinforcement-learning.html)</font><br>\n","<img src=\"https://www.data-artist.com/assets/images/contents/reinforcement-learning/reinforcement-learning-img09b.jpg\" width=\"480\">"],"metadata":{"id":"RPxRSOtTUl9G"}},{"cell_type":"markdown","source":["# <font color=\"silver\">価値推定│Temporal Difference learning</font><br>\n","> - <font color=\"silver\">Description</font><br>\n"," - TD法\n","   - 価値の更新をひたすら繰り返すという方法であり、この点は価値反復法と考え方が似ている。行動価値関数に関するベルマン方程式を試行錯誤の経験によって解くためのアルゴリズムといえる。<br>\n","   - 同じ予測値でも、より未来の情報を使うほど真の値に近いという仮定で、任意のステップのサンプリング報酬 $R_{t+n}$ と任意のステップ先の状態価値 $V_t(S_{t+n})$ から状態価値 $V_{t+1}(S)$ を計算する→モンテカルロ法のブートストラップ。<br>\n","   - 経験していない「状態と行動の組み合わせ」に対する行動価値関数は更新されないことになる。➡ 探索しないと更新されない。<br>\n","   - ステップ毎に行動価値関数を更新していくため、経験をすぐに次の行動に生かすことができる。結果が出るまでの道のりが長い、寄り道が多い場合に有効な手法である<br>\n","   - 初期の価値が学習されにくいなどのデメリットがある<br><br>\n","$\\begin{aligned}\n","V(S_t) &\\leftarrow (1- \\alpha) V(S_t) + \\alpha G_t \\\\\n","V(S_t) &\\leftarrow V(S_t) + \\alpha (G_t - V(S_t)) \\\\\n","V(S_t) &\\leftarrow V(S_t) + \\alpha (R_{t+1} + \\gamma V(S_{t+1}) - V(S_t))\n","\\end{aligned}$<br><br>\n","同様に<br><br>\n","$Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha (R_{t+1} + \\gamma Q(S_{t+1}, A_{t+1}) - Q(S_t, A_t))$<br><br>\n","\n",">| MC  |  TD  |\n","| ---- | ---- | \n","|  報酬が確定してから学習 |  1ステップごとに学習  |  \n","|  確実に終了する環境のみ  |  終端が存在しない環境でもOK  |  \n","|  バイアスが全くないが、バリアンスが高い  |  バイアスが多少存在するが、バリアンスは低い  |  \n","|  初期値の影響をあまり受けない  |  初期値の学習への影響が大きい  |  \n","|  マルコフ性を利用しない  |  マルコフ性を利用する  |  \n"],"metadata":{"id":"9bzB1KgfUNAc"}},{"cell_type":"markdown","source":["# <font color=\"silver\">価値推定│SalsaとQ学習</font><br>\n","> - <font color=\"silver\">Description</font><br>\n","  - 方策オン型:SARSA</font><br>\n","    - エピソードの更新方策と価値関数の更新方策が同じであり、行動価値関数Qの更新は行動の決定結果に依存する。<br>\n","    - 行動価値関数を更新する際、行動価値の小さな探索結果も考慮されやすいという利点があるが、計算が不安定になりやすい。<br>\n","    - 常に最適行動を選択すると（greedyな方策）、リスクを取ってより最適な方策を探索することができないため、一定の確率ϵでランダムな行動をとるという方策（ϵ-greedy方策）に従って価値を更新する（方策オン型）。価値関数の更新にランダム性を取り入れているため局所解に陥りにくい<br>\n","    - 方策オン型:SARSAの価値更新<br><br>\n",">$Q(s_t, a_t) = Q(s_t, a_t) + \\alpha \\, (r_{t+1} + \\gamma \\, Q(s_{t+1}, a_{t+1})  - Q(s_t, a_t))$<br><br>\n","$\\begin{split}\\pi(s_t, a) = \\begin{cases}1 - \\epsilon \\; \\text{if} \\; a = \\text{argmax} \\, Q(s_t, a) \\\\\\frac{\\epsilon}{|\\mathcal{A}(s_t) -1|} \\; \\text{otherwise.} \\\\ \\end{cases}\\end{split}$<br><br>\n","  - 方策オフ型:Q学習</font><br>\n","    - エピソードの更新方策と価値関数の更新方策が同じとは限らない方式で、行動価値関数Qの更新は行動の決定結果に依存しない。<br>\n","    - 行動価値関数を更新する際、探索の影響を受けにくいため計算が安定的に行えるという利点があるが、行動価値の小さな探索結果は反映されにくい。<br>\n","    - Sarsaは一定の確率ϵでランダムな行動をとるという方策（ϵ-greedy方策）であるのに対し、Q学習はmax関数によって最も価値の高い行動を一律に選択する（greedyな方策）。ただし、s'から実際に進む次の行動は、価値関数更新時にmax関数によって求めた行動ではなく、ϵ-greedy方策により求める。実際に進む行動（方策）と価値関数の更新に用いる行動（方策）が異なる（方策オフ型）。<br>\n","    - 方策オフ型:Q学習の価値更新<br><br>\n",">$Q(s_t, a_t) = Q(s_t, a_t) + \\alpha \\, (r_{t+1} + \\gamma \\, \\max_a Q(s_{t+1}, a) - Q(s_t, a_t))$<br><br>\n","$\\begin{split}\\pi(s_t, a) = \\begin{cases}1\\; \\text{if} \\; a = \\text{argmax} \\, Q(s_t, a) \\\\ 0 \\; \\text{otherwise.} \\\\ \\end{cases}\\end{split}$<br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://wikidocs.net/174556)</font><br>\n","<img src=\"https://wikidocs.net/images/page/169313/22_SARSA_vs_Q_Learning.png\" width=\"480\"><br>"],"metadata":{"id":"kIGnDFiEA1Wy"}},{"cell_type":"markdown","source":["# <font color=\"silver\">価値推定│更新手法まとめ</font><br>\n","><font color=\"silver\">モンテカルロ法</font><br>\n",">$\\displaystyle Q(s_t, a_t) \\leftarrow Q(s_t, a_t) + \\alpha \\, (R_t - Q(s_t, a_t))$<br><br>\n","><font color=\"silver\">Sarsa</font><br>\n",">$\\displaystyle Q(s_t, a_t) = Q(s_t, a_t) + \\alpha \\, (r_{t+1} + \\gamma \\, Q(s_{t+1}, a_{t+1})  - Q(s_t, a_t))$<br><br>\n","><font color=\"silver\">Q-learning</font><br>\n",">$\\displaystyle Q(s_t, a_t) = Q(s_t, a_t) + \\alpha \\, (r_{t+1} + \\gamma \\, \\max_a Q(s_{t+1}, a) - Q(s_t, a_t))$<br><br>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://lilianweng.github.io/posts/2018-02-19-rl-overview/)</font><br>\n","<img src=\"https://lilianweng.github.io/posts/2018-02-19-rl-overview/TD_MC_DP_backups.png\" width=\"720\"><br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://trafalbad.hatenadiary.jp/entry/2019/04/25/225639)</font><br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/trafalbad/20190425/20190425221709.png\" width=\"480\">"],"metadata":{"id":"J9rWHAMubP9Z"}},{"cell_type":"markdown","source":["# <font color=\"silver\">価値推定│appendix, Algorithmまとめ\n","><font color=\"silver\">方策反復法</font><br>\n","> <img src=\"https://lcalem.github.io/imgs/sutton/policy_iteration.png\" width=\"640\"><br>\n","><font color=\"silver\">価値反復法</font><br>\n","><img src=\"https://lcalem.github.io/imgs/sutton/value_iteration.png\" width=\"640\"><br>\n","><font color=\"silver\">モンテカルロ法</font><br>\n","><img src=\"https://lcalem.github.io/imgs/sutton/mc_es.png\" width=\"640\">\n","><font color=\"silver\">SALSA</font><br>\n","><img src=\"https://lcalem.github.io/imgs/sutton/sarsa_algo.png\" width=\"640\"><br>\n","><font color=\"silver\">Q学習</font><br>\n","><img src=\"https://lcalem.github.io/imgs/sutton/qlearning.png\" width=\"640\">"],"metadata":{"id":"ZL7S228PKpS0"}},{"cell_type":"markdown","source":["# <font color=\"silver\">DQN [<font color=\"silver\">…](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4537&cid=b0f01606242a6ed3&CT=1671102964232&OR=ItemsView)<br></font>"],"metadata":{"id":"ds4mk_OG4GhU"}},{"cell_type":"markdown","source":["# <font color=\"silver\">DQN│Q Network\n","</font><br><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://wikidocs.net/1745363)</font><br>\n","<img src=\"https://wikidocs.net/images/page/169312/20_Q_Network.png\" width=\"480\">　<img src=\"https://wikidocs.net/images/page/169311/20_Q_Table.png\" width=\"480\"><br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://wikidocs.net/1745363)</font><br>\n","<img src=\"https://wikidocs.net/images/page/169311/Fig_20.jpeg\" width=\"640\"><br><br>\n","<img src=\"https://wikidocs.net/images/page/172178/algorithm_train_step.png\" width=\"640\"><br><br>\n","<img src=\"https://wikidocs.net/images/page/169312/21_Q_Network.png\" width=\"640\"><br>"],"metadata":{"id":"4jal545u_RXr"}},{"cell_type":"markdown","source":["# <font color=\"silver\">DQN│DQN\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://towardsdatascience.com/diving-into-deep-reinforcement-learning-with-deep-q-learning-376e588bb803)<br>\n","<img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*G2x9_EQxrwdT25Pw1q8ISg.png\" width=\"320\">\n","<img src=\"https://lilianweng.github.io/posts/2018-02-19-rl-overview/agent_environment_MDP.png\" width=\"320\"><br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://wikidocs.net/174607)</font><br>\n","<img src=\"https://wikidocs.net/images/page/169315/Diagram_Nature2015.png\" width=\"640\"><br><br>\n","\n","\n","\n","\n"],"metadata":{"id":"8Zztyb-MMp-2"}},{"cell_type":"markdown","source":["# <font color=\"silver\">DQN│Experience Replay</font><br>\n","<font color=\"silver\">Experience Replay, 体験再生</font>\n","> - <font color=\"silver\">Description</font><br>\n"," - DQN\n","   - 体験再生\n","     - 従来のQ学習のように1ステップごとにそのステップの内容（experience）を学習するのではなく、メモリに各ステップの内容を保存しておき、メモリから内容をランダムに取り出して（replay）、ニューラルネットワークに学習させる方法<br><br>\n","     - 各ステップごとにそのステップの内容を学習すると、時間的に相関が高い内容（つまり時刻tの学習内容と時刻t+1の学習内容はとても似ている）をニューラルネットワークが学習するので、学習が安定しづらいという問題。<br><br>\n","     - 「入力データが時系列データであり、入力データ間に独立性がない」という問題。時系列データは、近い時間のデータが似通ってしまうため、相関性の強い系列となる。 強い相関性をもつ入力系列に対して学習を行うと、直近の入力に引きずられてパラメータが修正されるため、過去の入力に対する推定が悪化し、収束性が悪くなる。<br><br>\n","     - パラメータの更新時に同じ経験を何回も学習に使えるため、計算量の大きなエピソードの進行の回数を抑制できる。<br><br>\n","     - ランダムに取り出された経験を用いて損失を計算するため、入力系列の相関を断ち切り、更新の分散を軽減できる。強い相関性を持つ入力系列に対して学習を行うと、直近の入力に引きずられてパラメータが修正されるため、過去の入力に対する推定が悪化し収束性が悪くなるが、体験再生では経験をランダムに取り出すため、系列の相関を断ち切ることができる。これにより、パラメータの振動や発散を避けることができる。<br><br>\n","     -  過去のさまざまな状態で行動分布が平均化されるため、直前に取得したデータが次の行動の決定におよbす影響を軽減できる。<br><br>\n","$\\displaystyle L(\\theta) = {\\mathbb E}_{s,a,s',r～ D} \\left[\\left(r + \\gamma\\max_{a'} Q(s', a';\\theta^-)-Q(s,a;\\theta) \\right)^2\\right]$\n","<br><br>\n","Q-learning</font><br>\n",">$\\displaystyle Q(s_t, a_t) = Q(s_t, a_t) + \\alpha \\, (r_{t+1} + \\gamma \\, \\max_a Q(s_{t+1}, a) - Q(s_t, a_t))$<br><br>\n","$\\mathbb{E}_{s,a,r,s'\\sim D}$<font color=\"silver\">：ランダムサンプリングされたデータを用いて学習する</font><br>\n","$r + \\gamma \\max_{a'}Q(s',a';\\theta) $<font color=\"silver\">：目標値（教師信号）, 過去のある時点のパラメータ$Θ$での行動価値関数Qが最大になる行動$α$を求める</font><br>\n","$Q(s,a;\\theta) $<font color=\"silver\">：NNの出力</font>\n","<br><br>\n","<img src=\"https://miro.medium.com/max/828/1*Du1AnMnIEq85EJYh6GmFCA.png\" width=\"640\">"],"metadata":{"id":"LiWraQ-m4Jd1"}},{"cell_type":"markdown","source":["# <font color=\"silver\">DQN│Target Q-Network</font><br>\n","> ※  一定期間の間、目標値の計算に用いる価値関数ネットワークのパラメータを固定し、一定周期でこれを更新することで学習を安定させる。<br><br>\n","> ※  主となるmain-networkとは別に、誤差関数で使用する行動価値を求めるtarget-networkを用意し、Q学習で使用するmaxa Q(st+1, a)の値はtarget-networkから求める。このtarget-networkは少し前の時間のmain-networkを使用するようにする。<br><br>\n","> ※  ニューラルネットワークの学習に、そのニューラルネットワークの出力を使用すると学習が安定しづらいという問題が存在する。Fixed Target Q-Networkはこれを解決する。Fixed Target Q-Networkはミニバッチ学習を行うことで実装する。<br><br>\n","> ※  「価値関数が小さく更新されただけでも選ばれる行動が大きく変わってしまう」という問題。学習の目標値(教師信号)算出に用いるネットワークと、行動価値Qの推定に用いるネットワークが同じ場合、学習ごとに行動価値関数を更新すると目標値(教師信号)も変化してしまい、学習が不安定になる。"],"metadata":{"id":"l5leAysy4Mp_"}},{"cell_type":"markdown","source":["# <font color=\"silver\">DQN│報酬のclipping\n","> ※ 各ステップで得られる報酬を-1, 0, 1のいずれかに固定しておく方法。こうすることで、ゲーム内容（学習対象）によらず、同じハイパーパラメータでディープラーニングを実行しやすくなり、ゲームごとに学習率を調整する必要がなくなった。<br><br>\n","> ※ ゲームの種類によって得点の範囲が異なるため、報酬のスケールが与えられたタスクによって異なる。このままだと、学習が不安定になる。報酬の代償を区別できなくなるデメリットはあるものの、学習が安定するメリットのほうが大きい。\n"],"metadata":{"id":"wEoAJpVXgQE8"}},{"cell_type":"markdown","source":["# <font color=\"silver\">DQN│Huber損失</font><br>\n","> ※ 誤差が-1~1の間は二乗誤差の値となり、-1より小さいときや1より大きいときには誤差の絶対値をとる関数。<br><br>\n","> ※ 誤差が大きい場合に二乗誤差を使用すると、誤差関数の出力が大きくなりすぎて学習が安定しづらいという問題が存在する。Huber関数はこの問題を解決する工夫。<br><br>\n","${\\begin{equation}\n","L_\\delta (a) = \n","\\begin{cases}\n","\\cfrac{1}{2}a^2 & |a|\\leqq 1 \\\\\n","\\delta (|a| - \\cfrac{1}{2}\\delta) & \\text{上記以外}\n","\\end{cases}\n","\\end{equation}\n","}$\n","<br><br>\n","$a$<font color=\"silver\">：誤差</font>\n","<br><br>\n","<img src=\"https://book.mynavi.jp/files/user/manatee/rensai/019_kyoukagakusyuu/14/huber.JPG\" width=\"320\">\n"],"metadata":{"id":"UcqF5LwW4P-1"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">方策勾配法 [<font color=\"silver\">…](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4581&cid=b0f01606242a6ed3&CT=1668173197315&OR=ItemsView)<br></font>"],"metadata":{"id":"tibwtW-lOVx-"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">方策勾配法│方策勾配法<br></font>\n","> - <font color=\"silver\">Description</font><br>\n"," - 方策勾配法\n","   - 体験再生状態と行動の集合が有限で、かつマルコフ性を仮定すると、有限回の反復で最適な方策に収束する<br><br>\n","   - 方策勾配法の目的関数<br>\n","初期ステップからの期待累積和を最大化する<br><br>\n","$\\displaystyle J(\\theta) = \\sum_{s \\in \\mathcal{S}} d^\\pi(s) \\sum_{a \\in \\mathcal{A}} \\pi_\\theta(a \\vert s) Q^\\pi(s, a)$\n","       - 導出<br>\n","       $\\displaystyle {J(θ;s_{0}) = E[G_{0}|S_{0}=s_{0}] = E\\left[\\sum_{t=1}^{∞}\\gamma^{t-1}R_{t}|S_{0}=s_{0}\\right]}$<br><br>\n","$\\displaystyle J(\\theta) = \\mathbb{E}_{\\pi_\\theta} [r]\n","= \\sum_{s \\in \\mathcal{S}} d^\\pi(s) V^\\pi(s) \n"," = \\sum_{s \\in \\mathcal{S}} d^\\pi(s) \\sum_{a \\in \\mathcal{A}} \\pi_\\theta(a \\vert s) Q^\\pi(s, a)$<br><br>\n","   - 方策勾配定理<br><br>\n","$\\displaystyle\\nabla J(\\theta)  = \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s; \\theta) Q_\\pi(s, a)]$<br><br>\n","       - 導出　対数の微分の公式を用いて変形する $(\\log x)' = \\frac{1}{x}$</font><br><br>\n","$\\displaystyle{\\nabla} \\log \\pi(\\theta) \n","= \\frac{\\partial \\log \\pi(\\theta)}{\\partial \\theta} \n","= \\frac{1}{\\pi(\\theta)}\\frac{\\partial \\pi(\\theta)}{\\partial \\theta} \n","= \\frac{{\\nabla}\\pi(\\theta)}{\\pi(\\theta)}$\n","<br><br>\n",">$\\begin{aligned}\n","\\nabla J(\\theta) &= \\sum_{s \\in \\mathcal{S}} d(s) \\sum_{a \\in \\mathcal{A}} \\nabla \\pi(a \\vert s; \\theta) Q_\\pi(s, a) \\\\\\\\\n","&= \\sum_{s \\in \\mathcal{S}} d(s) \\sum_{a \\in \\mathcal{A}} \\pi(a \\vert s; \\theta) \\frac{\\nabla \\pi(a \\vert s; \\theta)}{\\pi(a \\vert s; \\theta)} Q_\\pi(s, a) \\\\\\\\\n","& = \\sum_{s \\in \\mathcal{S}} d(s) \\sum_{a \\in \\mathcal{A}} \\pi(a \\vert s; \\theta) \\nabla \\log \\pi(a \\vert s; \\theta) Q_\\pi(s, a) \\\\\\\\\n","& = \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s; \\theta) Q_\\pi(s, a)]\n","\\end{aligned}$<br><br>\n","   - パラメータ更新<br><br>\n","${\\begin{align}θ^{t+1} & = θ^{t} + {\\eta}{\\nabla}_{θ}J(θ)\\\\\\\\\n","& = θ^{t} + {\\eta}\\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s, \\theta) Q_\\pi(s, a)]\\end{align}}$<br><br>\n","   - その他<br>\n","$\\displaystyle d^{\\pi_\\theta}(s) = \\sum_{k=0}^{\\infty} \\gamma^k P^{\\pi_\\theta} (s_k = s|s_0)$\n","<br><br>\n","$d^{\\pi_\\theta}(s)$：<font color=\"Silver\">$s_0$から開始して方策$\\pi_\\theta$に従って行動した場合どれだけ頻繁に状態$s$を訪れるかを表す（割引率$\\gamma$で割引付き）。<br></font>\n","$P^{\\pi_\\theta} (s' \\mid s)$：<font color=\"Silver\">状態の推移の確率。</font>\n","<br><br>\n","\n"],"metadata":{"id":"4oDx0OFG3DXp"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">方策勾配法│確率的方策</font><br>\n","> <font color=\"Blue\">状態と行動が離散</font><br>\n","> ソフトマックス関数</font><br><br>\n",">$𝜋_{θ}(a|s) = {\\displaystyle\\frac{exp(θ_{sa})}{\\sum_{b{\\in}A}exp(θ_{sb})}}\n","$\n","<br><br>\n","> <font color=\"Blue\">状態が連続で行動が離散</font><br>\n","> 線形関数＋ソフトマックス関数</font><br><br>\n",">$\\displaystyle 𝜋_{θ}(a|s)= {\\frac{exp(θ^{\\rm{T}}\\Phi(s,a))}{\\sum_{b{\\in}A}exp(θ^{\\rm{T}}\\Phi(s,b))}}$\n","<br><br>\n","><font color=\"Blue\">状態と行動が連続</font><br>\n",">ガウス分布</font><br><br>\n",">$\\displaystyle𝜋_{θ}(a|s) = {\\frac{1}{(2𝜋)^{\\frac{d_{a}}{2}}|C|^{\\frac{1}{2}}}}exp(-\\frac{1}{2}(a-Ws)^{T}C^{-1}(a-Ws))$\n"],"metadata":{"id":"SVeDomJ4sp7q"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">方策勾配法│モンテカルロ近似</font><br>\n","> ※ $\\nabla_\\theta\\log\\pi_\\theta(a|s)$は解析的に求められない。<br>\n","> ※ そのため、$\\pi_\\theta$に基に基づいて経験したサンプルを用いて近似する<br><br>\n",">${\\begin{align}\n","\\nabla J(\\theta) &\\propto \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s, \\theta) Q_\\pi(s, a)]\\\\\\\\\n","& \\approx \\frac{1}{N}\\sum_{n=1}^{N}\\frac{1}{T}\\sum_{t=1}^{T}\n","\\nabla_\\theta\\log \\pi_\\theta(a_t^n|s_t^n)Q^\\pi(a_t^n|s_t^n)\n","\\end{align}}$\n","<br><br>\n","$N$<font color=\"Silver\">：エピソード数<br></font>\n","$T$<font color=\"Silver\">：ステップ数<br></font>\n"],"metadata":{"id":"bejmZ9gp5RSA"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">方策勾配法│REINFORCE</font>\n","> ※ $\\nabla_\\theta\\log\\pi_\\theta(a|s)$は解析的に求められない。<br>\n","> ※ そのため、$\\pi_\\theta$に基づいて経験したサンプルを用いて近似する<br><br>\n",">${\\begin{align}\n","\\nabla J(\\theta) &\\propto \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s, \\theta) Q_\\pi(s, a)]\\\\\\\\\n","& \\approx \\frac{1}{N}\\sum_{n=1}^{N}\\frac{1}{T}\\sum_{t=1}^{T}\n","\\nabla_\\theta\\log \\pi_\\theta(a_t^n|s_t^n)Q^\\pi(a_t^n|s_t^n)\n","\\end{align}}$\n","<br><br>\n","エピソード的タスクは収益で近似する：$\\displaystyle Q^\\pi(a_t^n|s_t^n) = \\sum_{k=1}^{T}r_k^n $\n","<br><br>\n","連続タスクはある時刻$t$で得られた即時報酬$ r_t $で近似する：$\\displaystyle Q^\\pi(a_t|s_t) \\approx r_t $\n","<br><br>\n","$N$<font color=\"Silver\">：エピソード数<br></font>\n","$T$<font color=\"Silver\">：ステップ数<br></font>"],"metadata":{"id":"z-9NqWKZ6syB"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">方策勾配法│REINFORCE with baseline</font>\n","> ※ 勾配推定時の分散を小さくする目的で導入する<br>\n","> ※ 推定したQ関数の分散が大きく学習が進みにくいので同じような分布を持つ関数との差分を取ることで勾配の報酬系列部分の分散を抑える工夫<br><br>\n",">${\\begin{align}\n","\\nabla J(\\theta) &= \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s, \\theta) Q_\\pi(s, a)]\\\\\\\\\n","& = \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s, \\theta) Q_\\pi(s, a)-b(s)]\n","\\end{align}}$\n"],"metadata":{"id":"Zwm0sxo_5Wzu"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">方策勾配法│Advantage</font>\n","> ※ ベースラインを価値関数$V_\\pi(s)$とすることである状態において行動がどれほど有利か測りやすくする<br><br>\n",">${\\begin{align}\n","\\nabla J(\\theta) &= \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s, \\theta) Q_\\pi(s, a)-b(s)]\\\\\\\\\n","& = \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s, \\theta) Q_\\pi(s, a)- V_\\pi(s)]\\\\\\\\\n","& = \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s, \\theta) A_\\pi(s,a)]\n","\\end{align}}$"],"metadata":{"id":"Y-6lZEpm8lZJ"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">Actor-Critic  [<font color=\"silver\">…](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!5885&cid=b0f01606242a6ed3&CT=1671857145700&OR=ItemsView)<br></font>\n"],"metadata":{"id":"InRA5oBJ8jyj"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">Actor-Critic│Actor-Critic</font>\n","<img src=\"https://julien-vitay.net/lecturenotes-deeprl/_images/actorcritic.png\" width=\"240\"><img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*G2x9_EQxrwdT25Pw1q8ISg.png\" width=\"320\"><img src=\"https://lilianweng.github.io/posts/2018-02-19-rl-overview/agent_environment_MDP.png\" width=\"320\"><br><br>\n","<img src=\"https://dl.acm.org/cms/attachment/9cc9fc4e-8c50-4576-b956-9ace7483d392/icpp20-69-fig6.jpg\" width=\"320\"><br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://wikidocs.net/175903)</font><br>\n","<img src=\"https://wikidocs.net/images/page/169326/AC_vs_PG_2.png\" width=\"480\"><br><br>\n","<img src=\"https://wikidocs.net/images/page/169326/42_Actor_Critic_0.png\" width=\"640\"><br><br>"],"metadata":{"id":"slNDmn8trZ1_"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">Actor-Critic│Algorithm</font>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://julien-vitay.net/lecturenotes-deeprl/3-MF/3-PG.html#)</font><br>\n","<img src=\"https://julien-vitay.net/lecturenotes-deeprl/_images/policygradient.svg\" width=\"480\"><br><br>\n"," <font color=\"Silver\">Policy Gradient</font><br>\n","$\\displaystyle\\nabla \\mathcal{J}  = \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s; \\theta) Q_\\pi(s, a)]$<br><br>\n"," <font color=\"Silver\">REINFORCE</font><br>\n","$\\displaystyle\\nabla \\mathcal{J}  = \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s; \\theta) R_t]$<br><br>\n"," <font color=\"Silver\">REINFORCE with baseline</font><br>\n","$\\displaystyle\\nabla \\mathcal{J}  = \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s; \\theta) R_t-b]$<br><br>\n"," <font color=\"Silver\">advantage actor-critic</font><br>\n","${\\begin{align}\n","\\nabla \\mathcal{J} \n","& = \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s, \\theta) A_\\pi(s,a)]\\\\\\\\\n","& = \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s, \\theta) Q_\\pi(s, a)- V_\\pi(s)]\\\\\\\\\n","& = \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s, \\theta) \\sum_{i=0}^{k-1}{ \\gamma^i R_{t+i} } + \\gamma^k V_{\\pi}(s_{t+k})- V_\\pi(s_t)]\n","\\end{align}}$<br><br>\n","$\\begin{split}\n","\\begin{eqnarray*}\n","    R_t &=& r_{t+1} + \\gamma \\, r_{t+2} +  \\gamma^2  \\, r_{t+3} + \\dots + \\gamma^k \\, r_{t+k+1} + \\dots \\\\\n","        &=& r_{t+1} + \\gamma \\, ( r_{t+2} +  \\gamma \\, r_{t+3} + \\dots + \\gamma^{k-1} \\, r_{t+k+1} + \\dots) \\\\\n","        &=& r_{t+1} + \\gamma \\,  R_{t+1} \\\\\n","\\end{eqnarray*}\n","\\end{split}$<br><br>\n","$\\displaystyle R_t = r_{t+1} + \\gamma r_{t+2} + \\dots = \\sum_{k=0}^{\\infty} \\gamma^k r_{t+k+1}$<br><br>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://julien-vitay.net/lecturenotes-deeprl/3-MF/3-PG.html#)</font><br>\n","<img src=\"https://julien-vitay.net/lecturenotes-deeprl/_images/policygradient.svg\" width=\"480\"><br><br>\n","「Criticの出力である状態価値」と 「kステップ先読みした収益」の差の2乗<br>\n"," <font color=\"Silver\">Monte-Carlo critic</font><br>\n","$\\mathcal{L}(\\varphi) =  \\mathbb{E}_{s \\sim \\rho_\\theta, a \\sim \\pi_\\theta}[(R(s, a) - Q_\\varphi(s, a))^2]$<br><br>\n"," <font color=\"Silver\">SARSA critic</font><br>\n","$\\mathcal{L}(\\varphi) =  \\mathbb{E}_{s, s' \\sim \\rho_\\theta, a, a' \\sim \\pi_\\theta}[(r + \\gamma \\, Q_\\varphi(s', a') - Q_\\varphi(s, a))^2]$<br><br>\n"," <font color=\"Silver\">Q-learning critic</font><br>\n","$\\mathcal{L}(\\varphi) =  \\mathbb{E}_{s, s' \\sim \\rho_\\theta, a \\sim \\pi_\\theta}[(r + \\gamma \\, \\max_{a'} Q_\\varphi(s', a') - Q_\\varphi(s, a))^2]$<br>"],"metadata":{"id":"VmILFfHheeP0"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">Actor-Critic│A3C</font>\n","> - Description<br>\n"," -  Actor-Critic<br>\n","   - 複数エージェントが別々の経験を積む（サンプルを並列的に生成）\n","   - パラメータの更新を非同期に行う\n","   - 報酬は、現時点の方策を用いて計算する。行動価値を計算する際に、方策を用いるので、方策オン型に位置付けられる\n","   - 方策勾配法を用いる\n"," -  Actor<br>\n","   - 行動を決める部分(方策)\n","   - Actor 側の損失を計算する際には、方策勾配を用いる<br>\n","   - ⾏動価値関数を$k$ステップ先読みした収益で推定する<br><br>\n","$\\displaystyle{ Q^{\\pi}(s_{t}, a_{t}) = \\sum_{i=0}^{k-1}{ \\gamma^iR_{i+1} } + \\gamma^k V^{\\pi}(s_{t+k}) }$<br><br>\n","   ${\\begin{align}\n","\\nabla J(\\theta) \n","&= \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s, \\theta) Q_\\pi(s, a)]\\\\\\\\\n","& = \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s, \\theta) A_\\pi(s,a)]\\\\\\\\\n","& = \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s, \\theta) Q_\\pi(s, a)- V_\\pi(s)]\\\\\\\\\n","& = \\mathbb{E}_{\\pi_\\theta} [\\nabla \\log \\pi(a \\vert s, \\theta) \\sum_{i=0}^{k-1}{ R^i_{t+i} } + \\gamma^k V_{\\pi}(s_{t+k})- V_\\pi(s)]\n","\\end{align}}$\n","<br><br>\n"," -  Critic<br>\n","   - 状態価値を推定する部分\n","   - Critic 側の損失を計算する際には、「Criticの出力である状態価値」と\n","「kステップ先読みした収益」の差の2乗の偏微分を用いる <br>\n","   - kステップ先読みした収益<br><br>\n","$\\displaystyle{ Q^{\\pi}(s_{t}, a_{t}) = \\sum_{i=0}^{k-1}{ r^i_{t+i} } + \\gamma^k V^{\\pi}(s_{t+k}) }$<br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://gri-blog.hatenablog.com/entry/2021/08/07/172955)</font><br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/g/gri-blog/20210807/20210807172341.png\" width=\"320\">\n","<br><br>\n","パラメータサーバー$\\overset{\\rm 重み}{\\longrightarrow}$ワーカー$\\overset{\\rm 勾配}{\\longrightarrow}$パラメータサーバー$\\overset{\\rm 重み}{\\longrightarrow}$ワーカー$\\overset{\\rm 勾配}{\\longrightarrow}$"],"metadata":{"id":"MY3aRhOEZnSQ"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Actor-Critic│appendix, スライド資料</font>\n","[<font color=\"black\">DL_appendix_for_E_ver_6_0](https://drive.google.com/drive/folders/1urKprW9bw_0PLgTPpGoQCRqjozrekXeR)<br>"],"metadata":{"id":"Ga63NIZZeStc"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">AlphaGo  [<font color=\"silver\">…](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4602&cid=b0f01606242a6ed3&CT=1671551705341&OR=ItemsView)<br></font>\n"],"metadata":{"id":"2Vq-cqRkP0JG"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">AlphaGo│AlphaGo\n",">[<font color=\"Blue\">$\\tiny{\\rm speakerdeck}$…</font>](https://speakerdeck.com/neungkl/algorithm-behind-alphago-and-alphago-zero)</font></font><br>\n"," - Architecture<br>\n","   - Rollout（人間対戦データ）\n","   - SL policy network（人間対戦データ）<br>\n","   $\\displaystyle\\Delta\\sigma = \\frac{\\alpha}{m} \\sum_{k=1}^m \\frac{\\partial \\log p_\\sigma(a^k | s^k)}{\\partial \\sigma} $<br>\n","   - RL policy network（自己対戦）<br>\n","   $\\displaystyle\\Delta\\rho = \\frac{\\alpha}{n} \\sum_{i=1}^n \\sum_{t=1}^{T^i} \\frac{\\partial \\log p_\\rho (a_t^i | s_t^i)}{\\partial \\rho}$ <br>\n","   - Value network（RL policy）<br>\n","   $\\displaystyle\\Delta \\theta = \\frac{\\alpha}{m} \\sum_{k=1}^m (z^k - v_\\theta(s^k)) \\frac{\\partial v_\\theta(s^k)}{\\partial \\theta}$ <br><br>\n","<img src=\"https://julien-vitay.net/lecturenotes-deeprl/_images/alphago.png\" width=\"800\"><br><br>\n"],"metadata":{"id":"j5fRhqV0_llC"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">AlphaGo│AlphaGo Zero\n","\n","> - Description<br>\n"," - AlphaGoの4つのDNN（ロールアウト方策、SL方策、RL方策、価値）を1つの**デュアルネットワーク**にした\n"," - 層をより深く**40層**にした\n"," - 探索木において、$Q(s,a)$の計算にロールアウトによる評価（$N_r(s,a)$と$W_r(s,a)$）をやめたため、探索をより深く行えるようになった。\n","> - Architecture<br><br>\n","<img src=\"https://julien-vitay.net/lecturenotes-deeprl/_images/alphazero.jpg\" width=\"480\">"],"metadata":{"id":"RPTYjq9Y6QHR"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">AlphaGo│SL policy network\n","> ある局面から最適な次の一手を選択。先読みはしない。<br>\n","人間対戦データ利用<br>\n","入力：盤面<br>\n","出力：それぞれの手を選ぶ確率, 囲碁の場合は19×19=361クラス<br>\n","CNNで学習する<br>\n","$\\displaystyle\\Delta\\sigma = \\frac{\\alpha}{m} \\sum_{k=1}^m \\frac{\\partial \\log p_\\sigma(a^k | s^k)}{\\partial \\sigma} $<br>\n","$\\alpha$：<font color=\"Silver\">学習率<br></font>\n","$a$：<font color=\"Silver\">行動（手）<br></font>\n","$s$：<font color=\"Silver\">状態（盤面）<br></font>\n","$m$：<font color=\"Silver\">ミニバッチのサイズ<br></font>"],"metadata":{"id":"ZgzqUtnCAxYu"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">AlphaGo│RL policy network\n",">自己対戦<br>\n","構造はSL方策ネットワークと同じ、初期値はステップ1で学習したパラメータ<br>\n","方策勾配法<br>\n","$\\displaystyle\\Delta\\rho = \\frac{\\alpha}{n} \\sum_{i=1}^n \\sum_{t=1}^{T^i} \\frac{\\partial \\log p_\\rho (a_t^i | s_t^i)}{\\partial \\rho}$ <br>\n","$T^i$：<font color=\"Silver\">$i$番目の対戦の最終タイムステップ</font><br>\n","$z_i^t$：<font color=\"Silver\">$i$番目の対戦のタイムステップ$t$における報酬</font>"],"metadata":{"id":"WpNxPzjmDBuC"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">AlphaGo│Value network\n",">入力：盤面<br>\n","出力：勝つ確率（-1から1）<br>\n","勾配降下法<br>\n","$\\displaystyle\\Delta \\theta = \\frac{\\alpha}{m} \\sum_{k=1}^m (z^k - v_\\theta(s^k)) \\frac{\\partial v_\\theta(s^k)}{\\partial \\theta}$ <br>\n","教師あり、データを作るために対戦する<br>\n","$t = 1, \\ldots, U - 1$の時間ステップではSL方策ネットワークで手を選ぶ<br>\n","$t = U$は乱数的に手を選ぶ<br>\n","$t = U+1, \\ldots, T$はRL方策ネットワークで手を選ぶ"],"metadata":{"id":"3hdoj6FDBu0f"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">AlphaGo│モンテカルロ木探索</font><br>\n","> - Rollout<br>\n","  - ある局面から黒番と白番が互いに手を選んで終局まで進める<br>\n","Logistic回帰で次の手を予測する<br><br>\n","> - 選択（Selection）<br>\n","  - 行動選択基準<br><br>\n","$\\displaystyle a_t = \\underset{a}{{\\rm argmax}}(Q(s_t, a) + u(s_t, a))$<br><br>\n","$\\displaystyle u(s_t, a) = c_\\text{puct}P(s,a)\\frac{\\sqrt{\\sum_b N_r(s,b)}}{1 + N_r(s,a)}$<br><br>\n","未探索のノードへの探索を促進する信頼上限<br>\n","多く訪問した手の採用確率を低くし、探索を広くする<br>\n","$c_\\text{puct}$：<font color=\"Silver\">定数</font><br>\n","$P(s,a)$：<font color=\"Silver\">SL方策ネットワークによって算出される事前確率</font><br>\n","$N_r(s,a)$：<font color=\"Silver\">ロールアウト回数</font><br><br>\n","> - 展開（Expansion）<br>\n","  - 訪問回数が閾値を超えたら、$s$から行動した結果の状態$s'$を探索木に追加する<br><br>\n","> - 評価（Evaluation）<br>\n","  - 価値ネットワークとロールアウトで報酬を計算する<br>\n","勝ったら1<br>\n","負けたら-1<br><br>\n","> - 記録（Backup）<br>\n","  - 統計量を更新する<br>\n","負けた回数$n_{rl}$<br>\n","葉で価値ネットワークで評価した回数$N_v(s,a)$<br>\n","$N_v(s,a)$回の評価に対する行動価値の総和$W_v(s,a)$<br>\n","ロールアウトの訪問回数$N_r(s,a)$<br>\n","$N_r(s,a)$回の訪問に対する行動価値の総和$W_r(s,a)$<br>\n","行動価値：$\\displaystyle Q(s,a) = (1 - \\lambda) \\frac{W_v(s,a)}{N_v(s,a)} + \\lambda \\frac{W_r(s,a)}{N_r(s,a)}$<br><br>\n","繰り返しの探索が終了したら、**最も訪問回数が多い**行動を次の指してに採用する<br><br>\n","<img src=\"https://livedoor.blogimg.jp/lunarmodule7/imgs/3/f/3f071266.png\" width=\"800\">"],"metadata":{"id":"FaI01sV6SnnL"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">AlphaGo│MCTSのAlgorithm</font><br>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://www.researchgate.net/figure/Phases-of-the-Monte-Carlo-tree-search-algorithm-A-search-tree-rooted-at-the-current_fig1_312172859)</font><br>\n","<img src=\"https://www.researchgate.net/profile/George-Konidaris/publication/312172859/figure/fig1/AS:613954925625373@1523389669557/Phases-of-the-Monte-Carlo-tree-search-algorithm-A-search-tree-rooted-at-the-current.png\" width=\"640\"></font><br>\n","> - Selection</font><br>\n",">  - ルートから始めて、子ノードを選択していきます。選択基準には複数あります。<br>\n","> - Expansion</font><br>\n",">  - 選択したノードから、次のノードをどれにするか選択します。シミュレーション後の結果をもとに展開します。<br>\n","> - Simulation</font><br>\n",">  - 一様分布などランダムにノードを選択していきリーフノードまで計算を行います。このSimulation何度も繰り返します。playout又はrolloutと呼ばれます。<br>\n","> - Backup</font><br>\n",">  - シミュレーションで得られた最終結果をもとに評価値を更新していきます。この図では(勝った回数) / (試行回数)となっており、最終的に勝つことができたノードほど選択されやすくなります。<br><br>\n","この操作を繰り返していくことで、木を拡大していきます。十分なシミュレーション回数を行うと、よりよい探索を行うことができるようになります。"],"metadata":{"id":"u6vy8l877o_M"}},{"cell_type":"markdown","source":["# <font color=\"silver\">距離学習 [<font color=\"Silver\">…](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!5887&cid=b0f01606242a6ed3&CT=1671333345265&OR=ItemsView)</font><br>\n","<font color=\"Silver\">距離学習, Metric Learning</font><br>"],"metadata":{"id":"EWr_xeyqLgOc"}},{"cell_type":"markdown","source":["# <font color=\"silver\">距離学習│SiameseNet<br></font>\n","> - Description<br>\n"," -  SiameseNet<br>\n","   - 入力されたペアについて、同じクラスに属するか、異なるクラスに属するかを\n","識別するモデルを学習する。\n","   - ラベル予測では、最も類似度の高いクラスを予測クラスとして返す\n","追加学習なしで one-shot ラベル予測タスクに利用可能\n","   - クラス数が多く,各クラスのサンプル数が少ない場合にも適用可能\n","   - <font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://copypaste-ds.hatenablog.com/entry/2019/03/01/164155)</font><br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/c/copypaste_ds/20190226/20190226204013.png\" width=\"640\"><br><br>\n"," -  SiameseNetの学習<br>\n","   - <font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/gesogeso/items/547079f967d9bbf9aca8#siamese-network)</font><br>\n","<img src=\"https://camo.qiitausercontent.com/447af5cbe4ba3d88703f97eeebd714ba8616a06f/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3530383539312f38376430313866302d326365352d366238662d663165302d3234616266316666333537302e706e67\" width=\"640\">\n","<br><br>\n","$L_{\\rm Contrastive}((x_i, x_j);f) = t_{ij}d_{ij} + (1-t_{id})(m - d_{ij})$<br><br>\n","$d_{ij} = ||f(x_i) - f(x_j) ||^2_2$<br><br>\n"," -  SiameseNetの損失関数<br>\n","   - Contrastive Loss<br><br>\n","$L=\\cfrac{1}{2} \\left(Yd^2+(1-Y)\\max(m-d, 0)^2 \\right)$\n","<br><br>\n","$Yd^2$：<font color=\"silver\">類似ペアの距離を小さくする</font><br>\n","$(1-Y)\\max(m-d, 0)^2$：<font color=\"silver\">非類似ペアの距離をマージンに近づける</font><br>\n","$d$：<font color=\"silver\">二つの埋め込みベクトルの距離</font><br>\n","$Y$：<font color=\"silver\">ベクトルの関係を表すラベル（類似=1、非類似=0）</font><br>\n","$m$：<font color=\"silver\">マージン（類似ペアとして扱われる距離の最大値）</font><br><br>\n"," -  SiameseNetの目的関数<br>\n","   - 損失関数を最小にするパラメータを求める<br>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/gesogeso/items/547079f967d9bbf9aca8#siamese-network)</font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F508591%2F97e293d3-2a29-c755-75eb-8649fc65c1aa.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=619ccf049d2d20e38b03767b74f3770d\" width=\"640\"><br>\n","  -  SiameseNetの<font color=\"blue\">課題</font>\n","   - <font color=\"Blue\">コンテキスト</font><br>\n","       - ２つの画像を近づけたいのか、遠ざけたいのかはコンテキストを考慮する必要がある<br>\n","       - Triplet Loss は、類似ペアと非類似ペアを同時に与えることで\n","この問題を解決している\n","       - Siamese Network では 2 つのサンプルが同じ・違うものというコンテキストを固定する必要があるが、Triplet Network では「アンカーサンプルが残り 2 つのサンプルのどちらにより類似しているか」という基準で学習できるため、学習時のコンテキストに関する制約が緩和されている。\n","   - <font color=\"Blue\">正負の不均衡</font><br>\n","       - 負のペアはマージンを超えた時点で最適化が終了するのに対して、正のペアは単一点に埋め込まれるまで最適化し続けてしまう。これによって正負で不均衡が生じてしまう。<br>"],"metadata":{"id":"iJfHAni-_Ga8"}},{"cell_type":"markdown","source":["# <font color=\"silver\">距離学習│TripletNet<br></font>\n","> - Description<br>\n"," -  TripletNet<br>\n","   - 基準画像、同じクラスの別画像、異なるクラスの画像の 3 つの画像が\n","入力されるネットワークに対して適用される\n","   - 同じクラスどうしをより近く、異なるクラスどうしをより遠ざけるように\n","埋め込みベクトルを学習する<br>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://copypaste-ds.hatenablog.com/entry/2019/03/01/164155)</font><br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/c/copypaste_ds/20190226/20190226205158.png\" width=\"640\"><br><br>\n"," -  TripletNetの学習<br>\n","   - <font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/gesogeso/items/547079f967d9bbf9aca8#siamese-network)</font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F508591%2Fdce7182c-975c-e800-cb37-da2266474fe5.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=36e3f85f698bcd869a42326c76bd3c8b\" width=\"640\">\n","<br><br>\n","$L_{\\rm triplet}((x_a,x_p,x_n);f) = max(0, d_{a, p} + m - d_{a, n})$\n","<br><br>\n","$d_{a,p} = ||f(x_{a}) - f(x_{p})||^2_2$\n","<br><br>\n","$d_{a,n} = ||f(x_{a}) - f(x_{n})||^2_2$<br><br>\n"," -  TripletNetの損失関数<br>\n","   - Triplet Loss</font><br><br>\n",">$L = [d_p- d_n + \\alpha]_+$\n","<br><br>\n",">${\\rm where}[z]_+ = \\max(z, 0)$\n","<br><br>\n","$\\alpha$<font color=\"silver\">：マージンの大きさを決める正の値であり、ハイパーパラメータ</font><br><br>\n"," -  TripletNetの目的関数<br>\n","   - 損失関数を最小にするパラメータを求める<br><br>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/tancoro/items/35d0925de74f21bfff14)</font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F146511%2F9ff66afc-6827-8b4d-f2f0-4a43f1d3512b.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=0c30f31262c8285c7494b2dece898c11\" width=\"320\"><br>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/gesogeso/items/547079f967d9bbf9aca8#siamese-network)</font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F508591%2F5e06b83e-2e05-595d-a073-60b3dae066dd.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=449b24354a605cf8979a80612fcf55c1\" width=\"640\"><br>\n","  -  TripletNetの<font color=\"blue\">課題</font>\n","   - 考えうる入力の組み合わせが膨大にあり、かつ学習に連れてその殆どがパラメタ更新に影響を及ぼさなくなるため、学習が停滞してしまう ➡ FaceNetのTriplet Selection<br>"],"metadata":{"id":"kvOyS7-O_Rgj"}},{"cell_type":"markdown","source":["# <font color=\"silver\">距離学習│Triplet Selection<br>\n","\n",">  ※ mini-batchの中だけでTripletを構築して、Semi-hard Negativeの条件 $d_p \\leqq d_n < d_p + \\alpha$ を満たすもののみをランダムに利用していく方法<br><br>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/tancoro/items/35d0925de74f21bfff14)</font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F146511%2Fd9b6e3a8-1150-a9d6-f360-3e09334c8f77.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=394aeadaf02be0adf3a25e84638aff1e\" width=\"480\"><br><br>\n","><font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/gesogeso/items/547079f967d9bbf9aca8#siamese-network)</font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F508591%2F4f214cb4-4f3a-2376-14f5-500a9c709ff6.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=fb0ddd444c44b4536c147b328853b279\" width=\"720\">\n","<br>"],"metadata":{"id":"3vXvZMcrEmpr"}},{"cell_type":"markdown","source":["# <font color=\"silver\">距離学習│appendix, Network比較</font>\n","$L_{\\rm Contrastive}((x_i, x_j);f) = t_{ij}d_{ij} + (1-t_{id})(m - d_{ij})$<br><br>\n","$d_{ij} = ||f(x_i) - f(x_j) ||^2_2$<br><br>\n","$L_{\\rm triplet}((x_a,x_p,x_n);f) = max(0, d_{a, p} + m - d_{a, n})$<br><br>\n","$d_{a,p} = ||f(x_{a}) - f(x_{p})||^2_2$<br><br>\n","$d_{a,n} = ||f(x_{a}) - f(x_{n})||^2_2$<br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://copypaste-ds.hatenablog.com/entry/2019/03/01/164155)</font><br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/c/copypaste_ds/20190226/20190226204013.png\" width=\"480\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/c/copypaste_ds/20190226/20190226205158.png\" width=\"480\"><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/tancoro/items/35d0925de74f21bfff14)</font><br>\n","<img src=\"https://camo.qiitausercontent.com/2158806ff15234ef07a1590a5e8400b9b2add1bd/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3134363531312f34366532313661662d653738612d666633392d333833642d6233313230336230363861622e706e67\" width=\"480\">\n","<img src=\"https://camo.qiitausercontent.com/cee403b38920370871730d798a391bf0bbbeee2d/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3134363531312f61313435633835372d386361392d656631392d313163312d3538633135313134346238322e706e67\" width=\"480\">\n","<br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://qiita.com/gesogeso/items/547079f967d9bbf9aca8#siamese-network)</font><br>\n","<img src=\"https://camo.qiitausercontent.com/447af5cbe4ba3d88703f97eeebd714ba8616a06f/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3530383539312f38376430313866302d326365352d366238662d663165302d3234616266316666333537302e706e67\" width=\"480\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F508591%2Fdce7182c-975c-e800-cb37-da2266474fe5.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=36e3f85f698bcd869a42326c76bd3c8b\" width=\"480\">\n"],"metadata":{"id":"1nn6bwqN39IP"}},{"cell_type":"markdown","source":["# <font color=\"silver\">距離学習│appendix, スライド資料</font>\n","[<font color=\"black\">DL_appendix_for_E_ver_6_0](https://drive.google.com/drive/folders/1OhdMb4UNH12KcO9XRrp5bmC1npED4Vvd)<br>"],"metadata":{"id":"UUiWSK2KGQVQ"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">MAML [<font color=\"Silver\">…](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!5901&cid=b0f01606242a6ed3&CT=1671523399048&OR=ItemsView)</font><br>"],"metadata":{"id":"gp9ClnqK0SMv"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">MAML│MAML</font><br>\n","<font color=\"Silver\">MAML, Model-Agnostic Meta-Learning, マムル</font>\n","> - Description<br><font color=\"red\">\n"," -  <font color=\"red\">MAML\n","   -  <font color=\"red\">少ないパラメータ更新で未知のタスクを学習できるModel-Agnostic（モデルに依存しない）なアルゴリズムを持っている<br>\n","   -  回帰問題や分類問題，そして強化学習といった様々なタスクに対応できる一般的なモデル<br>\n","   -  勾配法によって重みの初期値を探索するため、inner-learning の損失関数が微分可能である必要がある<br>\n","   -  innerとouterの学習がある。勾配の勾配。<br>\n","   - メタ学習は、数個の訓練データのみ学習して新しいタスクを解く Few-shot learning によって汎化性能を測ることが多い。<br><br>\n","  -  ファインチューニングとの違い\n","     -  <font color=\"red\">inner-learning が複数(ファインチューニングは inner-learning がひとつのみ)\n","     -  検証データに対する勾配を計算し、パラメータ(の初期値)を更新\n","     -  ファインチューニングにおける初期値は、あくまで、あるひとつの\n","inner-learning タスクの訓練損失の最小化しか考慮されていない（汎化性能が優れた初期値とは限らない、ということ）\n","  -  MAMLの利点と課題\n","    -  利点\n","      -  <font color=\"red\">追加パラメータを必要としない\n","      -  (微分可能な)任意のモデルを利用できる\n","      -  様々なタスクに適用できる\n","    -  課題\n","      -  メモリ・計算効率の悪さ\n","      -  複数の勾配ステップにおける<br><br></font>\n"," -  MAMLのAlgorithm<br>\n","   -  モデル$\\,f_\\theta\\,$のパラメータ$\\,\\theta\\,$を初期化<br>\n","while：not done に対して実行<br>\n","$\\qquad$タスク分布からタスクをサンプリングする$\\,\\mathcal T_i \\sim p (\\mathcal T)\\,$<br>\n","$\\qquad$for：$\\,\\mathcal T_i\\,$に対して実行<br>\n","$\\qquad\\qquad$$\\,K\\,$個のデータに対する勾配$\\, \\nabla_{\\theta}\\mathcal{L}_{\\mathcal T_i}(f_\\theta)\\,$を算出<br>\n","$\\qquad\\qquad$勾配降下法を用いて、パラメータを更新する：$\\, \\theta_i' = \\theta - \\alpha \\nabla_{\\theta}\\mathcal{L}_{\\mathcal T_i}(f_\\theta)\\, $<br>\n","$\\qquad$end for：<br>\n","$\\qquad$全体のパラメータ$\\,\\theta\\,$を更新 $\\,\\theta \\leftarrow \\theta - \\beta \\nabla_\\theta \\sum_{\\mathcal T_i \\sim p(\\mathcal T)} \\mathcal L_{\\mathcal T_i} (f_{\\theta_i'})\\,$<br>\n","end while：<br><br>\n","<img src=\"https://nryotaro.dev/maml.png\" width=\"480\"><br><br>\n","   -  MAMLの目的関数<br><br>\n",">$\\begin{align}\n","\\theta &= {\\rm arg}\\min_\\theta \\sum_{\\mathcal T_i \\sim p(\\mathcal T)} \\mathcal L_{\\mathcal T_i}(f_{\\theta_i'}) \\\\\\\\\n","&= {\\rm arg}\\min_\\theta \\sum_{\\mathcal T_i \\sim p(\\mathcal T)} \\mathcal L_{\\mathcal T_i}(f_{\\theta - \\alpha \\nabla_{\\theta}\\mathcal{L}_{\\mathcal T_i}(f_\\theta)})\n","\\end{align}$<br><br>\n","   -  MAMLのパラメータ更新<br><br>\n","$\\,\\displaystyle\\theta \\leftarrow \\theta - \\beta \\nabla_\\theta \\sum_{\\mathcal T_i \\sim p(\\mathcal T)} \\mathcal L_{\\mathcal T_i} (f_{\\theta_i'})\\,$<br><br>\n"],"metadata":{"id":"hC4nBPVbEl_7"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MAML│appendix, 1703.03400</font>\n",">https://arxiv.org/pdf/1703.03400.pdf<br>\n","[<font color=\"Blue\">$\\tiny{\\rm [論文解説]}$…</font>](https://qiita.com/ku2482/items/ee2fd87bbb5353664f59)</font></font><br>\n","> - Description<br>\n"," -  Figure 2：回帰の検証\n","    - 振幅($0.1\\sim5.0$)と位相($0 \\sim \\pi$)を持った$\\sin$カーブからサンプリングされたデータを用いて，元の$\\sin$カーブの形を推定するタスク\n","    - $K = \\{5, 10\\}$として，$K$個のデータ点を用いて勾配更新を行った際の結果\n","    - MAMLでは，$K=5$の時，かつ定義域の半分のみにデータが集中しているようなサンプルについても，ある程度回帰できている。また、定義域のもう半分でもきちんと予測できていることから，振幅や位相とは別の要素，$sin$カーブの周期性をMeta-Learningによって学習することができている。一方で、Pretrainedではうまく回帰できていない。<br><br>\n","<img src=\"https://camo.qiitausercontent.com/25f2560f23f920a598d8806f4f17c84b8a32eccd/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3234383535322f34623835306535322d396235622d323836372d336634372d6165306531303430313266352e706e67\"  width=\"640\"><br>\n"," -  Table 1：クラス分類の検証<br>\n","    - Few-shot learning によるクラス分類タスクでの Accuracy を MAML と他の Few-shot learning 手法で比較した結果<br>\n","    - 5-way・20-way はそれぞれ 5 クラス・20 クラスからサンプルしていることを表す\n","    - 1-shot・5-shot はそれぞれ 1 枚・5 枚の画像をサンプルして学習しているこ\n","とを表す\n","    - 1-shot・20-way における Accuracy は MAML が最も高い\n","    - 1-shot・5-way における Accuracy は neural statistician より MAML(ours) の方が高い\n","    - 5-shot・20-way における Accuracy は Siamese nets より MAML(ours) の方が高い<br><br>\n","<img src=\"https://d3i71xaburhd42.cloudfront.net/f50a38cf2db71ca6746980615cd7b6eb69541820/7-Table1-1.png\"  width=\"640\"><br>\n"," -  Figure 5：強化学習の検証<br><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F248552%2F2bea4dc6-b62b-3d33-8553-0713b04335c6.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=993e4eb0896c8863f542ef7597daac28\"  width=\"640\"><br>"],"metadata":{"id":"2050S6Rt11Pr"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MAML│appendix, スライド資料</font>\n","[<font color=\"black\">DL_appendix_for_E_ver_6_0](https://drive.google.com/drive/folders/1wHf2oaMWUfN6WtpMLAyhiUOvou_L-R8p)"],"metadata":{"id":"gvyqsbedDSZs"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">LIME, SHAP [<font color=\"Silver\">…](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!5113&cid=b0f01606242a6ed3&CT=1669092070120&OR=ItemsView)</font><br>"],"metadata":{"id":"x1JeNF8hO0Z1"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">LIME, SHAP│加法的特徴帰属法<br></font>\n","<font color=\"Silver\">Additive Feature Attribution Methods, 加法的特徴帰属法</font>\n","\n","> - Description<br>\n"," -  加法的特徴帰属法\n","   -  <font color=\"Blue\">$\\tiny{\\rm Link}$ [<font color=\"Blue\">…</font>](https://speakerdeck.com/smorce/shap-lime-pdp-grad-cam?slide=10) </font><br>\n","   -  特徴量の線形関数を用いた機械学習の解釈手法のこと<br>\n","   -  線形回帰モデルの解釈が容易なことから、機械学習モデルにおいても各データに対して特徴量と予測結果の線形モデルを作り、特徴量が予測に与える影響を定量評価しようとする手法<br>\n","   -  元の特徴量$\\,x_i\\,$から、その特徴量の存在有無を示す1or0のバイナリ値$\\,z_i\\,$に代えて扱う<br>\n","<br>\n","$\\displaystyle g(z^{'})=\\phi_{0}+\\sum_{i=1}^{M}\\phi_{i}z_{i}^{'}$\n","<br><br>\n","$z_{i}^{'}$<font color=\"Silver\">：元の特徴量$x_i$の存在有無を示すバイナリ値</font><br>\n","$g(z^{'})$：<font color=\"Silver\">元の予測モデル$\\,f(x)\\,$に対する局所的な代替モデル</font><br>\n","$\\phi_{i}$：<font color=\"Silver\">特徴量$\\,i\\,$の有無によってどれだけ最終的な予測結果に影響があるか, 各特徴量の重要度, 貢献度<br>"],"metadata":{"id":"lgOr9m0v9LKX"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">LIME, SHAP│SHAPの主定理<br></font>\n","> - Description<br>\n","   -  SHAPの主定理<br>\n","      -  <font color=\"Blue\">$\\tiny{\\rm Link}$ [<font color=\"Blue\">…</font>](https://speakerdeck.com/smorce/shap-lime-pdp-grad-cam?slide=12) [<font color=\"Blue\">…</font>](https://speakerdeck.com/hightensan/lime-and-shap-ji-jie-xue-xi-moderuniyoruyu-ce-jie-guo-falseshuo-ming-xing?slide=26) </font>  [<font color=\"Blue\">…</font>](https://qiita.com/perico_v1/items/fbbb18681ecc362a4f9e#shap%E3%81%AE3%E3%81%A4%E3%81%AE%E6%80%A7%E8%B3%AA) </font><br>\n","      -  法的特徴帰属法に求められる 3 つの性質を提示\n","      -  局所的正確性・欠落性・一貫性を満たす説明モデルはひとつだけ存在する<br><br>\n","      -  <font color=\"Blue\">Local Accuracy, 局所的正確性</font><br>\n","          -  ある入力を $x$、 $x$ の予測を $f(x)$ とする。また、単純化した入力データを  $x´$、$x´$ に対する局所的近似を $f´(x´)$ とする。このとき、$f(x)$ と $f´(x´)$ は同じになる。<br><br><font color=\"black\">\n","$\\displaystyle f(x)=g(x^{'})=\\phi_{0}+\\sum_{i=1}^{M}\\phi_{i}x_{i} ^{'}$<br><br>\n","      -  <font color=\"Blue\">Missingness, 欠落性</font><br>\n","          -  シンプルな入力において 0 である特徴量は予測結果に影響を与えない。<br>\n","          -  予測結果に影響を与えないような特徴量は、その予測に対して貢献をしていない。<br><br>\n","$x_{i}^{'}=0\\Rightarrow \\phi_{i}=0$<br><br>\n","      -  <font color=\"Blue\">Consistency, 一貫性</font><br>\n","          -  ある特徴 の有無の影響が、モデル$f$の出力よりもモデル$f´$の出力の方が大きいとき、その特徴量に対する重みは、モデル$f$よりもモデル$f´$の方が大きくなる<br>\n","          -  $f$ のほうが $f´$ よりもある特徴量$x_i$が有るか無いかによって出力値に大きな変化があるならば、$f$ のほうが $f´$ よりも貢献度が大きくなる\n","</font><br><br>\n","$ f_\\boldsymbol{x}'(\\boldsymbol{z}') -   f_\\boldsymbol{x}'(\\boldsymbol{z}'\\backslash i)\n","  \\geq f_\\boldsymbol{x}(\\boldsymbol{z}') -   f_\\boldsymbol{x}(\\boldsymbol{z}'\\backslash i) \\ \\ \\mathrm{for \\ all \\ inputs } \\ \\boldsymbol{z}' \\in \\{0,1\\}^M$\n","のとき、<br><br>\n","$\\phi_i(f', \\boldsymbol{x}) \\geq \\phi_i(f, \\boldsymbol{x})$\n","\n"],"metadata":{"id":"Cbsmzx_7y6Ez"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">LIME, SHAP│LIME</font><br>\n","<font color=\"Silver\"> LIME, Local Interpretable Model-Agnostic Explanation</font>\n","> - Description<br>\n"," -  LIMEの解釈\n","       -  以下のコラージュ画像 (a) を Inception という CNN のモデルに入力すると、予測結果は\n","エレキギター:32%、アコースティックギター:24%、ラブラドールレトリバー:21%\n","       -  この予測結果に対し、LIME を用いると、画像のどの部分を根拠にクラス分類したかを説明できる<br><br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/k/kentaPt/20211206/20211206222812.png\"  width=\"480\"><br><br>\n","       -  データ一つに対する分類器による予測結果に対して、どうして分類が行われたのかを説明する<br><br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/g/gat-chin321/20170107/20170107164420.png\"  width=\"480\"><br><br>\n","       -  分類器がどういう性質を持っているのかを説明する<br><br>\n","<img src=\"https://d3ansictanv2wj.cloudfront.net/figure2-802e0856e423b6bf8862843102243a8b.jpg\"  width=\"480\"><br><br>\n"," -  LIME\n","   -  <font color=\"Blue\">$\\tiny{\\rm Link}$ [<font color=\"Blue\">…</font>](https://qiita.com/takotatsu5141/items/eab63331aec5aea2c3f8#lime)  [<font color=\"Blue\">…</font>](https://qiita.com/saltcooky/items/21f2ad17c32e5c3b710f#lime)<br><br></font>\n","   -  深層学習でも SVM でもランダムフォレストでも線形回帰でも何でもOKな、モデルを選ばない, model-agnostic に推論根拠を説明できる局所的な説明手法。<br>\n","   -  ある説明したいインスタンスがあった時に、そのインスタンス周辺のブラックボックスな学習済みモデル $f$ の挙動を解釈可能な局所的近似モデル $g$ で近似して説明を行う。<br>\n","   -  <font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://pesuchin.hatenablog.com/entry/2017/01/07/170859)</font><br>\n","   <img src=\"https://c3.ai/wp-content/uploads/2020/10/Lime1.png\" width=\"480\"><br><br>\n","   -  <font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://pesuchin.hatenablog.com/entry/2017/01/07/170859)</font><br>\n","   <img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/g/gat-chin321/20170106/20170106191925.png\" width=\"480\"><br><br>\n"," -  LIMEのAlgorithm<br>\n","   -  近似モデル $g$ を$f$ の説明モデル(explanation model)という。\n","   -  $g(x)\\simeq f(x) =  \\phi_{0}+\\phi_{1}z_{1}+\\phi_{2}z_{2}+\\cdots+\\phi_{M}z_{M}$ となるように局所的近似モデル $g$ を構築する\n","   -  $z'$は$z$をシンプルにしたもの\n","   -  係数 $\\phi$ のの絶対値の大小を変数の重要度と解釈する\n","   -  <font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://zenn.dev/r2en/articles/e9281662755dbe39c773)</font><br>\n","   <img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/g/gat-chin321/20170107/20170107152919.png\" width=\"480\"><br><br>\n"," -  LIMEの損失関数<br><br>\n","$f$と$g$との距離を類似度$\\,π_x\\,$で重み付けしたもの</font><br><br>\n","$\\displaystyle L(f,g,\\pi_x )=\\sum_{z,z^{\\prime } \\in Z} \\pi_x (z)(f(z)-g(z^{\\prime } ))^2$<br><br>\n","$\\displaystyle \\pi_x (z) = \\exp\\Bigl(\\frac{-D(x,z)^2}{\\sigma^2}\\Bigr)$<br><br>\n","$z' \\in \\{0,1\\}^d$<font color=\"Silver\">：非ゼロ要素を一部だけ含むサンプリングにより生成された2値のスパースな点</font><br>\n","$z \\in R^d$<font color=\"Silver\">：$\\,z′\\,$を用いて復元された元のサンプルの特徴表現</font><br>\n","$D(x,z)$<font color=\"Silver\">：距離関数</font><br>\n","$\\sigma$<font color=\"Silver\">：カーネル指数</font><br><br>\n"," -  LIMEの目的関数<br><br>\n",">$\\xi (x)=\\mathop{\\rm argmin}\\limits_{g\\in G} L(f,g,\\pi_x )+\\Omega (g)$\n","<br><br>\n","$\\Omega (g)$<font color=\"Silver\">：モデル$\\,g\\,$の複雑さ</font><br>\n","$x$<font color=\"Silver\">：説明したいインスタンス</font><br>\n","$f$<font color=\"Silver\">：説明したいブラックボックスなモデル</font><br>\n","$G$<font color=\"Silver\">：解釈可能なモデルの集合</font><br>\n","$g$<font color=\"Silver\">：解釈可能なモデルの集合$\\,G\\,$のうちの一つのモデル</font><br>\n","\n"],"metadata":{"id":"0FoJ1R75q5Zv"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">LIME, SHAP│SHAP</font>\n","<font color=\"Silver\">SHAP, SHapley Additive exPlanations</font>\n","> - Description<br>\n"," -  SHAPの解釈\n","       -  SVMを用いてアヤメの特徴量（がくと花弁の長さ・幅）からアヤメの品種（setosa，versicolor，virginica）を予測している．SVMのモデルがある入力データに対してsetosaである確率を約97%だと予測しており，Kernel SHAPの結果は，その予測に最も寄与しているのは，「petal length（がくの長さ）= 1.2 cm」であると解釈を与えている<br>\n","       -  <font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://blog.tsurubee.tech/entry/2021/07/19/120541)</font><br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/h/hirotsuru314/20210715/20210715141054.png\"  width=\"640\"><br><br>\n"," -  SHAP\n","   -  <font color=\"Blue\">$\\tiny{\\rm Link}$ [<font color=\"Blue\">…</font>](https://speakerdeck.com/hightensan/lime-and-shap-ji-jie-xue-xi-moderuniyoruyu-ce-jie-guo-falseshuo-ming-xing?slide=24)  [<font color=\"Blue\">…</font>](https://qiita.com/takotatsu5141/items/eab63331aec5aea2c3f8#shap) [<font color=\"Blue\">…</font>](https://qiita.com/perico_v1/items/fbbb18681ecc362a4f9e) [<font color=\"Blue\">…</font>](https://speakerdeck.com/smorce/shap-lime-pdp-grad-cam?slide=9)<br></font>\n","   -  説明したいインスタンスの予測値と、全てのインスタンスの平均との間の差分を、各特徴量ごとの貢献度に分配する手法。<br>\n","   -  協力ゲーム理論におけるシャープレイ値を計算する。<br>\n","   -  シャープレイ値はもともと協力ゲーム理論の分野で、プレイヤーの協力により得られた報酬をどのように公正に分配するかという問題に対して提案された<br>\n","   -  機械学習モデルの解釈においては、各プレイヤーを「機械学習モデルの各特徴量」に、報酬を「モデルの予測平均と予測値の差」に置き換えてシャープレイ値を計算する<br>\n","   -  <font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://blog.tsurubee.tech/entry/2021/07/19/120541)</font><br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/h/hirotsuru314/20210715/20210715215701.png\"  width=\"480\"><br><br>\n"," -  限界貢献度<br>\n","    -  「機械学習モデルの各特徴量 i 」が加わることによって生じる追加的な貢献度を限界貢献度という。\n","    -  限界貢献度は特徴量の追加する順番によって異るため、全ての順列に対して限界貢献度を求め、平均をとったものを特徴量の貢献度として使用する。<br><br>\n","   $f_{x}(S\\cup \\{i\\})-f_{x}(S)$<br><br>\n","   $f_{x}(S)=E[f(x)|x_{S}]$<br><br>\n","$S$：<font color=\"Silver\">モデルで使用されている特徴量の部分集合</font><br><br>\n"," -  シャープレイ値<br>\n","   -  協力ゲーム理論において利益分配の基準として用いられる指標の1つ\n","   -  複数のプレイヤーが協力して得た利益を各プレイヤーの貢献度に応じて分配する際に、どのプレイヤーにどれだけ分配すればよいかを表す\n","   -  プレイヤー $i$ が加わることによって生じる追加的な貢献度を限界貢献度と呼び、この限界貢献度を用いて計算される<br>\n","     -  ただし、全ての順列の組み合わせに対して限界貢献度を求めると計算量が膨大となる。解決策として特徴量 i の追加前の特徴量の組み合わせが同じであれば、限界貢献度が同じことを利用し、全ての組み合わせに対して限界貢献度を求め、組み合わせの出現数に応じて加重平均を計算する。<br>\n","   -  ある予測値に対してある特徴量の シャープレイ値を求めたい場合、全ての組み合わせでその特徴量の限界貢献度を計算し、その計算結果の平均がその特徴量のシャープレイ値となる。<br><br>\n","   $\\displaystyle \\phi_{i}=\\sum_{S\\subseteq N\\setminus \\{i\\}}\\frac{|S|!(n-|S|-1)!}{n!}(f_{x}(S\\cup \\{i\\})-f_{x}(S))$<br><br>\n","$n$：<font color=\"Silver\">特徴量の数</font><br><br>\n"," -  SHAPの派生<br>\n","   - どんなモデルにでも使える SHAP => Kernel SHAP<br>\n","   - 深層学習用の SHAP => Deep SHAP<br>\n","   - 線形モデル向け SHAP => Linear SHAP<br>\n","   - 説明変数の次元が小さいときの高速な SHAP => Low-order SHAP<br>\n","   - 出力が最大値関数になっているときの高速な SHAP => Max-SHAP<br>\n","   -  <font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://www.dinop.com/vc/combination.html)</font><br>\n","<img src=\"https://www.dinop.com/vc/combination.gif\"  width=\"120\"><br><br>"],"metadata":{"id":"LouAHDLm32RM"}},{"cell_type":"markdown","source":["# <font color=\"silver\">LIME, SHAP│appendix, LIMEの概念図</font>\n","\n","<img src=\"https://github.com/marcotcr/lime/raw/master/doc/images/twoclass.png\" width=\"640\">\n","<br>\n","<img src=\"https://github.com/marcotcr/lime/raw/master/doc/images/multiclass.png\" width=\"640\">\n","<br>\n","<img src=\"https://github.com/marcotcr/lime/raw/master/doc/images/tabular.png\" width=\"640\">"],"metadata":{"id":"6y8whDqYXByG"}},{"cell_type":"markdown","source":["# <font color=\"silver\">LIME, SHAP│appendix, スライド資料</font>\n","[<font color=\"black\">DL_appendix_for_E_ver_6_0](https://drive.google.com/drive/folders/1SFakhl6FmfawIzPly7h4o4REOVBjaIgr)"],"metadata":{"id":"x5X3IYnbTIrU"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">CAM [<font color=\"Silver\">…](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!5117&cid=b0f01606242a6ed3&CT=1667069936495&OR=ItemsView)</font><br>\n","<font color=\"Silver\"> Class Activation Mapping, CAM"],"metadata":{"id":"jfsMpc4EKD16"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">CAM│CAM</font><br>\n","<font color=\"Silver\"> CAM, Class Activation Mapping</font>\n","> - Description<br>\n"," -  CAM\n","   -  最後の畳み込み層が出力した特徴量マップに重みをかけて、判断根拠を可視化する手法<br>\n","   -  畳み込みニューラルネットワークが学習した内容を可視化する手法の一種であり、モデルがある画像においてどのピクセルに着目してクラス分類したのかを理解することに役立つ。<br>\n","   -  ネットワークの推論時における貢献度の高い領域をクラス活性マップ, Class Activation Map, Attention map として可視化することができる<br>\n"," -  CAMのAlgorithm<br>\n","   -  ❶ 入力画像をネットワークに入力して>特徴マップを獲得する<br>\n","   -  ❷ 特徴マップに対してGAP</font>を行い、各特徴マップの空間方向に対する平均値を算出する<br> \n","   -  ❸ GAPによる各チャネルに対する平均値を全結合層のユニットの応答値</font>として最終的な認識結果を出力する。<br> \n","   -  ❹ 畳み込み層で得られた特徴マップと特定のクラスにおける特徴マップの各チャネルに対応する全結合層の結合重みを乗算</font>する。<br>\n","   -  ❺ 乗算した特徴マップを全て加算</font>することで，Attention mapを獲得する。<br><br>\n","<img src=\"https://axa.biopapyrus.jp/media/cnn-cam-fig1.png\"  width=\"640\"><br><br>\n"," -  CAMのAlgorithm<br>\n","   -  GAP を行った結果 $F_{k}$<br><br>\n","   $\\displaystyle F_{k} = \\sum_{x, y}f_{k}(x,y)$<br><br>\n","   -  全結合層で計算する、CAM の計算部分は$\\sum_{k}w_{k}^{c}f_{k}(x,y)$<br><br>\n","   $\\displaystyle S_{c} =\\sum_{k}w_{k}^{c}F_{k}=  \\sum_{k}w_{k}^{c}\\sum_{x, y}f_{k}(x,y) = \\sum_{x, y}\\sum_{k}w_{k}^{c}f_{k}(x,y) $<br><br>\n","   -  カテゴリ c の出力値$S_{c}$<br><br>\n","   $\\displaystyle S_{c} = \\sum_{x, y} M_{c}(x,y)$<br><br>\n","   -  クラス$c$に対するAttention map$M_c$<br><br>\n","   $\\displaystyle M_c(x,y)=\\sum_{k}w^{c}_{k}f_{k}(x,y)$<br><br>\n","$w^{c}_{k}$：<font color=\"Silver\">クラス$c$の$k$番目の特徴マップに対する結合重み</font><br>\n","$f_{k}(x,y)$：<font color=\"Silver\">k 番目の特徴量マップ</font><br><br>\n","<font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://zenn.dev/iq108uni/articles/7269a1b72f42be)</font><br>\n","<img src=\"https://storage.googleapis.com/zenn-user-upload/548847652ccf-20220311.png\" width=\"400\">\n","<img src=\"https://storage.googleapis.com/zenn-user-upload/adf0881a4275-20220311.png\" width=\"80\"><font color=\"red\">\n"," -  CAMの課題<br>\n","   -  CAM は、 CNN の出力が GAP + Linear である必要があるという制約がある。<br>\n","   -  CAMは、ネットワークの一部をGAPに置き換える必要があるため、Attention mapを獲得するためにネットワークを学習させる必要がある。<br>\n","   -  CAM は画像分類モデルにしか適用できない</font>"],"metadata":{"id":"rrMM3tXgCJOc"}},{"cell_type":"markdown","source":["# <font color=\"Silver\">CAM│Grad-CAM</font>\n","<font color=\"Silver\"> Gradient-weighted Class Activation Mapping, Grad-CAM</font><br>\n","> - Description<br><font color=\"red\">\n"," -  Grad-CAM\n","   -  CAMは、ネットワークの一部をGAPに置き換える必要があるため、Attention mapを獲得するためにネットワークを学習させる必要がある。一方で、Grad-CAMはネットワークの順伝播時の特徴マップと逆伝播時の勾配を用いてAttention mapを獲得する。<br>\n","   -  学習済みの様々なネットワークからAttention map を獲得することができる。<br>\n","   -  CAMの「GAP+全結合層」の部分を「特徴マップへの勾配の各特徴マップ内の平均」で代用する。<br>\n","   -  Grad-CAM はモデルのバイアスの判断にも使用できます.例えば,医師か看護師かを分類する問題を,入力画像の顔や髪型で判断しているモデルがあれば,モデルおよび学習データセットに性別のバイアスがあることが考えられます</font>\n"," -  Grad-CAMのAlgorithm<br>\n","   -  $y^c$ の $A^k_{ij}$ についての勾配を求める。<br><br>\n","   $\\displaystyle \\frac{\\delta y^c}{\\delta A_{ij}^k}=\\frac{\\partial S_{c}}{\\partial f_{k}(x, y)}$<br><br>   \n","   -  勾配を特徴マップの全要素について GAP (Global Average Pooling) をする。GAPで平均した値を各特徴マップに対する重量度, 重み $a^c_k$ とする。<br><br>\n","$\\displaystyle \\alpha_k^c = \\overbrace{\\frac{1}{Z}\\sum_{i}\\sum_{j}}^{\\text{global average pooling}} \\underbrace{\\frac{\\delta y^c}{\\delta A_{ij}^k}}_{\\text{gradients via backprop}}$<br><br>\n","   -  獲得した重量度, 重み $a^c_k$ で各特徴マップ $A^k_{ij}$ に重み付けして、重み付けした特徴マップを全て加算する, 線形結合, 加重平均。クラス c に寄与した箇所のみに関心があるため,正の値のみを抽出するReLUを用いる。加算した特徴マップにReLUを適用することでAttention mapを獲得する。<br><br>\n","$\\displaystyle L^c_{{\\rm Grad-CAM}} = \\underbrace{{\\rm ReLU}}_{\\text{Pick positive values}}\\left(\\sum_{k} \\alpha_k^c A^k\\right)$<br><br>\n","       -  <font color=\"silver\">$\\tiny\\text{画像引用元}$[<font color=\"silver\">…</font>](https://evaluelog.com/post-129/)</font><br>\n","<img src=\"https://evaluelog.com/blog/wp-content/uploads/2021/02/%E5%9B%B35.png\"  width=\"640\"><br><br>\n","<img src=\"https://github.com/himidev/Lecture/blob/main/11_cnn_pytorch/02_4_grad_cam/grad-cam.png?raw=true\"  width=\"720\">\n","<br><br>\n","<img src=\"https://betashort-lab.com/wp-content/uploads/2020/08/grad_cam1.png\"  width=\"720\">\n"," -  Grad-CAMの定式化<br><br>\n","$\\displaystyle L_{\\text {Grad-CAM}}^{c} = \\operatorname{ReLU} \\left( \\sum_{k} \\alpha_{k}^{c} f_{k}(x, y) \\right)$<br><br>\n","$\\displaystyle \\alpha_{k}^{c} = \\frac{1}{Z}\\sum_{x, y} \\frac{\\partial S_{c}}{\\partial f_{k}(x, y)}$<br><br>\n","$\\displaystyle L_{\\text {Grad-CAM}}^{c}$：<font color=\"Silver\">クラス$c$に対するAttention map</font><br>\n","$\\alpha^{c}_{k}$：<font color=\"Silver\">逆伝播時のクラス$c$に対する$k$番目の勾配に対する重み</font><br>\n","$Z$：<font color=\"Silver\">勾配の空間方向に対する値の数</font><br><br>\n"," -  Grad-CAMの定式化<br><br>\n","$\\displaystyle\\frac{\\delta y^c}{\\delta A_{ij}^k}=\\displaystyle \\frac{\\partial S_{c}}{\\partial f_{k}(x, y)}$<br><br>\n","$\\displaystyle L_{\\text {Grad-CAM}}^{c}=\\operatorname{ReLU}\\left(\\sum_{k} \\alpha_{k}^{c} A^{k}\\right)$<br><br>\n","$\\displaystyle \\alpha^c_k = \\frac{1}{Z} \\sum_i \\sum_j \\frac{\\partial y^c}{\\partial A^k_{ij}}$<br><br>\n","$\\displaystyle L_{\\text {Grad-CAM}}^{c}$：<font color=\"Silver\">クラス$c$に対するAttention map</font><br>\n","$\\alpha^{c}_{k}$：<font color=\"Silver\">逆伝播時のクラス$c$に対する$k$番目の勾配に対する重み</font><br>\n","$Z$：<font color=\"Silver\">勾配の空間方向に対する値の数</font><br>\n","$y^c$：<font color=\"Silver\">クラス$c$に対するスコア</font><br>\n","$A^{k}_{i,j}$：<font color=\"Silver\">$k$番目の特徴マップ（$i$, $j$）の値</font><br><br>\n"," -  Grad-CAMの課題</font><br>\n","   -  <font color=\"RED\">変化に敏感\n","   -  勾配による近似は入力の微小な変化によって大きく変化しやすい<br>\n","   -  判別に寄与しないレベルのノイズでも可視化結果に大きく影響してしまう<br>\n","   -  出力が変わらないのに可視化結果が変わるのは好ましくない<br>\n","   -  勾配を用いずに入出力のみを用いて予測の根拠を可視化したい ➡ Score-CAM<br></font><br><br>\n","import numpy as np<br>\n","import cv2<br>\n","import matplotlib.pyplot as plt<br>\n","from torchvision.models import vgg16<br>\n","from pytorch_grad_cam import GradCAM<br>\n","from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image<br>\n","<br>\n","if __name__ == '__main__':<br>\n","IMAGE_PATH = './input.jpg'<br>\n","rgb_img = cv2.imread(IMAGE_PATH, 1)[:, :, ::-1]<br>\n","rgb_img = cv2.resize(rgb_img, (224, 224))<br>\n","rgb_img = np.float32(rgb_img) / 255<br>\n","input_tensor = preprocess_image(rgb_img, mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])<br><br>\n","model = vgg16(pretrained=True)<br>\n","model.eval()<br>\n","<font color=\"Silver\"># VGGにおいてTabby cat(281)なのにTiger cat(282)と分類した場合<br></font>\n","target_layer = model.features[-1]<br>\n","target_category = 282<br>\n","gradcam = GradCAM(model=model, target_layer=target_layer)<br>\n","grayscale_cam = gradcam(input_tensor=input_tensor, target_category=target_category)<br>\n","grayscale_cam = grayscale_cam[0, :]<br>\n","cam_image = show_cam_on_image(rgb_img, grayscale_cam)<br>\n","cam_image = cv2.cvtColor(cam_image, cv2.COLOR_BGR2RGB)<br>\n","plt.imshow(cam_image, cmap='jet')<br>\n","plt.colorbar()<br>\n","plt.savefig('result.png')<br><br>\n"," - FasterRCNN: model.backbone<br>\n"," - Resnet18 and 50: model.layer4[-1]<br>\n"," - VGG and densenet161: model.features[-1]<br>"],"metadata":{"id":"1pW7PeAqSlub"}}]}