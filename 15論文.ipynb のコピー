{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/group-nai-shomu/00/blob/main/15%E8%AB%96%E6%96%87.ipynb","timestamp":1682401833742}],"collapsed_sections":["ogtjZDMMHYTa","xXPyDeYrHykq","sRQeK_gzH3gT","cd1YDHM5mRIa","o8iceq4lzir4","8GhWXj9e-8Pe","zoCeCcSh9iui"],"authorship_tag":"ABX9TyMBdaugRo73QqGOXHzCwH1Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"0N5d6UIKNDHV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# <font color=\"Blue\">â– </font><font color=\"silver\">GoogLeNet [<font color=\"silver\">â€¦</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4855&cid=b0f01606242a6ed3&CT=1666714515497&OR=ItemsView)</font><br>\n","https://arxiv.org/pdf/1409.4842.pdf<br>"],"metadata":{"id":"oztwAt_m-NHR"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GoogLeNet  1 Introduction èƒŒæ™¯"],"metadata":{"id":"8h1r-NmqCh6X"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GoogLeNet  2 é–¢é€£ç ”ç©¶"],"metadata":{"id":"gUH0i6fQCqPJ"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GoogLeNet  3 Motivation and High Level Considerations"],"metadata":{"id":"X1u_VquHCqk-"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GoogLeNet  4 Architectural Detailse\n","# Inception Module<br>\n","> â€» ç•°ãªã‚‹ã‚µã‚¤ã‚ºã®ç•³ã¿è¾¼ã¿ã‚’ç‹¬ç«‹ã—ã¦è¡Œã£ã¦ã„ã‚‹ãŸã‚ã€éé›¶ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¤§ããæ¸›ã‚‹<br>\n","> â€» å°ã•ãªç•³è¾¼ã¿ãƒ•ã‚£ãƒ«ã‚¿ã‚’ä¸¦åˆ—ã«ä¸¦ã¹ã¦è¿‘ä¼¼ã™ã‚‹ã“ã¨ã¦ã‚™ã€ è¡¨ç¾åŠ›ã¨ãƒã‚šãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®ãƒˆãƒ¬ãƒ¼ãƒˆã‚™ã‚ªãƒ•ã‚’æ”¹å–„<br>\n","> â€» 1Ã—1ã®ç•³ã¿è¾¼ã¿å±¤ã‚’æŒ¿å…¥ã™ã‚‹ã“ã¨ã§ã€æ¬¡å…ƒå‰Šæ¸›ã‚’è¡Œã„ã€ã•ã‚‰ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’å‰Šæ¸›ã—ã¦ã„ã‚‹<br><br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://qiita.com/jun40vn/items/5ac97a6f1d8f82a49194)</font></font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F209705%2F73d58375-38ca-b8f3-49dd-a5dc2b7ea2cd.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=14759e901deefd4e04e04fca3d6832aa\" width=\"320\">\n","<br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://www.researchgate.net/figure/Basic-Inception-v3-structure_fig3_332428603)</font></font>\n","<br>\n","<img src=\"https://www.researchgate.net/publication/332428603/figure/fig3/AS:748134426755072@1555380555179/Basic-Inception-v3-structure.png\" width=\"640\"><br>\n","<br>\n","<img src=\"https://axa.biopapyrus.jp/media/objectclassification_ref_googlenet_02.png\" width=\"640\"><br>\n","\n"],"metadata":{"id":"NN7-CQufCq1H"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GoogLeNet  5 GoogLeNet\n","# Auxiliary Classifier<br>\n","> â€» å­¦ç¿’æ™‚ã¯ã€å‡ºåŠ›å±¤ä»¥å¤–ã«2ã¤ã®è£œåŠ©ã®åˆ†é¡å™¨ã®å‡ºåŠ›ã‚’é‡ã¿ä»˜ãå¹³å‡ã‚’ã¨ã‚Šã€æå¤±ã‚’è¨ˆç®—ã™ã‚‹ã€‚<br>\n","> â€» ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä¸­é–“å±¤ã«ç›´æ¥èª¤å·®ã‚’ä¼æ¬ã•ã›ã‚‹ã“ã¨ã§ã€å‹¾é…æ¶ˆå¤±é˜²æ­¢ã¨æ­£å‰‡åŒ–ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹ã€‚<br>\n","> â€» ã‚¢ãƒ³ã‚µãƒ³ãƒ•ã‚™ãƒ«å­¦ç¿’ã¨åŒæ§˜ã®åŠ¹æœã‹ã‚™å¾—ã‚‰ã‚Œã‚‹ãŸã‚ã€æ±åŒ–æ€§èƒ½ã®å‘ä¸Šã‹ã‚™æœŸå¾…ã§ãã‚‹ã€‚<br>\n","> â€» AuxililaryLossã‚’å°å…¥ã—ãªã„å ´åˆã¦ã‚™ã‚‚BatchNormalizationã‚’åŠ ãˆã‚‹ã“ã¨ã«ã‚ˆã‚Šã€åŒæ§˜ã«å­¦ç¿’ã‹ã‚™ã†ã¾ãé€²ã‚€ã“ã¨ã‹ã‚™ã‚ã‚‹ã€‚<br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://qiita.com/jun40vn/items/5ac97a6f1d8f82a49194)</font></font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F209705%2F8d251aa2-54e4-a886-390b-b5aa87519e8c.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=cd3c041fb8b150ca4daa86514cdfbffb\" width=\"640\"><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F209705%2F67f98213-a8ff-de52-2d7e-18a3ef37cdd2.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=b114488e13f5781fbb2ebc72856b3a3b\" width=\"640\">\n"],"metadata":{"id":"4xTpBfaTCraP"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GoogLeNet  6 Training Methodology"],"metadata":{"id":"J7sOM60jDQVq"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GoogLeNet  7 ILSVRC 2014 Classification Challenge Setup and Results"],"metadata":{"id":"gLceM0KwDRFI"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GoogLeNet  8 ILSVRC 2014 Detection Challenge Setup and Results"],"metadata":{"id":"GHDPL4qADgsB"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GoogLeNet  9 Conclusions"],"metadata":{"id":"YsU8d7XoDhCP"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GoogLeNet  10 Acknowledgement"],"metadata":{"id":"YWZVFUORDqig"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Inception v3</font><br>\n","<img src=\"https://cloud.google.com/static/tpu/docs/images/inceptionv3onc--oview.png\" width=\"640\">"],"metadata":{"id":"uTYPHAJGKN77"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Inception v3ï¼ˆ3Ã—3 Convï¼‰</font><br>\n","# 3Ã—3 Convolution<br>\n","> â€» 3Ã—3 ã®ç•³ã¿è¾¼ã¿å±¤ã‚’è¤‡æ•°ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€å—å®¹é‡ã‚’åŒã˜ã«ã—ã¤ã¤ã€è¨ˆç®—é‡ã®å‰Šæ¸›ã‚’å›³ã‚‹ã€‚<br>\n","<img src=\"https://miro.medium.com/max/1100/1*gyc_dcvBf51JLIu986LteQ.png\" width=\"240\">\n","<img src=\"https://pystyle.info/wp/wp-content/uploads/2021/11/pytorch-inceptionv3_01.jpg\" Height=\"160\">\n","<img src=\"https://miro.medium.com/max/1100/1*UvfZWRbPS8d1RGtBuKhIgw.png\" width=\"240\">"],"metadata":{"id":"E34XVFhoKYT6"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Inception v3ï¼ˆ1Ã—n Conv, nÃ—1 Convï¼‰\n","# 1Ã—n Convolution, nÃ—1 Convolution<br>\n","> â€» nx1 ã®ç•³ã¿è¾¼ã¿å±¤ã¨ 1xn ã®ç•³ã¿è¾¼ã¿å±¤ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€å—å®¹é‡ã‚’åŒã˜ã«ã—ã¤ã¤ã€è¨ˆç®—é‡ã®å‰Šæ¸›ã‚’å›³ã‚‹<br>\n","<img src=\"https://miro.medium.com/max/1100/1*UvfZWRbPS8d1RGtBuKhIgw.png\" width=\"240\">\n","<img src=\"https://pystyle.info/wp/wp-content/uploads/2021/11/pytorch-inceptionv3_03.jpg\" Height=\"160\">\n","<img src=\"https://miro.medium.com/max/1100/1*QPKnhTEjA4GELiGnLnvi8g.png\" width=\"240\">"],"metadata":{"id":"oP7PjeBkKYnx"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Inception v3ï¼ˆBatch Normï¼‰"],"metadata":{"id":"YNAqTgFTLYwg"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Inception v3ï¼ˆLabel Smoothingï¼‰"],"metadata":{"id":"sCsoRGZELdj6"}},{"cell_type":"markdown","source":["# <font color=\"Blue\">â– </font><font color=\"silver\">ResNet [<font color=\"silver\">â€¦</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4853&cid=b0f01606242a6ed3&CT=1666715412254&OR=ItemsView)</font><br>\n","https://arxiv.org/pdf/1512.03385.pdf<br>\n","[*â€¦*</font>](https://ai-kenkyujo.com/artificial-intelligence/ai-architecture-02/)\n","\n"],"metadata":{"id":"IurcoaAvpe9P"}},{"cell_type":"markdown","source":["# <font color=\"silver\">ResNet  1 Introduction èƒŒæ™¯\n","><img src=\"https://raw.githubusercontent.com/rohan-varma/resnet-implementation/master/images/verydeep_network.png\" width=\"640\">"],"metadata":{"id":"fknIUpehlVWN"}},{"cell_type":"markdown","source":["# <font color=\"silver\">ResNet  2 é–¢é€£ç ”ç©¶"],"metadata":{"id":"79qKCyHqlV3p"}},{"cell_type":"markdown","source":["# <font color=\"silver\">ResNet  3 Deep Residual\n","# Residual Learning<br>Identity Mapping by Shortcuts\n","> â€»  å‹¾é…æ¶ˆå¤±ã‚’æŠ‘ãˆã€ã€Œå±¤ã‚’æ·±ãã™ã‚‹ã¨å­¦ç¿’ã§ããªã„ã€ã¨ã„ã†åŠ£åŒ–å•é¡Œã‚’è§£æ±ºã—ãŸã€‚<br>\n","> â€»  ãƒã‚¤ãƒ‘ã‚¹ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦å…¥åŠ›å±¤ã«è¿‘ã„å±¤ã«ã‚‚èª¤å·®ãŒä¼ã‚ã‚‹ãŸã‚ã€å‹¾é…æ¶ˆå¤±ã‚’é˜²ãã€‚<br>\n","> â€»  è‰²ã€…ãªãƒã‚¤ãƒ‘ã‚¹ã®çµ„ã¿åˆã‚ã›ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã«ãªã‚Šã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åŠ¹æœãŒã‚ã‚‹ã€‚<br>\n","> â€»  å…¥åŠ›ã‚’ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆã—ã¦è¶³ã™ã ã‘ãªã®ã§ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã¯ã»ã¨ã‚“ã©å¢—ãˆãšã«ã€å®Ÿè£…ã‚‚å®¹æ˜“ã€‚<br>\n","> â€»  ğ¹(ğ‘¥) ã¯ã€å…¥åŠ›ğ‘¥ã¨å‡ºåŠ› H(ğ‘¥) ã®æ®‹å·® Hğ‘¥âˆ’ğ‘¥ ã‚’å­¦ç¿’ã—ã¦ã„ã‚‹<br>\n","> â€»  ãƒ•ã‚™ãƒ­ãƒƒã‚¯ã¸ã®å…¥åŠ›ã«ã“ã‚Œä»¥ä¸Šã®å¤‰æ›ã‹ã‚™å¿…è¦ãªã„å ´åˆã¯é‡ã¿ãŒ0ã¨ãªã‚Šã€å°ã•ãªå¤‰æ›ã‹ã‚™æ±‚ã‚ã‚‰ã‚Œã‚‹å ´åˆã¯å¯¾å¿œã™ã‚‹å°ã•ãªå¤‰å‹•ã‚’ã‚ˆã‚Šè¦‹ã¤ã‘ã‚„ã™ããªã‚‹ã€‚<br> <br>\n","<font color=\"black\">$H(x)=F(x)+x$\n","<br>\n","<img src=\"https://raw.githubusercontent.com/rohan-varma/resnet-implementation/master/images/residual_learning_block.png\" width=\"480\"><br><br>\n","# Network Architectures\n","><img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20200424011138/ResNet.PNG\" width=\"640\">\n","# <font color=\"silver\">ResNet  3.4. Implementation"],"metadata":{"id":"93jQa6oNlV__"}},{"cell_type":"markdown","source":["# <font color=\"silver\">ResNet  4 å®Ÿé¨“\n","# Bottleneck Block\n","> â€» 1Ã—1 Convã§æ¬¡å…ƒå‰Šæ¸›ã€3Ã—3 Convã€1Ã—1 Convã§æ¬¡å…ƒã‚’å¾©å…ƒã™ã‚‹ã¨ã„ã†å½¢<br>\n","> â€» åŒç­‰ã®è¨ˆç®—é‡ã‚’ä¿ã¡ãªãŒã‚‰ã€ã‚ˆã‚Šæ·±ã„ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ãŒå‡ºæ¥ã‚‹ã€‚<br>\n","> â€» å·¦å›³ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼æ•°ï¼š3Ã—3Ã—64Ã—64ã€3Ã—3Ã—64Ã—64â‰’70k<br>\n","> â€» å³å›³ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼æ•°ï¼š256Ã—64ã€64Ã—3Ã—3Ã—64ã€64Ã—256â‰’70kï¼ˆãƒœãƒˆãƒ«ãƒãƒƒã‚¯ï¼‰<br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/shikiponn/20190603/20190603173844.png\" width=\"480\"><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F38555%2F1557d5bd-50bc-a65e-cf9a-dad10649a6c0.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=21774d16a1f02b2759fa9fb941212d13\" width=\"640\"><br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦</font>](https://qiita.com/jun40vn/items/be48afbdd9da19f1e43e)<br></font>\n","<img src=\"https://camo.qiitausercontent.com/310591eea55adba318520a682e19baac8ab64d19/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3331353036332f36303336393736332d643734382d386334382d396262322d3734616564623262663263392e706e67\" width=\"480\">"],"metadata":{"id":"lQSswzq8lsMa"}},{"cell_type":"markdown","source":["# <font color=\"Blue\">â– </font><font color=\"silver\">WideResNet [<font color=\"silver\">â€¦</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4863&cid=b0f01606242a6ed3&CT=1666720554388&OR=ItemsView)\n","â€» ResNetãŒæ®‹å·®æ¥ç¶šã«ã‚ˆã£ã¦å±¤ã‚’æ·±ãã—ãŸã®ã«å¯¾ã—ã€ WideResNet ã¯æ®‹å·®ãƒ–ãƒ­ãƒƒã‚¯å†…ã®ç•³ã¿è¾¼ã¿å±¤ã®å‡ºåŠ›ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã‚’å¢—ã‚„ã—ã€å±¤ã‚’æµ…ãã—ãŸãƒ¢ãƒ‡ãƒ«ã€‚<br></font>\n","<br>\n","<font color=\"Black\">depthï¼š<font color=\"silver\">å…¨ä½“ã®depthï¼ˆç•³ã¿è¾¼ã¿ã®æ·±ã•ã€ç•³ã¿è¾¼ã¿ã®æ•°ï¼‰<br>\n","<font color=\"Black\">lï¼š<font color=\"silver\">ãƒ–ãƒ­ãƒƒã‚¯å†…ã®depthï¼ˆç•³ã¿è¾¼ã¿ã®æ·±ã•ã€ç•³ã¿è¾¼ã¿ã®æ•°ï¼‰<br>\n","<font color=\"Black\">kï¼š<font color=\"silver\">ãƒ–ãƒ­ãƒƒã‚¯å†…ã®widthï¼ˆç•³ã¿è¾¼ã¿ã®åºƒã•ï¼‰ç‰¹å¾´å¹³é¢ã®æ•°ï¼ˆãƒãƒ£ãƒãƒ«æ•°ï¼‰ã‚’ k å€ã™ã‚‹ã“ã¨ã‚’æ„å‘³ã™ã‚‹ã€‚<br>\n","<font color=\"Black\">B(M)ï¼š<font color=\"silver\"> Residial Blockï¼ˆæ®‹å·®ãƒ–ãƒ­ãƒƒã‚¯ï¼‰<br>\n","<font color=\"Black\">Mï¼š<font color=\"silver\">ãƒ–ãƒ­ãƒƒã‚¯å†…ã®ç•³ã¿è¾¼ã¿å±¤ã®ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚ºã®ãƒªã‚¹ãƒˆ<br>\n","<font color=\"Black\">WRN-n-kï¼š<font color=\"silver\"> nå±¤ã®ç•³ã¿è¾¼ã¿ã‚’ã‚‚ã¡ã€å¹…k ã‚’ã‚‚ã¤ Wide Residual Networks<br>"],"metadata":{"id":"FqQ40TgEGGAh"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WideResNet  1 Introduction èƒŒæ™¯ <br>\n","# <font color=\"silver\"> å›³1<br>\n","<img src=\"https://norman3.github.io/papers/images/wrn/f01.png\" width=\"640\"><br>"],"metadata":{"id":"R-hfUIbhHek9"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WideResNet  2 Wide residual networks<br>\n","# <font color=\"silver\">å¼ï¼‘<br>\n","${\\bf x}_{l+1} = {\\bf x}_{l} + F({\\bf x}_{l}, {W_l})$<br>\n","# <font color=\"silver\">è¡¨1 Baseline Model<br>\n","<img src=\"https://norman3.github.io/papers/images/wrn/f02.png\" width=\"640\"><br>\n","# <font color=\"silver\">ï¼ˆå‚è€ƒï¼‰\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F38555%2F1557d5bd-50bc-a65e-cf9a-dad10649a6c0.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=21774d16a1f02b2759fa9fb941212d13\" width=\"640\"><br>\n"],"metadata":{"id":"_apKKPVgHeve"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WideResNet  2.1 Type of convolutions in residual block<br>\n","# <font color=\"silver\">è¡¨2 Block Type\n","Residual Blockå†…ã®ç•³ã¿è¾¼ã¿å±¤ã®çµ„ã¿åˆã‚ã›ã‚’æ¤œè¨¼<br>\n","ãƒãƒ£ãƒ³ãƒãƒ«æ•°Kï¼2å€ã®ã¨ãã®æ€§èƒ½æ¯”è¼ƒã§ã¯ã€B(3, 3)ã®æ€§èƒ½ãŒæœ€ã‚‚è‰¯ã„ã€‚<br>\n","<br>\n","<img src=\"https://norman3.github.io/papers/images/wrn/f03.png\" width=\"400\"><br>\n","<font color=\"black\">\n","B(1, 3, 1): 1Ã—1 -> 3Ã—3 -> 1Ã—1ã€‚ã‚ªãƒªã‚¸ãƒŠãƒ«ã® Bottleneck Block<br>\n","B(3, 1): 3Ã—3 -> 1Ã—1<br>\n","B(1, 3): 1Ã—1 -> 3Ã—3<br>\n","B(3, 1, 1): 3Ã—3 -> 1Ã—1 -> 1Ã—1ã€‚Network In Network ã¨åŒã˜æ§‹é€ ã€‚<br>\n","B(3, 3): 3Ã—3 -> 3Ã—3ã€‚ã‚ªãƒªã‚¸ãƒŠãƒ«ã® Building Block<br>\n","B(3, 1, 3): 3Ã—3 -> 1Ã—1 -> 3Ã—3<br>"],"metadata":{"id":"37gPeOxeHe4r"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WideResNet  2.2 Number of convolutional layers per residual block<br>\n","# <font color=\"silver\">è¡¨3 Layers per Block\n","ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å…¨ä½“ã®å±¤æ•°ã‚’40ã¨ã—ã¦ã€1 ãƒ–ãƒ­ãƒƒã‚¯å†…ã®ç•³ã¿è¾¼ã¿å±¤ã®æ•°$\\,l\\,$ã‚’å¤‰åŒ–ã•ã›ã¦æ¤œè¨¼<br>\n","å±¤ã®æ•°$\\,l=1\\,$ã§ã¯è¡¨ç¾åŠ›ãŒè¶³ã‚Šãšã€$\\,l=3\\,$ä»¥ä¸Šã®ã¨ãã¯æ®‹å·®æ¥ç¶šãŒæ¸›å°‘ã—ãŸãŸã‚æœ€é©åŒ–ãŒé›£ã—ããªã£ãŸçµæœã¨ã„ãˆã‚‹ã€‚<br><br>\n","<img src=\"https://norman3.github.io/papers/images/wrn/f04.png\" width=\"200\"><br>\n","l=1ã¯B(3)<br>\n","l=2ã¯B(3, 3)<br>\n","l=3ã¯B(3, 3, 3)<br>\n","l=4ã¯B(3, 3, 3, 3)<br>"],"metadata":{"id":"Eaqd3QeyHfEJ"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WideResNet  2.3 Width of residual blocks<br>\n","\n","\n"],"metadata":{"id":"KNkAbuGaHuhQ"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WideResNet  2.4 Dropout in residual blocks<br>"],"metadata":{"id":"vbMEMecdHx7u"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WideResNet  3 Experimental results<br>\n","# <font color=\"silver\">è¡¨ï¼”\n","depthï¼ˆå…¨ä½“ã®å±¤ã®æ·±ã•ï¼‰ã¨ kï¼ˆå¹…ã®åºƒã•ï¼‰ã®çµ„ã¿åˆã‚ã›ã®çµæœ<br>\n","<br>\n","<img src=\"https://norman3.github.io/papers/images/wrn/f05.png\" width=\"640\"><br>\n","# <font color=\"silver\">è¡¨ï¼•<br>\n","ä»–ã®ãƒ¢ãƒ‡ãƒ«ã¨ã®æ€§èƒ½æ¯”è¼ƒã®çµæœ<br><br>\n","<img src=\"https://norman3.github.io/papers/images/wrn/f06.png\" width=\"640\"><br>\n","# <font color=\"silver\">å›³ï¼’<br>\n","ResNetã¨WideResNetã¨ã®æ¯”è¼ƒ<br><br>\n","<img src=\"https://norman3.github.io/papers/images/wrn/f07.png\" width=\"640\"><br>\n","# <font color=\"silver\">è¡¨6 Dropout\n","ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆæœ‰ã¨ç„¡ã®æ€§èƒ½æ¯”è¼ƒ<br><br>\n","<img src=\"https://norman3.github.io/papers/images/wrn/f08.png\" width=\"640\"><br>\n","# <font color=\"silver\">å›³3 Dropout\n","ResNet ã¨ WideResNet ã®æ¯”è¼ƒã€WideResNet ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆæœ‰ã¨ç„¡ã®æ¯”è¼ƒ<br>\n","Dropout ãªã—ã®å ´åˆã¯ã€å­¦ç¿’ç‡ã‚’ä¸‹ã’ã‚‹ã¨éå‰°é©åˆã«ã‚ˆã‚Šæ€¥æ¿€ã«è¨“ç·´æå¤±ãŒä¸‹ãŒã‚‹ã€‚<br><br>\n","<img src=\"https://norman3.github.io/papers/images/wrn/f09.png\" width=\"640\"><br>\n","# <font color=\"silver\">è¡¨7\n","WideResNet ã®å¹…ã‚„æ·±ã•ã‚’å¤‰æ›´ã—ãŸã¨ãã®æ€§èƒ½æ¯”è¼ƒ<br><br>\n","<img src=\"https://norman3.github.io/papers/images/wrn/f10.png\" width=\"640\"><br>\n","# <font color=\"silver\">è¡¨8\n","ResNetã¨WideResNetã¨ã®æ¯”è¼ƒ<br><br>\n","<img src=\"https://norman3.github.io/papers/images/wrn/f11.png\" width=\"640\"><br>\n","# <font color=\"silver\">è¡¨9\n","å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ WideResNet ã®çµæœ<br><br>\n","<img src=\"https://norman3.github.io/papers/images/wrn/f12.png\" width=\"640\"><br>\n","# <font color=\"silver\">å›³4\n","ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ResNetã¨ã®ç²¾åº¦ã¨è¨ˆç®—æ™‚é–“ã®æ¯”è¼ƒ<br>\n","<img src=\"https://norman3.github.io/papers/images/wrn/f13.png\" width=\"240\"><br>"],"metadata":{"id":"_QJvx_Q-HyJ1"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WideResNet  4 Conclusions<br>"],"metadata":{"id":"eiHN90dKHfND"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WideResNet  5 Acknowledgements <br>"],"metadata":{"id":"cptGEm8SH37F"}},{"cell_type":"markdown","source":["# <font color=\"Blue\">â– </font><font color=\"silver\">DenseNet [<font color=\"silver\">â€¦</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4861&cid=b0f01606242a6ed3&CT=1666715758082&OR=ItemsView)</font><br>\n","â€» Denseãªã‚¹ã‚­ãƒƒãƒ—æ¥ç¶šç¾¤ã«ã‚ˆã‚Šï¼ŒResNetã‚ˆã‚Šã‚‚å‹¾é…æ¶ˆå¤±å•é¡Œã‚’ç·©å’Œã—ãŸã€‚<br>\n","â€» Denseãƒ–ãƒ­ãƒƒã‚¯å†…ã§å±¤é–“ãŒå…¨ã¦ã‚¹ã‚­ãƒƒãƒ—æ¥ç¶šã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ç‰¹å¾´ãƒãƒƒãƒ—ã®ä¼æ¬ã‚’å¼·åŒ–ã—ã¦ã„ã‚‹ã€‚<br>\n","â€» ç‰¹å¾´é‡ã‚’å†åˆ©ç”¨ã™ã‚‹çµåˆã«ãªã£ã¦ã„ã‚‹ãŸã‚ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’å°‘ãªãã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br>\n","â€» å®Ÿéš›ã«ã¯ã€æ¬¡å…ƒå‰Šæ¸›ã®ãŸã‚Bottleneckã‚’ä½¿ç”¨ã€‚<br>\n","â€» Grow Rateã¨ã¯ã€Dense Blockã®ä¸­ã§å¢—ã‚„ã™ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®æ•°ã§ã€k=32ã«è¨­å®šã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„\n","<br><br>\n","<font color=\"black\">$xl = Hl(x0, x1, â€¦, xl-1)$\n","<br><br>\n","$xl$ï¼š<font color=\"silver\">ç¬¬lå±¤ã®å‡ºåŠ›</font><br>\n","$Hl$ï¼š<font color=\"silver\">Batch normalizationã€ReLUã€3Ã—3 Convolution</font>\n","<br><br>\n","<img src=\"https://ai-kenkyujo.com/wp-content/uploads/2021/12/ai-img2-20.png.webp\" width=\"640\"><br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦</font>](https://techplay.jp/event/846663)</font><br>\n","<img src=\"https://i.gyazo.com/8cae5dd02904890ca66f11470603cfd3.png\" width=\"640\">\n","<br><br>\n","â€» Dense Blockã§å¤§ãããªã£ãŸãƒãƒ£ãƒ³ãƒãƒ«æ•°ã‚’åœ§ç¸®ã™ã‚‹ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®å½¹å‰²ã‚’æŒã¤ãƒ¬ã‚¤ãƒ¤ãƒ¼<br>\n","â€» 1Ã—1 Convolutionã€2Ã—2 Average Poolingã§æ§‹æˆã•ã‚Œã¦ã„ã‚‹<br>\n","â€» ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’è¡Œã†å±¤ã¯é‡è¦ãªè¦ç´ ã«ãªã‚‹ãŸã‚ã€Dense Blocké–“ã«Poolingå±¤ã‚’å°å…¥ã—ãŸã€‚<br>\n","<img src=\"https://ai-kenkyujo.com/wp-content/uploads/2021/12/ai-img2-21.png.webp\" width=\"640\">"],"metadata":{"id":"ogtjZDMMHYTa"}},{"cell_type":"markdown","source":["# <font color=\"silver\">DenseNet  å›³1 Dense Block\n","<font color=\"black\">$xl = Hl(x0, x1, â€¦, xl-1)$\n","<br><br>\n","$xl$ï¼š<font color=\"silver\">ç¬¬lå±¤ã®å‡ºåŠ›</font><br>\n","$Hl$ï¼š<font color=\"silver\">Batch normalizationã€ReLUã€3Ã—3 Convolution</font>\n","<br><br>\n","<img src=\"https://ai-kenkyujo.com/wp-content/uploads/2021/12/ai-img2-20.png.webp\" width=\"640\"><br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦</font>](https://techplay.jp/event/846663)</font><br>\n","<img src=\"https://i.gyazo.com/8cae5dd02904890ca66f11470603cfd3.png\" width=\"640\"><br>\n","<img src=\"https://velog.velcdn.com/images/skhim520/post/abd9ef85-e295-43d6-8e3e-929308129b88/KakaoTalk_20210506_175258356.jpg\" width=\"640\"><br>\n"],"metadata":{"id":"xXPyDeYrHykq"}},{"cell_type":"markdown","source":["# <font color=\"silver\">DenseNet  å›³2 Transition Layer\n","â€» Dense Blockã§å¤§ãããªã£ãŸãƒãƒ£ãƒ³ãƒãƒ«æ•°ã‚’åœ§ç¸®ã™ã‚‹ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®å½¹å‰²ã‚’æŒã¤ãƒ¬ã‚¤ãƒ¤ãƒ¼<br>\n","â€» 1Ã—1 Convolutionã€2Ã—2 Average Poolingã§æ§‹æˆã•ã‚Œã¦ã„ã‚‹<br>\n","â€» ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’è¡Œã†å±¤ã¯é‡è¦ãªè¦ç´ ã«ãªã‚‹ãŸã‚ã€Dense Blocké–“ã«Poolingå±¤ã‚’å°å…¥ã—ãŸã€‚<br>\n","<img src=\"https://ai-kenkyujo.com/wp-content/uploads/2021/12/ai-img2-21.png.webp\" width=\"640\">\n","<img src=\"https://images.velog.io/images/skhim520/post/9e72346d-ef5e-4a42-95f3-1c0e2feb235d/image.png\" width=\"640\"><br>\n","\n"],"metadata":{"id":"sRQeK_gzH3gT"}},{"cell_type":"markdown","source":["# <font color=\"silver\">DenseNet  è¡¨1 Architecture\n","<img src=\"https://arthurdouillard.com/figures/densenet_archi.png\" width=\"640\"><br>"],"metadata":{"id":"cd1YDHM5mRIa"}},{"cell_type":"markdown","source":["# <font color=\"Blue\">â– </font><font color=\"silver\">MobileNet v1 [<font color=\"silver\">â€¦</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4869&cid=b0f01606242a6ed3&CT=1666816954089&OR=ItemsView)</font>\n"],"metadata":{"id":"wftD_3BVdEoj"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v1  1. Introduction\n","# <font color=\"silver\">å›³ï¼‘\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/fig01.png\" width=\"640\"><br>"],"metadata":{"id":"0hjfe9kgMCU6"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v1  2. Prior Work"],"metadata":{"id":"O3C9S_A6MTvL"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v1  3. MobileNet Architecture"],"metadata":{"id":"gX5_-BMtMURD"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v1  3.1. Depthwise Separable Convolution\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/fig02.png\" width=\"640\">\n","# <font color=\"silver\">å›³ï¼’\n","<br><br>\n","<font color=\"black\">${\\cfrac{D_{K} Â· D_{K} Â· M Â· D_{F} Â· D_{F} ï¼‹M Â· N Â· D_{F} Â· D_{F} }{D_{K} Â· D_{K} Â· M Â· N Â· D_{F} Â· D_{F} } = \\cfrac{1}{N} + \\cfrac{1}{D_{K}^2}}$\n","<br><br>\n","<font color=\"black\">$M$ï¼š<font color=\"silver\">å…¥åŠ›ãƒãƒ£ãƒãƒ«æ•°</font><br>\n","<font color=\"black\">$N$ï¼š<font color=\"silver\">å‡ºåŠ›ãƒãƒ£ãƒãƒ«æ•°</font><br>\n","<font color=\"black\">$D_{K}Ã—D_{K}$ï¼š<font color=\"silver\">ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º</font><br>\n","<font color=\"black\">$D_{F}Ã—D_{F}$ï¼š<font color=\"silver\">ç‰¹å¾´ãƒãƒƒãƒ—ã‚µã‚¤ã‚º</font>\n","<br><br>\n","${\\rm Depthwise} :c_{in}ï½¥k^2$\n","<br>\n","${\\rm Pointwise} :c_{in}ï½¥c_{out}$\n","<br>\n","$c_{in}ï½¥k^2 + c_{in}ï½¥c_{out} = c_{in}(c_{out}+k^2)$\n","<br><br>\n","$\\cfrac{c_{in}(c_{out}+k^2)}{c_{in}ï½¥c_{out}ï½¥k^2} ï¼\\cfrac{c_{out}ï¼‹k^2}{c_{out}ï½¥k^2} ï¼\\cfrac{1}{k^2} ï¼‹\\cfrac{1}{c_{out}}$\n","<br><br>\n","\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://muscle-programmer.hatenablog.com/entry/2018/06/07/190221)</font></font><br>\n","<img src=\"https://qiita-image-store.s3.amazonaws.com/0/108729/5e4bb20f-127e-4d9e-10fb-110ba4694360.png\" width=\"480\">\n","<br><br>\n","<img src=\"https://qiita-image-store.s3.amazonaws.com/0/108729/72ca6fe6-f6a0-7dd3-3b24-7aa3aa185ab6.png\" width=\"480\">\n","<br><br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://techplay.jp/event/846663)</font></font><br>\n","<img src=\"https://i.gyazo.com/fa9826d7d41fee8f3910fe0916c1f595.png\" width=\"640\">\n","<br><br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://www.mdpi.com/2072-4292/13/16/3211/htm)</font></font><br>\n","<img src=\"https://www.mdpi.com/remotesensing/remotesensing-13-03211/article_deploy/html/images/remotesensing-13-03211-g002-550.jpg\" width=\"640\">"],"metadata":{"id":"gFZbB1wdMUt7"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v1  3.2. Network Structure and Training\n","# <font color=\"silver\"> å›³ï¼“\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/fig03.png\" width=\"320\"><br>\n","# <font color=\"silver\"> è¡¨ï¼‘\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/tab01.png\" width=\"480\"><br>\n","# <font color=\"silver\"> è¡¨ï¼’\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/tab02.png\" width=\"480\"><br>"],"metadata":{"id":"72wOiHlvMVId"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v1  3.3. Width Multiplier: Thinner Models\n","â€» ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å†…ã®ãƒãƒ£ãƒãƒ«æ•°ã‚’èª¿æ•´ã™ã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿<br>\n","â€» å„ãƒ¬ã‚¤ãƒ¤ã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä¸€æ§˜ã«è–„ãã™ã‚‹å½¹å‰²ã‚’æŒã¤<br>\n","â€» è¨ˆç®—ã‚³ã‚¹ãƒˆã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’ç´„$Î±$ã®äºŒä¹—ã®äºŒæ¬¡é–¢æ•°çš„ã«å‰Šæ¸›ã™ã‚‹<br><br>\n","<font color=\"black\">$D_{K} Â· D_{K} Â· Î±M Â· \\rho D_{F} Â· \\rho D_{F} ï¼‹Î±M Â· Î±N Â· \\rho D_{F} Â· \\rho D_{F} $\n","<br><br>\n","<font color=\"black\">$M$ï¼š<font color=\"silver\">å…¥åŠ›ãƒãƒ£ãƒãƒ«æ•°</font><br>\n","<font color=\"black\">$N$ï¼š<font color=\"silver\">å‡ºåŠ›ãƒãƒ£ãƒãƒ«æ•°</font><br>\n","<font color=\"black\">$D_{K}Ã—D_{K}$ï¼š<font color=\"silver\">ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º</font><br>\n","<font color=\"black\">$D_{F}Ã—D_{F}$ï¼š<font color=\"silver\">ç‰¹å¾´ãƒãƒƒãƒ—ã‚µã‚¤ã‚º</font>\n","<br><br>\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/tab06.png\" width=\"480\"><br>"],"metadata":{"id":"FO43yCq-MVi8"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v1  3.4. Resolution Multiplier: Reduced Representation\n","â€» åŠ›ç”»åƒã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å†…ã§ã®ä¸­é–“è¡¨ç¾ã®è§£åƒåº¦ã‚’èª¿æ•´ã™ã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿<br>\n","â€» å…¥åŠ›ç”»åƒã«é©ç”¨ã™ã‚‹ã¨ã€å„å±¤ã®å†…éƒ¨è¡¨ç¾ãŒåŒã˜ä¹—æ•°ã§å‰Šæ¸›ã•ã‚Œã‚‹ã€‚<br>\n","â€» å„å±¤ã®ãƒãƒ£ãƒãƒ«æ•° / è§£åƒåº¦ã‚’å°ã•ãã—ã€ç²¾åº¦ã¯ä¸‹ãŒã£ã¦ã—ã¾ã†ã‚‚ã®ã®ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›<br>\n","<br>\n","<font color=\"black\">$D_{K} Â· D_{K} Â· Î±M Â· \\rho D_{F} Â· \\rho D_{F} ï¼‹Î±M Â· Î±N Â· \\rho D_{F} Â· \\rho D_{F} $\n","<br><br>\n","<font color=\"black\">$M$ï¼š<font color=\"silver\">å…¥åŠ›ãƒãƒ£ãƒãƒ«æ•°</font><br>\n","<font color=\"black\">$N$ï¼š<font color=\"silver\">å‡ºåŠ›ãƒãƒ£ãƒãƒ«æ•°</font><br>\n","<font color=\"black\">$D_{K}Ã—D_{K}$ï¼š<font color=\"silver\">ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º</font><br>\n","<font color=\"black\">$D_{F}Ã—D_{F}$ï¼š<font color=\"silver\">ç‰¹å¾´ãƒãƒƒãƒ—ã‚µã‚¤ã‚º</font>\n","<br><br>\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/tab06.png\" width=\"480\"><br>"],"metadata":{"id":"eo1sp-QtMXGC"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v1  4. Experiments\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/tab03.png\" width=\"480\"><br>\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/tab04.png\" width=\"480\"><br>\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/tab04.png\" width=\"480\"><br>\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/tab06.png\" width=\"480\"><br>\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/fig04.png\" width=\"320\"><br>\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/fig05.png\" width=\"320\"><br>\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/tab08.png\" width=\"480\"><br>\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/tab08.png\" width=\"480\"><br>\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/tab12.png\" width=\"480\"><br>\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/tab13.png\" width=\"480\"><br>\n","<img src=\"https://greeksharifa.github.io/public/img/2022-02-01-MobileNetV1/tab14.png\" width=\"480\"><br>"],"metadata":{"id":"BGiOUokeMoXh"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v1  5. Conclusion"],"metadata":{"id":"FfCpwq00MqCA"}},{"cell_type":"markdown","source":["# <font color=\"Blue\">â– </font><font color=\"silver\">MobileNet v2 [<font color=\"silver\">â€¦</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4871&cid=b0f01606242a6ed3&CT=1666818057888&OR=ItemsView)</font><br>\n","<img src=\"https://miro.medium.com/max/1100/1*bqE59FvgpvoAQUMQ0WEoUA.png\" width=\"480\">"],"metadata":{"id":"o8iceq4lzir4"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v2  1. Introduction"],"metadata":{"id":"WiSHfISQTZdo"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v2  2. Related Work"],"metadata":{"id":"b-OBzKwbTeJQ"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v2  3. Preliminaries, discussion and intuition"],"metadata":{"id":"-cWJZGunTeta"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v2  3.1. Depthwise Separable Convolutions\n","<img src=\"https://camo.githubusercontent.com/f456646d6aec8b4c677d568c7d00844bf9c93cbf86f7872f0a8f69915968404f/68747470733a2f2f692e696d6775722e636f6d2f4a62386a3373682e706e67\" width=\"480\"><br>"],"metadata":{"id":"jnFHJ9cQTfLp"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v2  3.2. Linear Bottlenecks"],"metadata":{"id":"XlV9FU-bTfl6"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v2  3.3. Inverted residuals\n","$\\rm{ReLU}6(x) = \\min(\\max(x,0),6)$\n","<br><br>\n","<img src=\"https://camo.githubusercontent.com/2c0209ee2e2da079a17428c6d96e945a6c362116f1883ca6af5ea63ea5125c7d/68747470733a2f2f692e696d6775722e636f6d2f6b554a753635522e706e67\" width=\"480\">\n","<br><br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://www.researchgate.net/figure/Residual-block-12-36-and-inverted-residual-block_fig2_358518820)</font></font><br>\n","<img src=\"https://www.researchgate.net/publication/358518820/figure/fig2/AS:1157628617072649@1653011578181/Residual-block-12-36-and-inverted-residual-block.png\" width=\"400\">"],"metadata":{"id":"cs4Xwp_LTf_a"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v2  3.4. Information flow interpretation"],"metadata":{"id":"MdqHf0rTTg0k"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v2  4. Model Architecture"],"metadata":{"id":"CDbapiaBThOy"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v2  5. Implementation Notes"],"metadata":{"id":"WJUW0LjQTz-m"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v2  5.1. Memory efficient inference"],"metadata":{"id":"sYaBH-NNT0bd"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v2  6. Experiments"],"metadata":{"id":"OBHT8fIpT02E"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v2  7. Conclusions and future work"],"metadata":{"id":"2bucsEBrT9vM"}},{"cell_type":"markdown","source":["# <font color=\"Blue\">â– </font><font color=\"silver\">MobileNet v3 [<font color=\"silver\">â€¦</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4871&cid=b0f01606242a6ed3&CT=1666818057888&OR=ItemsView)</font><br>\n","\n","NetAdapt</font><br>\n","<img src=\"https://miro.medium.com/max/1100/1*pPnym46xkAH5b3VaipEp7Q.png\" width=\"640\">"],"metadata":{"id":"8GhWXj9e-8Pe"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v3  1. Introduction"],"metadata":{"id":"4Vnh9cnmV8vM"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v3  2. Related Work"],"metadata":{"id":"u1LbtTyIWJ_A"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v3  3. Efficient Mobile Building Blocks\n","<img src=\"https://miro.medium.com/max/786/1*UzDT6jEDJYKGkHB2nAejUw.png\" width=\"480\">"],"metadata":{"id":"oN4_n79sWKaD"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v3  4. Network Search"],"metadata":{"id":"bGD0U2QDWLWa"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v3  4.1. Platform-Aware NAS for Block-wise Search"],"metadata":{"id":"eeYiPabwWLwk"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v3  4.2. NetAdapt for Layer-wise Search"],"metadata":{"id":"dGiwazIYWMPT"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v3  5. Network Improvements"],"metadata":{"id":"EU2lOgp9WMnl"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v3  5.1. Redesigning Expensive Layers\n","<img src=\"https://miro.medium.com/max/828/1*sV45zudDSKlqnlftIXc09w.png\" width=\"640\">"],"metadata":{"id":"pcQtAxNZWNAF"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v3  5.2. Nonlinearities\n","$h-{\\rm swish}[x] = x\\cfrac{{\\rm ReLU}6(x+3)}{6}$\n","<br>\n","<img src=\"https://miro.medium.com/max/828/1*fL0LcL4ZC3i7mbfpuaAQiw.png\" width=\"480\">"],"metadata":{"id":"5T99RFBsWNZM"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v3  5.3. Large squeeze-and-excite\n","\n"],"metadata":{"id":"5OWvnoi9WN3U"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v3  5.4. MobileNetV3 Definitions"],"metadata":{"id":"ovBOak4GWvY_"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v3  6. Experiments\n","<img src=\"https://combustion.readthedocs.io/en/v0.1.0rc1/_images/raspp.png\" width=\"800\">"],"metadata":{"id":"ldr7hrA5Wvzu"}},{"cell_type":"markdown","source":["# <font color=\"silver\">MobileNet v3  7. Conclusions and future work"],"metadata":{"id":"AE0OEmDWWwUh"}},{"cell_type":"markdown","source":["# <font color=\"Blue\">â– </font><font color=\"silver\">EfficientNet [<font color=\"silver\">â€¦</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4875&cid=b0f01606242a6ed3&CT=1666816283914&OR=ItemsView)"],"metadata":{"id":"DNW1gt0ijGuT"}},{"cell_type":"markdown","source":["# <font color=\"silver\">EfficientNet  1. Introduction\n","# <font color=\"silver\"> å›³1\n","ãƒ¢ãƒ‡ãƒ«ã®ç¨®é¡ãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãƒ»æ­£è§£ç‡ã®ã‚°ãƒ©ãƒ•<br>\n","<font color=\"black\">F1. Model Size vs. ImageNet Accuracy.<br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/n/nuka137/20200908/20200908141057.png\" width=\"480\"><br>\n","# <font color=\"silver\"> å›³2\n","<font color=\"black\">F2. Model Scaling.<br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/n/nuka137/20200904/20200904095539.png\" width=\"800\"><br>"],"metadata":{"id":"YvK_YtQ91uGB"}},{"cell_type":"markdown","source":["# <font color=\"silver\">EfficientNet  2. Related Work"],"metadata":{"id":"9-SSPbay1vPq"}},{"cell_type":"markdown","source":["# <font color=\"silver\">EfficientNet  3. Compound Model Scaling"],"metadata":{"id":"wTX5caG01v5T"}},{"cell_type":"markdown","source":["# <font color=\"silver\">EfficientNet  3.1. Problem Formulation\n","# <font color=\"silver\">å¼1\n","$\\displaystyle \\mathcal{N}=\\bigodot_{i=1,...,s}\\mathcal{F}_i^{L_i}\\left(X_{<H_i, W_i, C_i>}\\right)$\n","# <font color=\"silver\">å¼2\n","ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ­£è§£ç‡ã‚’æœ€å¤§ã«ã™ã‚‹$d,w,r$ã‚’ãƒãƒ©ãƒ³ã‚¹ã‚’ã¨ã£ã¦ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹<br><br>\n","<font color=\"black\">$\\displaystyle \\max_{d, w, r} \\quad Accuracy\\left(\\mathcal{N}(d, w, r)\\right)$<br>\n","$\\displaystyle \\mathcal{N}(d, w, r) = \\bigodot_{i=1,...s}\\hat{\\mathcal{F}}_i^{d \\cdot \\hat{L}_i}\\left(X_{<r \\cdot \\hat{H}_i, r \\cdot \\hat{W}_i, w \\cdot \\hat{C}_i>}\\right)$<br>\n","$\\displaystyle \\rm Memory(\\mathcal{N}) \\le target\\_memory$<br>\n","$\\displaystyle \\rm FLOPS(\\mathcal{N}) \\le target\\_flops$<br><br>\n","<font color=\"black\">$\\mathcal{N}$ï¼š<font color=\"silver\">Baseline Modelã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯<br>\n","<font color=\"black\">$Î±, Î² ,Î³$ï¼š<font color=\"silver\">Baseline Modelã«ãŠã‘ã‚‹å±¤æ•°ã€å¹…ã€è§£åƒåº¦ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä¿‚æ•°<br>\n","<font color=\"black\">$\\displaystyle\\bigodot_{i=1...s}$ï¼š<font color=\"silver\">ãƒ¢ãƒ‡ãƒ«$\\mathcal{N}$ãŒ$s$å€‹ã®ã‚¹ãƒ†ãƒ¼ã‚¸(ãƒ–ãƒ­ãƒƒã‚¯)ã§æˆã‚Šç«‹ã£ã¦ã„ã‚‹<br>\n","<font color=\"black\">$\\rm FLOPS$ï¼š<font color=\"silver\">1ç§’ã‚ãŸã‚Šã«ã§ãã‚‹æµ®å‹•å°æ•°ç‚¹æ¼”ç®—ã®å›æ•°ï¼ˆFLoating-point Operations Per Secondï¼‰<br><br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/n/nuka137/20200908/20200908105522.png\" width=\"400\"><br>"],"metadata":{"id":"E1ggqpzX1wZK"}},{"cell_type":"markdown","source":["# <font color=\"silver\">EfficientNet  3.2. Scaling Dimensions\n","# <font color=\"silver\">å›³3\n","ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¢—åŠ ã«ä¼´ã£ã¦ç²¾åº¦å‘ä¸ŠãŒéˆåŒ–ã™ã‚‹<br>\n","<font color=\"black\">F3. Scaling Up a Baseline Model with Different Network Width (w), Depth (d), and Resolution (r) Coefficients.<br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/n/nuka137/20200904/20200904134009.png\" width=\"800\"><br>\n","<font color=\"black\">å±¤æ•° d<br>\n","<font color=\"black\">å±¤ã‚’å¢—ã‚„ã™ã“ã¨ã§ã€ã‚ˆã‚Šè¤‡é›‘ãªç‰¹å¾´é‡ã‚’æ‰ãˆã‚‹ã“ã¨ãŒã§ãã¦æ±åŒ–æ€§èƒ½ã®å‘ä¸Šã«ã¤ãªãŒã‚‹ã€‚ä¸€æ–¹ã§ã€å‹¾é…æ¶ˆå¤±å•é¡ŒãŒç™ºç”Ÿã—ã‚„ã™ããªã‚‹ã€‚å‹¾é…æ¶ˆå¤±å•é¡Œã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã€ResNetã‚„Batch Normlizationãªã©ã®æ‰‹æ³•ãŒã‚ã‚‹ã€‚<br>\n","<font color=\"black\">å¹… w<br>\n","<font color=\"black\">ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å¹…ã‚’åºƒã’ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šç´°ã‹ã„ç‰¹å¾´ã‚’æ‰ãˆã‚‹ã“ã¨ãŒã§ãã¦ã€å­¦ç¿’ãŒã†ã¾ãã„ãã‚ˆã†ã«ãªã‚‹ã€‚ä¸€æ–¹ã§ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å¹…ãŒåºƒãã¦ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å±¤æ•°ãŒå°‘ãªã„å ´åˆã¯ã€è¤‡é›‘ãªç‰¹å¾´ã‚’æ‰ãˆãã‚Œãªã„ã¨ã„ã†å•é¡ŒãŒã‚ã‚‹ã€‚<br>\n","<font color=\"black\">è§£åƒåº¦ r<br>\n","<font color=\"black\">å…¥åŠ›ç”»åƒã®è§£åƒåº¦ã‚’é«˜ã‚ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šç´°ã‹ã„ç‰¹å¾´ã‚’æ‰ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br>"],"metadata":{"id":"hEpKRX501w1J"}},{"cell_type":"markdown","source":["# <font color=\"silver\">EfficientNet  3.3. Compound Scaling\n","# <font color=\"silver\">å›³4\n","ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’1ã¤ã ã‘ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã‚‹ã‚ˆã‚Šã‚‚ã€ãƒãƒ©ãƒ³ã‚¹ã‚ˆããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã—ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã—ãŸã»ã†ãŒç²¾åº¦ãŒã‚ˆã„ã€‚<br>\n","<font color=\"black\">F4. Scaling Network Width for Different Baseline Networks.<br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/n/nuka137/20200904/20200904135046.png\" width=\"400\"><br>\n","# <font color=\"silver\">å¼3\n","ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç¨‹ã‚ˆã„å…·åˆã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã•ã›ã‚‹ãŸã‚ã®å¼ã‚’ææ¡ˆã—ãŸã€‚ ã“ã‚Œã‚’ã€Compound Model Scalingã¨å‘¼ã¶ã€‚<br><br>\n","<font color=\"black\">${\\rm depth}: d=\\alpha^{\\phi}$<br>\n","<font color=\"black\">${\\rm width}: w=\\beta^{\\phi}$<br>\n","<font color=\"black\">${\\rm resolution}: r=\\gamma^{\\phi}$<br>\n","$\\alpha \\cdot \\beta^2 \\cdot \\gamma^2 \\simeq 2 \\qquad (\\alpha \\ge 1, \\beta \\ge 1, \\gamma \\ge 1)$<br>\n","<br>\n","<font color=\"black\">$\\phi$ï¼š<font color=\"silver\">åˆ©ç”¨ã§ãã‚‹è¨ˆç®—è³‡æºã®ä¸Šé™ã«åŸºã¥ã„ã¦æ±ºå®šã•ã‚Œã‚‹ã¹ããƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿<br>\n","<font color=\"black\">$Î±, Î² ,Î³$ï¼š<font color=\"silver\">Baseline Modelã«ãŠã‘ã‚‹å±¤æ•°ã€å¹…ã€è§£åƒåº¦ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä¿‚æ•°<br>\n","<font color=\"black\">$\\mathcal{F}, \\hat{L_i}, \\hat{H_i}, \\hat{W_i}, \\hat{C_i}$ï¼š<font color=\"silver\">H1ã‚’å‚è€ƒ<br>\n","<br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/n/nuka137/20200908/20200908105552.png\" width=\"400\">\n"],"metadata":{"id":"m5YXY3OO1xRR"}},{"cell_type":"markdown","source":["# <font color=\"silver\">EfficientNet  4. EfficientNet Architecture\n","# <font color=\"silver\">è¡¨1\n","<font color=\"black\">H1. EfficientNet-B0 baseline network<br>\n","<img src=\"https://camo.qiitausercontent.com/8002ee099889ab5f0378ff78e8cd7113c0c6d4a5/68747470733a2f2f696d6775722e636f6d2f4c38524231314a2e706e67\" width=\"400\"><br>"],"metadata":{"id":"RhaKpR0S1xyC"}},{"cell_type":"markdown","source":["# <font color=\"silver\">EfficientNet  5. Experiment\n","# <font color=\"silver\">è¡¨2 B0â€B7\n","<font color=\"black\">H2. EfficientNet Performance Results on ImageNet (Russakovsky et al., 2015).<br>\n","<img src=\"https://norman3.github.io/papers/images/efficient_net/t02.png\" width=\"800\"><br>\n","# <font color=\"silver\">è¡¨3\n","<font color=\"black\">H3. Scaling Up MobileNets and ResNet.<br>\n","<img src=\"https://norman3.github.io/papers/images/efficient_net/t03.png\" width=\"400\"><br>\n","# <font color=\"silver\">å›³5\n","<font color=\"black\">F5. FLOPS vs. ImageNet Accuracy<br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/n/nuka137/20200908/20200908141014.png\" width=\"400\"><br>\n","# <font color=\"silver\">è¡¨4\n","<font color=\"black\">H4. Inference Latency Comparison<br>\n","<img src=\"https://norman3.github.io/papers/images/efficient_net/t04.png\" width=\"400\"><br>\n","# <font color=\"silver\">è¡¨5\n","<font color=\"black\">H5. EfficientNet Performance Results on Transfer Learning Datasets.<br>\n","<img src=\"https://norman3.github.io/papers/images/efficient_net/t05.png\" width=\"800\"><br>\n","# <font color=\"silver\">å›³6\n","<font color=\"black\">F6. Model Parameters vs. Transfer Learning Accuracy<br>\n","<img src=\"https://norman3.github.io/papers/images/efficient_net/f06.png\" width=\"800\"><br>\n","# <font color=\"silver\">å›³7\n","<font color=\"black\">F7. Class Activation Map (CAM) (Zhou et al., 2016) for Models with different scaling methods<br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/n/nuka137/20200908/20200908142419.png\" width=\"800\"><br>\n","# <font color=\"silver\">è¡¨6\n","<font color=\"black\">H6. Transfer Learning Datasets.<br>\n","<img src=\"https://norman3.github.io/papers/images/efficient_net/t06.png\" width=\"400\"><br>\n","# <font color=\"silver\">å›³8\n","<font color=\"black\">F8. Scaling Up EfficientNet-B0 with Different Methods.<br>\n","<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/n/nuka137/20200908/20200908143507.png\" width=\"400\"><br>\n","# <font color=\"silver\">è¡¨7\n","<font color=\"black\">H7. Scaled Models Used in F7.<br>\n","<img src=\"https://norman3.github.io/papers/images/efficient_net/t07.png\" width=\"400\"><br>\n"],"metadata":{"id":"XP8lBMwt1yOJ"}},{"cell_type":"markdown","source":["# <font color=\"silver\">EfficientNet  6. Discussion"],"metadata":{"id":"eY9wRodp2Ufy"}},{"cell_type":"markdown","source":["# <font color=\"silver\">EfficientNet  7. Conclusion"],"metadata":{"id":"NtRFCeyA2foD"}},{"cell_type":"markdown","source":["# <font color=\"Blue\">â– </font><font color=\"silver\">R-CNN family [<font color=\"silver\">â€¦</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4894&cid=b0f01606242a6ed3&CT=1666717278455&OR=ItemsView)</font><br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://lilianweng.github.io/posts/2017-12-31-object-recognition-part-3/)</font></font><br>\n","<img src=\"https://lilianweng.github.io/posts/2017-12-31-object-recognition-part-3/rcnn-family-summary.png\" width=\"640\"><br>\n"],"metadata":{"id":"5A2sKu46NVnD"}},{"cell_type":"markdown","source":["# <font color=\"silver\">R-CNNï¼ˆRegion Proposalsï¼‰\n","<font color=\"silver\">Region Proposals, é ˜åŸŸå€™è£œ<br>"],"metadata":{"id":"sQ1CzRbwOAgC"}},{"cell_type":"markdown","source":["# <font color=\"silver\">R-CNNï¼ˆSelective Searchï¼‰"],"metadata":{"id":"qIUHh9NsONwj"}},{"cell_type":"markdown","source":["# <font color=\"silver\">R-CNNï¼ˆWrapï¼‰"],"metadata":{"id":"goWxivVqOXI6"}},{"cell_type":"markdown","source":["# <font color=\"silver\">R-CNNï¼ˆSVMï¼‰"],"metadata":{"id":"buy3ITuWOiwq"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SPP</font>\n","<font color=\"silver\">SPP, Spatial Pyramid Pooling, ç©ºé–“ãƒ”ãƒ©ãƒŸãƒƒãƒ‰ãƒ—ãƒ¼ãƒªãƒ³ã‚°</font>\n","<br><br>\n","<img src=\"https://axa.biopapyrus.jp/media/sppnet-desc03.png\" width=\"320\">\n","<br><br>\n","<img src=\"https://axa.biopapyrus.jp/media/sppnet-desc01.png\" width=\"320\">"],"metadata":{"id":"YElgnCTBSxrb"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Fast R-CNNï¼ˆRegion of Interestï¼‰\n","<font color=\"silver\">Region of Interest,  é–¢å¿ƒé ˜åŸŸ"],"metadata":{"id":"gl0GYpqhO6Vb"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Fast R-CNNï¼ˆSelective Searchï¼‰"],"metadata":{"id":"NHLkTy1FPLIy"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Fast R-CNNï¼ˆRoI Poolingï¼‰"],"metadata":{"id":"yNqGLK12PLaf"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Fast R-CNNï¼ˆMulti-Task Lossï¼‰"],"metadata":{"id":"UXup0bTLPLsJ"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Faster R-CNNï¼ˆRegion of Interestï¼‰\n","<font color=\"silver\">Region of Interest,  é–¢å¿ƒé ˜åŸŸ"],"metadata":{"id":"EHcJ6HAxPmyD"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Faster R-CNNï¼ˆRPNï¼‰\n","<font color=\"silver\">RPN, Region Proposal Network, é ˜åŸŸææ¡ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</font><br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://cvml-expertguide.net/terms/dl/object-detection/)</font></font><br>\n","<img src=\"https://i0.wp.com/cvml-expertguide.net/wp-content/uploads/2021/09/RPN-1.png?resize=1024%2C662&ssl=1\" width=\"480\">\n","<br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://qiita.com/shtmr/items/4283c851bc3d9721ed96)</font></font><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F62555%2F267eaff6-4462-e413-e9d7-3239f728b4a7.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=84b488754133bd3053ab85763d2d1988\" width=\"480\">\n"],"metadata":{"id":"mCfjN5RIP6dA"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Faster R-CNNï¼ˆRoI Poolingï¼‰"],"metadata":{"id":"dJ0TMLrqQBIB"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Faster R-CNNï¼ˆMulti-Task Lossï¼‰"],"metadata":{"id":"LGxc8RwRQFvy"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Mask R-CNNï¼ˆRegion of Interestï¼‰\n","<font color=\"silver\">Region of Interest,  é–¢å¿ƒé ˜åŸŸ"],"metadata":{"id":"vpSBka7fQMcC"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Mask R-CNNï¼ˆRPNï¼‰"],"metadata":{"id":"Jp0sOnQTQbOK"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Mask R-CNNï¼ˆRoI Alignï¼‰"],"metadata":{"id":"-C52a5sSQfYH"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Mask R-CNNï¼ˆBilinear Interpolationï¼‰\n","<font color=\"silver\">Bilinear Interpolation, åŒç·šå½¢è£œé–“"],"metadata":{"id":"-0xa9VBEQit4"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Multi-Task Lossï¼ˆMulti-Task Lossï¼‰"],"metadata":{"id":"ghQGf3AMQ_eg"}},{"cell_type":"markdown","source":["# <font color=\"Blue\">â– </font><font color=\"silver\">YOLOv1 [<font color=\"silver\">â€¦</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4900&cid=b0f01606242a6ed3&CT=1666717393959&OR=ItemsView) </font><br>\n","<font color=\"silver\">YOLO, You Only Look Once: Unified, Real-Time Object Detection</font><br><br>\n","â€» åˆ†å‰²ã•ã‚ŒãŸã‚°ãƒªãƒƒãƒ‰ã®ã‚µã‚¤ã‚ºã¯å›ºå®šã§ã€ã‚°ãƒªãƒƒãƒ‰å†…ã§è­˜åˆ¥ã‚¯ãƒ©ã‚¹ã¯1ã¤ã¾ã§ã€æ¤œå‡ºå¯¾è±¡ã®ç‰©ä½“ã¯2ã¤ã¾ã§ã€‚ãã®ãŸã‚ã€ã‚°ãƒªãƒƒãƒ‰å†…ã®ç‰©ä½“ãŒå¤§é‡ã®å ´åˆã¯ã€ç²¾åº¦ãŒä¸‹ãŒã‚‹<br>\n","â€» ã‚µã‚¤ã‚ºã®å°ã•ãªç‰©ä½“ã®æ¤œå‡ºã‚’è‹¦æ‰‹ã¨ã—ã¦ãŠã‚Šã€ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ»ãƒœãƒƒã‚¯ã‚¹ã‚’å€‹åˆ¥ã«åˆ†æã§ãã‚‹Faster R-CNNã«æ¯”ã¹ã¦ã€è­˜åˆ¥ã®ç²¾åº¦ãŒä½ã„ã€‚<br>\n","â€» é ˜åŸŸæ¢ç´¢ã¨ã‚¯ãƒ©ã‚¹åˆ†é¡ã‚’åŒæ™‚ã«å®Ÿè¡Œã—ã€ç‰©ä½“æ¤œå‡ºã‚’åˆ†é¡å•é¡Œã§ã¯ãªãå›å¸°å•é¡Œæ¨å®šã‚’è¡Œã†<br>\n","â€» æ¤œå‡ºã¨è­˜åˆ¥ã‚’åŒæ™‚ã«è¡Œã†ã“ã¨ã§å‡¦ç†é€Ÿåº¦ã‚’æ—©ã‚ãŸ<br>\n","â€» ç”»åƒå…¨ä½“ã«å¯¾ã—ã¦ç‰¹å¾´ãƒãƒƒãƒ—ã‚’ç”Ÿæˆã—ã¦ã„ããŸã‚ã€æ±åŒ–åˆ¶åº¦ãŒé«˜ã„<br>\n","â€» å°ã•ã„ç”»åƒã®æ¤œå‡ºã¯ä¸å¾—æ„ãªéƒ¨åˆ†ãŒã‚ã‚Šã€å¯†æ¥ã—ãŸå¯¾è±¡ã®è­˜åˆ¥ã«ã¯å‘ã„ã¦ã„ãªã„<br>\n","<br>"],"metadata":{"id":"AlwrOHr2I2G9"}},{"cell_type":"markdown","source":["# <font color=\"silver\">YOLOv1   1 Introduction èƒŒæ™¯\n","â€» ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°windowã‚„region proposalã¨ã„ã£ãŸé ˜åŸŸã‚¹ã‚­ãƒ£ãƒ³ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä½¿ã‚ãšã«ã€ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ç”»åƒå…¨ä½“ã‹ã‚‰ç›´æ¥ç‰©ä½“ã‚‰ã—ã•ã¨ä½ç½®ã‚’ç®—å‡ºã™ã‚‹ã€‚<br>\n","â€»ã¾ãšå…¥åŠ›ç”»åƒã‚’æ­£æ–¹å½¢(è«–æ–‡ã®ä¾‹ã§ã¯448Ã—448)ã«ãƒªã‚µã‚¤ã‚ºã—ã€ãã‚Œã‚’ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å…¥åŠ›ã¨ã™ã‚‹ã€‚<br>\n","<br>\n","<img src=\"https://tech-swim-bike.info/wp-content/uploads/2022/02/YoLo-2.png\" width=\"480\"><br>\n"],"metadata":{"id":"3HC75u4PJ0Rw"}},{"cell_type":"markdown","source":["# <font color=\"silver\">YOLOv1   2. Unified Detection\n","â€» S Ã— S ã®å„ grid cell ã«å¯¾ã—ã¦ã€Bå€‹ã® Bounding Box ã‚’æ¨å®šã™ã‚‹ã€‚Sã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ±ºã‚ã‚‹ã€‚è«–æ–‡ã§ã¯ï¼—Ã—ï¼—ã€‚<br>\n","â€» 1ã¤ã®Bounding Boxã«ã¤ãã€Bounding Boxã®åº§æ¨™å€¤(x, y, w, h)ã¨ã€ãã®Bounding BoxãŒç‰©ä½“ã§ã‚ã‚‹ä¿¡é ¼åº¦(confidence)ã‚¹ã‚³ã‚¢ã®è¨ˆ5ã¤ã®å€¤ã‚’å‡ºåŠ›ã™ã‚‹ã€‚<br>\n","â€» åº§æ¨™å€¤ã®x, yã¯grid cellã®å¢ƒç•Œã‚’åŸºæº–ã«ã—ãŸBounding Boxã®ä¸­å¿ƒåº§æ¨™ã€å¹…wã¨é«˜ã•hã¯ç”»åƒå…¨ä½“ã®ã‚µã‚¤ã‚ºã«å¯¾ã™ã‚‹ç›¸å¯¾å€¤ã€‚ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã¯ãã®Bounding BoxãŒç‰©ä½“ã‹èƒŒæ™¯ã‹ã®ç¢ºç‡ã‚’è¡¨ã™ã€‚(ç‰©ä½“ãªã‚‰1, èƒŒæ™¯ãªã‚‰0)<br>\n","<font color=\"black\"><br>\n","$\\rm Confidence = Pr(Object) * IoU$ <font color=\"silver\">ç‰©ä½“ãŒå«ã¾ã‚Œã¦ã„ã‚‹æ™‚ã®äºˆæ¸¬æ¤œå‡ºä½ç½®ã®æ­£ç¢ºæ€§\n","<br><br><font color=\"black\">\n","$\\rm C = Pr(Class|Object)$\n","<br><br>\n","$\\rm Confidence Score = C * Pr(Object) * IoU$\n","<br><br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://blog.negativemind.com/2019/02/21/general-object-recognition-yolo/)</font></font><br>\n","<img src=\"https://blog.negativemind.com/wp-content/uploads/2019/02/YOLO_detection.jpg\" width=\"640\"><br>\n","<img src=\"https://tech-swim-bike.info/wp-content/uploads/2022/02/YoLo-1.png\" width=\"480\"><br>"],"metadata":{"id":"kRfr8O9BJ0ub"}},{"cell_type":"markdown","source":["# <font color=\"silver\">YOLOv1   2.1. Network Design, Darknet\n","â€» 24å±¤ã®CNNã¨ï¼”å±¤ã®Poolingå±¤ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã€ï¼’å±¤ã®å…¨çµåˆå±¤ã§ç‰©ä½“ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã¨ç‰©ä½“ã®ç¨®é¡ã®ç¢ºç‡ã‚’æ¨å®šã™ã‚‹ã€‚<br>\n","â€» ç•³ã¿è¾¼ã¿å±¤ã®æœ€çµ‚å‡ºåŠ›ã‚µã‚¤ã‚º7Ã—7ã¯grid cellã®åˆ†å‰²æ•°ã¨ä¸€è‡´ã™ã‚‹ã€‚<br>\n","â€» YOLOã®å‡ºåŠ›ã¯ã€1ã¤ã®grid cellã«ã¤ãB Ã— 5 + Cå€‹ã®å‡ºåŠ›ã¨ãªã‚Šã€å…¨ä½“ã®å‡ºåŠ›ã¯S Ã— S Ã— (B Ã— 5 + C)å€‹<br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F296108%2F53abd9cc-4633-44b6-7592-9854437bb64b.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=e6a4fcfaee4209aa78e21ae225b06921\" width=\"640\"><br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/#yolo-you-only-look-once)</font></font><br>\n","<img src=\"https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/yolo-network-architecture.png\" width=\"640\">\n","<br><br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://human-blog.com/yolocommentary3/)</font></font><br>\n","<img src=\"https://human-blog.com/wp-content/uploads/2022/05/Screen-Shot-2022-05-17-at-19.29.43-1024x457.png\" width=\"640\">\n","<br><br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://human-blog.com/yolocommentary3/)</font></font><br>\n","<img src=\"https://human-blog.com/wp-content/uploads/2022/05/CE471F42-AA15-41CF-95F7-E5D31BF5FD84.png\" width=\"640\"><br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://wikidocs.net/167502)</font></font><br>\n","<img src=\"https://wikidocs.net/images/page/163644/Fig_8.png\" width=\"640\"><br>\n","<img src=\"https://wikidocs.net/images/page/163644/Fig_9.png\" width=\"640\"><br><br>"],"metadata":{"id":"TohMbbLOJ1By"}},{"cell_type":"markdown","source":["# <font color=\"silver\">YOLOv1   2.2. Training\n","â€» æœ€çµ‚å±¤ã®ReLUã‚’é™¤ã„ã¦æ´»æ€§åŒ–å±¤ã¯Leaky ReLUã‚’åˆ©ç”¨ã™ã‚‹ã€‚<br>\n","â€» æå¤±é–¢æ•°ã¯ã€Localization Loss and Classification Loss<br>\n","â€» ã€Œ(1)ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ãƒœãƒƒã‚¯ã‚¹ã®æå¤±ã€ï¼‹ã€Œ(2)ä¿¡é ¼åº¦ã®æå¤±ã€ï¼‹ã€Œ(3)ã‚¯ãƒ©ã‚¹è­˜åˆ¥æå¤±ï¼ˆäº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼‰ã€ã®ï¼“ã¤ã‚’é‡ã¿ã¥ã‘ã—ãŸåˆæˆæå¤±<br><br>\n","<font color=\"black\">${ \\phi(x) = \\begin{cases} x, \\quad if \\quad x>0 \\\\ 0.1x, \\quad {\\rm otherwise} \\end{cases}}$\n","<br><br>\n","$\\mathcal{L}_{YOLOv1}= \\mathcal{L}_{BB} + \\lambda_1 \\mathcal{L}_{conf} +\\lambda_2  \\mathcal{L}_{CE}$\n","<br><br>\n","$\\mathcal{L} = \\mathcal{L}_\\text{loc} + \\mathcal{L}_\\text{cls}$\n","<br><br>\n"," $\\begin{aligned}\n","\\mathcal{L}_\\text{loc} = \\lambda_\\text{coord} \\sum_{i=0}^{S^2} \\sum_{j=0}^B \\mathbb{1}_{ij}^\\text{obj} [(x_i - \\hat{x}_i)^2 + (y_i - \\hat{y}_i)^2 + (\\sqrt{w_i} - \\sqrt{\\hat{w}_i})^2 + (\\sqrt{h_i} - \\sqrt{\\hat{h}_i})^2 ]\n","\\end{aligned}$\n","<br><br>\n"," $\\begin{aligned}\n","\\mathcal{L}_\\text{cls}  = \\sum_{i=0}^{S^2} \\sum_{j=0}^B \\big( \\mathbb{1}_{ij}^\\text{obj} + \\lambda_\\text{noobj} (1 - \\mathbb{1}_{ij}^\\text{obj})\\big) (C_{ij} - \\hat{C}_{ij})^2 + \\sum_{i=0}^{S^2} \\sum_{c \\in \\mathcal{C}} \\mathbb{1}_i^\\text{obj} (p_i(c) - \\hat{p}_i(c))^2\n","\\end{aligned}$\n","<br><br>\n","<img src=\"https://camo.qiitausercontent.com/4669cb72cfdf272a36e9958db40523743387a1a9/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3337323138322f37393332653335622d353331362d373436352d373032612d3937343031613462633966652e706e67\" width=\"480\">"],"metadata":{"id":"rUnmaPi1J1UL"}},{"cell_type":"markdown","source":["# <font color=\"silver\">YOLOv1   2.3. Inference\n","<font color=\"black\">NMS, Non-Maximum Suppression\n","<br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://human-blog.com/yolocommentary3/)</font></font><br>\n","<img src=\"https://human-blog.com/wp-content/uploads/2022/05/Screen-Shot-2022-05-22-at-11.17.03-1536x715.png\" width=\"320\">"],"metadata":{"id":"ZM_1ssauJ1pd"}},{"cell_type":"markdown","source":["# <font color=\"silver\">YOLOv1   3. Comparison to Other Detection Systems"],"metadata":{"id":"XpelwRoHJ2La"}},{"cell_type":"markdown","source":["# <font color=\"silver\">YOLOv1   4. Experiments"],"metadata":{"id":"NFVoX3GwJ2e6"}},{"cell_type":"markdown","source":["# <font color=\"silver\">YOLOv1   4.1. Comparison to Other Real-Time Systems"],"metadata":{"id":"gBWK3gAsJ2yq"}},{"cell_type":"markdown","source":["# <font color=\"silver\">YOLOv1   4.2. VOC 2007 Error Analysis"],"metadata":{"id":"4SmCe8jGJ3FD"}},{"cell_type":"markdown","source":["# <font color=\"silver\">YOLOv1   4.3. Combining Fast R-CNN and YOLO"],"metadata":{"id":"cmtU_m5hKJ-l"}},{"cell_type":"markdown","source":["# <font color=\"silver\">YOLOv1   4.4. VOC 2012 Results"],"metadata":{"id":"GdKZwrh7KKV6"}},{"cell_type":"markdown","source":["# <font color=\"silver\">YOLOv1   4.5. Generalizability: Person Detection in Artwork"],"metadata":{"id":"_bQwdf5lKVTk"}},{"cell_type":"markdown","source":["# <font color=\"silver\">YOLOv1   5. Real-Time Detection In The Wild"],"metadata":{"id":"2INj5XvdKVn5"}},{"cell_type":"markdown","source":["# <font color=\"silver\">YOLOv1   6. Conclusion"],"metadata":{"id":"sNju5Ww-Ka-M"}},{"cell_type":"markdown","source":["# <font color=\"Blue\">â– </font><font color=\"silver\">SSD [<font color=\"silver\">â€¦</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4904&cid=b0f01606242a6ed3&CT=1666717577682&OR=ItemsView) </font><br>\n","<font color=\"silver\">SSD, Single Shot MultiBox Detector</font><br>"],"metadata":{"id":"oexG4l_lDBDj"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SSD  1 Introduction èƒŒæ™¯\n"],"metadata":{"id":"T6pEV0toEio0"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SSD  2 The Single Shot Detector (SSD)\n","<img src=\"https://camo.qiitausercontent.com/1f6ef47cc3e6e3298d4ddf48b55e600a3d0e821c/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3231313731322f65616530383430362d363530352d626165662d666139322d3537613632643364303561632e706e67\" width=\"640\"><br>"],"metadata":{"id":"FthsMEbjEi9J"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SSD  2.1 Model\n","<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/455946/0e56b7b4-9e62-f28d-3655-336d429f4e83.png\" width=\"640\"><br>"],"metadata":{"id":"99bUELa8EjO5"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SSD  2.2 Training\n","â€» ä¿¡é ¼åº¦(confidence)æå¤±(3.2.1ç¯€)ã¨é ˜åŸŸæ¤œå‡º(localization)æå¤± (3.2.2ç¯€)ã®ï¼Œ2ã‚¿ã‚¹ã‚¯ã®æå¤±ã‚’åˆæˆã—ãŸï¼Œä»¥ä¸‹ã®Multiboxæå¤±é–¢æ•°</font><br><br>\n","$L(x, c, l, g) = \\cfrac{1}{N}(L_{CLS}(x, c) + \\alpha L_{LOC}(x, l, g))$<br><br>\n","${\\begin{aligned}\n","L_{\\mathrm{loc}}(x,l,g)\n","&= \\sum_{k=1}^p\\sum_{i\\in \\mathrm{Default Box}}\\sum_{j\\in \\mathrm{GT Box}} \\sum_{m\\in (cx, cy, w, h)} x_{ij}^k \\mathrm{smooth}_{\\mathrm{L1}}(l_i^m- \\hat g_j^m) \\\\\n","\\hat g_j^{\\mathrm{cx}} &= \\frac{g_j^{\\mathrm{cx}} - d_i^{\\mathrm{cx}}}{d_i^{\\mathrm y}} \\\\\n","\\hat g_j^{\\mathrm{cy}} &= \\frac{g_j^{\\mathrm{cy}} - d_i^{\\mathrm{cy}}}{d_i^{\\mathrm h}} \\\\\n","\\hat g_j^{\\mathrm w} &= \\log \\frac{g_j^{\\mathrm w} }{d_i^{\\mathrm w} } \\\\\n","\\hat g_j^{\\mathrm h} &= \\log \\frac{g_j^{\\mathrm h} }{d_i^{\\mathrm h} }\n","\\end{aligned}\n","}$<br><br>\n","${\\begin{aligned}\n","L_{\\mathrm{conf}}(x,c) &=\n","-\\sum_{k=1}^p\\sum_{i\\in \\mathrm{Default Box}}\\sum_{j\\in \\mathrm{GT Box}}  x_{ij}^k \\log(\\hat c_i^k) - \\sum_{i\\in \\mathrm{Default Box}}\\log(\\hat c_i^0)\\prod_{k=1}^p\\prod_{j\\in \\mathrm{GT Box}}(1-x_{ij}^k ) \\\\\n","\\hat c_i^k &= \\frac{\\exp(c_i^k)}{\\sum_k \\exp(c_i^k)}\n","\\end{aligned}\n","}$\n","<br><br>\n","$\\displaystyle {s_k = s_{\\mathrm{min}} + \\frac{s_{\\mathrm{max}} - s_{\\mathrm{min}}\n","}{m-1}(k-1), \\ k \\in [1,m]\n","}$"],"metadata":{"id":"RtOo_10FEjfZ"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SSD  3 Experimental Results"],"metadata":{"id":"pGlTeCSQEjwx"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SSD  3.1 PASCAL VOC2007"],"metadata":{"id":"aI14w0B0EkBI"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SSD  3.2 Model analysis"],"metadata":{"id":"1b1xV7FpEkSp"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SSD  3.3 PASCAL VOC2012"],"metadata":{"id":"LHV5muyXEkkq"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SSD  3.4 COCO"],"metadata":{"id":"ua3V53o4EvVF"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SSD  3.5 Preliminary ILSVRC results"],"metadata":{"id":"gQihDdC7Evoq"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SSD  3.6 Data Augmentation for Small Object Accuracy"],"metadata":{"id":"hTvpj9itEv5o"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SSD  3.7 Inference time"],"metadata":{"id":"FPGNPdukFAfE"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SSD  4 Related Work"],"metadata":{"id":"DDZS7o7_FAv4"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SSD  5 Conclusions"],"metadata":{"id":"nLmOPYXCFBDo"}},{"cell_type":"markdown","source":["# <font color=\"silver\">SSD  6 Acknowledgment"],"metadata":{"id":"X2cis9wJFXKi"}},{"cell_type":"markdown","source":["# <font color=\"Blue\">â– </font><font color=\"silver\">FCOS  [<font color=\"silver\">â€¦</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4906&cid=b0f01606242a6ed3&CT=1666771227100&OR=ItemsView) </font><br>\n","<font color=\"silver\">FCOS, Fully Convolutional One-Stage Object Detection</font><br><br>\n","> â€» FPNã‚’ç”¨ã„ã¦è¤‡æ•°ã®ã‚¹ã‚±ãƒ¼ãƒ«ã§æŠ½å‡ºã—ãŸç‰¹å¾´ãƒãƒƒãƒ—ã«ã€Œheadã€ã‚’è¿½åŠ ã—ã¦ã€ã‚¯ãƒ©ã‚¹åˆ†é¡ã€BBå›å¸°ã¨ã‚»ãƒ³ã‚¿ãƒ¼ãƒã‚¹ã‚’å­¦ç¿’ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã€‚<br>\n","> â€» è¤‡æ•°ã®ã‚¯ãƒ©ã‚¹ã«å½“ã¦ã¯ã¾ã‚‹ç‚¹ã¸ã®å¯¾å‡¦<br>\n","> â€» Feature Pyramid ã‚’ç”¨ã„ã¦ã€ç•°ãªã‚‹ãƒ¬ãƒ™ãƒ«ã®ç‰¹å¾´ãƒãƒƒãƒ—ã‚’è¤‡æ•°å‡ºåŠ›ã—ã€ãã‚Œãã‚Œã®ç‰¹å¾´ãƒãƒƒãƒ—ã§ã€ç•°ãªã‚‹ã‚µã‚¤ã‚ºã®ç‰©ä½“ã‚’æ¤œå‡ºã™ã‚‹<br>\n","> â€» ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒ«æ•°ã¨ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒ«æ•°(æ¤œå‡ºç‰©ã¨èƒŒæ™¯)ã®ä¸å‡è¡¡ã‚’æ”¹å–„ã—ã¦ã„ã‚‹ã€‚<br>\n","<br>\n","<img src=\"https://user-images.githubusercontent.com/24524018/88918758-f8459280-d2a4-11ea-9119-175abfa056b8.png\" width=\"480\">"],"metadata":{"id":"zLX0biKD3RqN"}},{"cell_type":"markdown","source":["# <font color=\"silver\">FCOS  1. èƒŒæ™¯â˜…\n","\n"],"metadata":{"id":"_lXqfF_X3R8m"}},{"cell_type":"markdown","source":["# <font color=\"silver\">FCOS  2. é–¢é€£ç ”ç©¶â˜…\n","\n"," ã‚¢ãƒ³ã‚«ãƒ¼ãƒœãƒƒã‚¯ã‚¹ã®æ¬ ç‚¹<br>\n","> â€» ã‚¢ãƒ³ã‚«ãƒ¼ãƒœãƒƒã‚¯ã‚¹ã®ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚„æ•°ãŒã€äºˆæ¸¬ç²¾åº¦ã«å½±éŸ¿ã™ã‚‹<br>\n","> â€» ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ãƒãƒƒãƒ—ã”ã¨ã«ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚‹<br>\n","> â€» ã‚¢ãƒ³ã‚«ãƒ¼ãƒœãƒƒã‚¯ã‚¹ã®ã»ã¨ã‚“ã©ã¯ã€äºˆæ¸¬æ™‚ã«æ¡ç”¨ã•ã‚Œãªã„<br>\n","> â€» å…¨ã¦ã®ã‚¢ãƒ³ã‚«ãƒ¼ãƒœãƒƒã‚¯ã‚¹ã® IoU ã‚’è¨ˆç®—ã™ã‚‹å¿…è¦ã‚ã‚‹ãŸã‚è¨ˆç®—è² è·ãŒå¤§ãã„<br>\n","> â€» ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒ«æ•°ã¨ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒä¸å‡è¡¡ãªçŠ¶æ…‹<br>\n"],"metadata":{"id":"kb3LvyCp3SPS"}},{"cell_type":"markdown","source":["# <font color=\"silver\">FCOS  Anchor-free Detectors"],"metadata":{"id":"t-ET4vwA3SiB"}},{"cell_type":"markdown","source":["# <font color=\"silver\">FCOS  3. Our Approach"],"metadata":{"id":"SFwnpMP43UF0"}},{"cell_type":"markdown","source":["# <font color=\"silver\">FCOS  3.1. Fully Convolutional One-Stage Object Detectorâ˜…\n",">$\\begin{cases}l^{\\ast} = x - x^{(i)}_0, t^\\ast = y - y^{(i)}_0 \\\\ r^\\ast = x^{(i)}_1 - x, b^\\ast = y^{(i)}_1 - y  \\end{cases} $\n"],"metadata":{"id":"KVRjFXX23dSS"}},{"cell_type":"markdown","source":["# <font color=\"silver\">FCOS  Network Outputs."],"metadata":{"id":"3BVXvHaY3dsr"}},{"cell_type":"markdown","source":["# <font color=\"silver\">FCOS  Loss Function.â˜…</font>\n","> â€» å„ç‰¹å¾´é‡ãƒãƒƒãƒ—ã®ä½ç½®ijã«ãŠã„ã¦ã€æ­£ã—ã„Bounding boxã¨ã®ä¸Šä¸‹å·¦å³ã®è·é›¢ã‚’å›å¸°ã•ã›ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ãŸã€‚</font><br>\n","> â€» ã‚¯ãƒ©ã‚¹åˆ†é¡ã«é–¢ã™ã‚‹æå¤± + ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®åº§æ¨™ã«é–¢ã™ã‚‹æå¤±<br>\n","> â€» ã“ã‚Œã«ã‚ˆã‚Šã‚¢ãƒ³ã‚«ãƒ¼ãŒä¸è¦ã«ãªã‚‹ã€‚<br>\n","<br>\n","<img src=\"https://user-images.githubusercontent.com/24524018/88918650-c7655d80-d2a4-11ea-8a04-32ade7894a88.png\" width=\"480\">\n","<br><font color=\"Black\">\n","<br>\n","ç¬¬ 1 é …ï¼š<font color=\"silver\">ã‚¯ãƒ©ã‚¹åˆ†é¡ã«é–¢ã™ã‚‹æå¤±<br></font>\n","ç¬¬ 2 é …ï¼š<font color=\"silver\">ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®åº§æ¨™ã«é–¢ã™ã‚‹æå¤±<br></font>\n","<br>\n","$p_{x,y}$ï¼š<font color=\"silver\">ã‚¯ãƒ©ã‚¹åˆ†é¡ã®äºˆæ¸¬ç¢ºç‡<br></font>\n","$c_{x,y}^*$ï¼š<font color=\"silver\">æ­£è§£ã®ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«<br></font>\n","$t_{x,y}$ï¼š<font color=\"silver\">(l, r, t, b)ã®äºˆæ¸¬çµæœ<br></font>\n","$t_{x,y}^*$ï¼š<font color=\"silver\">æ­£è§£ã®$t_{x,y}$<br></font>\n","$1_{c_{x,y}^*>0}$ï¼š<font color=\"silver\">ç‰©ä½“ãŒå­˜åœ¨ã™ã‚‹ã¨ãã¯1<br></font>\n","$N_{pos}$ï¼š<font color=\"silver\">ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®å€‹æ•°<br></font>\n","<br>\n","$\\displaystyle L(\\{\\vec p_{x, y}\\}, \\{\\vec t_{x, y}\\}) = \\frac{1}{N_{pos}} \\sum_{x,y} L_{cls}(\\vec p_{x, y}, c^{\\ast}_{x, y}) + \\frac{\\lambda}{N_{pos}} \\sum_{x,y} I_{c^\\ast_{x,y} > 0} L_{reg} (\\vec t_{x, y}, \\vec t^\\ast_{x,y}) $"],"metadata":{"id":"P36EdE0j5m1V"}},{"cell_type":"markdown","source":["# <font color=\"silver\">FCOS  Inference"],"metadata":{"id":"lXBmZNfj3eCC"}},{"cell_type":"markdown","source":["# <font color=\"silver\">FCOS  3.2. Multi-level Prediction with FPN for FCOSâ˜…\n","> â€» FPNã‚’ç”¨ã„ã¦è¤‡æ•°ã®ã‚¹ã‚±ãƒ¼ãƒ«ã§ç‰¹å¾´é‡ãƒãƒƒãƒ—ã®æŠ½å‡ºã‚’è¡Œã„ã€ãƒ¬ãƒ™ãƒ«ã”ã¨(P3ã€œP7)ã«äºˆæ¸¬ã™ã‚‹ã“ã¨ã§ã€ã•ã¾ã–ã¾ãªã‚¹ã‚±ãƒ¼ãƒ«ã®ç‰¹å¾´ã‚’æ‰ãˆã‚‹ã€‚<br>\n","> â€» FCN ã¨åŒæ§˜ã«ã€å…¨çµåˆå±¤ã‚’æŒãŸãªã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€‚<br>\n","> â€» å‡ºåŠ›ãƒ†ãƒ³ã‚½ãƒ«ã®è¦ç´ ã¯ã€ç‰¹å¾´ãƒãƒƒãƒ—ä¸Šã®å„ç‚¹ã«é–¢ã™ã‚‹å€¤ã€‚<br>\n","> ï¼ˆä¸Šï¼‰ã‚¯ãƒ©ã‚¹ã‚’å‡ºåŠ›ã€‚<br>\n","> ï¼ˆä¸­ï¼‰ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®ä¸­å¿ƒã«å¯¾ã™ã‚‹ã‚ºãƒ¬ã‚’å‡ºåŠ›ã€‚<br>\n","> ï¼ˆä¸‹ï¼‰ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®å„è¾ºã¾ã§ã®è·é›¢ã‚’å‡ºåŠ›ã€‚<br><br>\n","<img src=\"https://user-images.githubusercontent.com/24524018/88918756-f67bcf00-d2a4-11ea-9549-cb7a28a3c4b3.png\" width=\"800\">\n","<br><br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦</font>](https://www.researchgate.net/figure/Network-structure-of-Tiny-FCOS_fig1_355699312)</font><br>\n","<img src=\"https://www.researchgate.net/publication/355699312/figure/fig1/AS:1123578456088597@1644893387688/Network-structure-of-Tiny-FCOS.png\" width=\"640\">"],"metadata":{"id":"aGUgAWYl3eYS"}},{"cell_type":"markdown","source":["# <font color=\"silver\">FCOS  3.3. Center-ness for FCOSâ˜…\n","<font color=\"silver\">Center-ness for FCOS\n","> â€» ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ãƒãƒƒãƒ—ä¸Šã®ç‚¹ã¨ ground truth ã®ä¸­å¿ƒè·é›¢ã‚’æ•°å€¤åŒ–ã—ãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€‚<br>\n","> â€» ç‰¹å¾´ãƒãƒƒãƒ—ä¸Šã®ã‚ã‚‹ç‚¹ãŒæ­£è§£ãƒœãƒƒã‚¯ã‚¹ã®ä¸­å¿ƒã‹ã‚‰ã©ã‚Œãã‚‰ã„é›¢ã‚Œã¦ã„ã‚‹ã‹ã‚’è¡¨ã™æŒ‡æ¨™ã€‚<br>\n","> â€» å­¦ç¿’ã«ãŠã„ã¦æå¤±ã¯ BCELoss:Binary Cross Entropyã«ã‚ˆã£ã¦è¨ˆç®—ã•ã‚Œã‚‹ã€‚<br><br>\n","> â€» FCOS ã§ã¯ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ãƒãƒƒãƒ—ä¸Šã® ground truth å†…ã«å…¥ã‚‹å…¨ã¦ã®ç‚¹ã¯ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒ«(ç‰©ä½“ãŒå­˜åœ¨ã™ã‚‹é ˜åŸŸ)ã¨ã—ã¦æ‰±ã†ã€‚ãã®ãŸã‚ã€ç‰©ä½“ã®ä¸­å¿ƒã‹ã‚‰é›¢ã‚ŒãŸç‚¹ã‚’ä¸­å¿ƒã¨ã—ãŸãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãŒäºˆæ¸¬ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚ãã®æ§˜ãªçŠ¶æ³ã‚’é˜²ããŸã‚ã€ FCOS ã§ã¯ Center-ness ã¨ã„ã†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å­¦ç¿’ã«åŠ ãˆã€ä½å“è³ªãªãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãŒä½œæˆã•ã‚Œã‚‹ã“ã¨ã‚’æŠ‘åˆ¶ã™ã‚‹ã€‚<br>\n","> â€» ï¼ˆ $l, t, r, b$ ï¼‰ã§è¨ˆç®—ã™ã‚‹ 0ã€œ1ã®å€¤ã§ã€å€¤ãŒå¤§ãã„ã»ã©ã€æ­£è§£ãƒœãƒƒã‚¯ã‚¹ã®ä¸­å¿ƒã«ä½ç½®ã™ã‚‹ã€‚<br>\n","> â€» ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹äºˆæ¸¬ã®éš›ã€ã‚»ãƒ³ã‚¿ãƒ¼ãƒã‚¹ã®ä½ã„ç‚¹ã¯NMSã«ã‚ˆã‚Šãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã€‚<br>\n","> â€» æ­£è§£ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‹ã‚‰é›¢ã‚ŒãŸä½ç½®ã«äºˆæ¸¬ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãŒå‡ºç¾ã™ã‚‹ã“ã¨ã‚’æŠ‘åˆ¶<br>\n","> â€» å­¦ç¿’æ™‚ã«ã€æ­£è§£ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã«å¯¾å¿œã™ã‚‹äºˆæ¸¬ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹(æ­£ã®ã‚µãƒ³ãƒ—ãƒ«)ãŒå¤šããªã‚Šã€å­¦ç¿’åŠ¹ç‡ãŒä¸ŠãŒã‚‹<br>\n","<br><font color=\"black\">\n","$\\displaystyle {\\rm centerness}^\\ast = \\sqrt{\\frac{\\min(l^\\ast, r^\\ast)}{\\max(l^\\ast, r^\\ast)} \\times \\frac{\\min(t^\\ast, b^\\ast)}{\\max(t^\\ast, b^\\ast)}} $\n","<br><br>\n","ï¼ˆ $l^*, t^*, r^*, b^*$ ï¼‰ï¼š<font color=\"silver\">ã‚ã‚‹ç‚¹ã‹ã‚‰ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®å„è¾ºã¾ã§ã®è·é›¢<br><br>\n","<img src=\"https://user-images.githubusercontent.com/24524018/88918747-f1b71b00-d2a4-11ea-8faa-1892f21c064b.png\" width=\"320\">"],"metadata":{"id":"t5O-D7zd4Xom"}},{"cell_type":"markdown","source":["# <font color=\"silver\">FCOS  4. Experiments"],"metadata":{"id":"SRjacsun4YFj"}},{"cell_type":"markdown","source":["# <font color=\"silver\">FCOS  5. Extensions on Region Proposal Networks"],"metadata":{"id":"sM54Evyw5Dzd"}},{"cell_type":"markdown","source":["# <font color=\"silver\">FCOS  6. Conclusion"],"metadata":{"id":"mFHGkLkF5IeM"}},{"cell_type":"markdown","source":["#<font color=\"Blue\">**â– **</font> <font color=\"silver\">Transformer [<font color=\"silver\">â€¦](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4673&cid=b0f01606242a6ed3&CT=1666551601096&OR=ItemsView)</font><br>\n","https://arxiv.org/pdf/1706.03762.pdf"],"metadata":{"id":"o8ZgIoBnlcZd"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Transformer 1 Introduction å°å…¥ <br>"],"metadata":{"id":"yE5a1Kgfmwqd"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Transformer 2 Background èƒŒæ™¯ <br>"],"metadata":{"id":"duGjAOO4my8v"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Transformer 3 Model Architecture<br>\n","><font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦</font>](https://lilianweng.github.io/posts/2018-06-24-attention/)</font><br>\n","<img src=\"https://lilianweng.github.io/posts/2018-06-24-attention/transformer.png\" width=\"640\"><br>\n","<br>\n","<font color=\"Blue\">**Layer Normalization**</font><br>\n","><font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html)</font><br>\n","<img src=\"https://lena-voita.github.io/resources/lectures/seq2seq/transformer/layer_norm-min.png\" width=\"320\">\n"],"metadata":{"id":"W7y6Csl9m3yL"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Transformer 3.1 Encoder and Decoder Stacks<br>\n","><font color=\"Blue\">**Encoder and Decoder**</font><br>\n","><font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦</font>](https://nlpillustration.tech/?p=2171)</font><br>\n","<img src=\"https://nlpillustration.tech/wp-content/uploads/2022/08/Transformer6-770x770.jpg\" width=\"480\">"],"metadata":{"id":"akIo8vEGm5bD"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Transformer 3.2 Attention<br></font>"],"metadata":{"id":"PFIEt2iUm7UU"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Transformer 3.2.1 Scaled Dot-Product Attention<br></font>\n","><font color=\"Blue\">**Scaled Dot-Product Attention**</font><br>\n","> â€» $\\sqrt{d_k}$ã§å‰²ã‚‹ç†ç”±<br>\n","> ãƒ» $\\sqrt{d_k}$ã¯query, keyã®å˜èªåˆ†æ•£è¡¨ç¾ã®æ¬¡å…ƒæ•°ã§ã€è«–æ–‡ã§ã¯512<br>\n","> ãƒ» ç¢ºç‡ãŒä½ã„éƒ¨åˆ†ã®å‹¾é…æƒ…å ±ã‚’ä¿æŒã™ã‚‹ãŸã‚</font><br>\n","> ãƒ» $\\sqrt{d_k}$ ãŒå¤§ãããªã‚‹ã¨é€†ä¼æ’­æ™‚ã®ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹é–¢æ•°ã®å‹¾é…ãŒå°ã•ããªã‚‹ãŸã‚ã€ å­¦ç¿’ãŒå††æ»‘ã«é€²ã¾ãªããªã‚‹</font><br>\n","<br>\n","$\\rm{ScaledDotProductAttention}(\\boldsymbol{Q}, \\boldsymbol{K}, \\boldsymbol{V}) = \\rm{softmax}\\left(\\cfrac{\\boldsymbol{QK}^T}{\\sqrt{d_k}}\\right)\\boldsymbol{V}$<br>\n","<br>\n","<img src=\"https://production-media.paperswithcode.com/methods/SCALDE.png\" width=\"200\"><br>"],"metadata":{"id":"K66PsnrIm9C1"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Transformer 3.2.2 Multi-Head Attention <br>\n","><font color=\"Blue\">**Multi-Head Attention**</font><br>\n","<br>\n",">$\\begin{eqnarray} \\rm{MultiHead Attention}(\\boldsymbol{Q}, \\boldsymbol{K}, \\boldsymbol{V}) &=& \\rm{Concat}(head_1, head_2, \\cdots, head_h)\\boldsymbol{W}_o\\\\ \\rm{where}\\ head_i &=& \\rm{ScaledDotProductAttention}(\\boldsymbol{QW}^Q_i, \\boldsymbol{KW}^K_i, \\boldsymbol{VW}^V_i) \\end{eqnarray}$<br>\n","<br>\n","ãŸã ã—ã€$W_i^Q, W_i^K \\in \\mathbb{R}^{d_{model} \\times d_k}, W_i^V \\in \\mathbb{R}^{d_{model} \\times d_v}, W^O \\in \\mathbb{R}^{hd_v \\times d_{model}}$\n","<br><br>\n","<img src=\"https://production-media.paperswithcode.com/methods/multi-head-attention_l1A3G7a.png\" width=\"200\">\n","<br>"],"metadata":{"id":"9p3OFL3mnAc6"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Transformer 3.2.3 Applications of Attention in our Model <br></font>\n","># <font color=\"silver\">ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ ãƒ¼ ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã®Attention\n","> â€» Queryã¯ãƒ‡ã‚³ãƒ¼ãƒ€å†…å‰å±¤ã®å‡ºåŠ›ã€Keyã¨Valueã¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®æœ€çµ‚å‡ºåŠ›ã€‚ã™ãªã‚ã¡ã€ç³»åˆ—å¤‰æ›ãƒ¢ãƒ‡ãƒ«ã§ã®Attentionã¨åŒæ§˜ã®ã‚‚ã®ï¼ˆ<font color=\"Blue\">**Source Target Attention**</font>ï¼‰ã€‚\n","># <font color=\"silver\">ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®Attention\n","> â€» Query, Key, Valueã®å…¨ã¦ãŒã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å†…ã®å‰å±¤å‡ºåŠ›ï¼ˆ<font color=\"Blue\">**Self-Attention**</font>ï¼‰ã€‚\n","># <font color=\"silver\">ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã®Attention\n","> â€» Scaled Dot-Product Attentionã®softmaxã®å‰ã®å…¥åŠ›ã«å¯¾å¿œã™ã‚‹éƒ¨åˆ†ã‚’$-\\infty$ã«ç½®ãæ›ãˆã¦ãƒã‚¹ã‚¯ã™ã‚‹ï¼ˆ<font color=\"Blue\">**Masked Mult-Head Attention**</font>ï¼‰ã€‚<br>\n","> â€» ${\\rm softmax}(x_i)=\\frac{\\exp(x_i)}{\\sum_j \\exp (x_j)}$ ãªã®ã§ã€$x_i \\to -\\infty$ãªã‚‰ã€maskã•ã‚Œã‚‹ã€‚<br>\n","><font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦</font>](https://lilianweng.github.io/posts/2018-06-24-attention/)</font><br>\n","<img src=\"https://lilianweng.github.io/posts/2018-06-24-attention/transformer.png\" width=\"640\">\n"],"metadata":{"id":"ogF-XZGdnB20"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Transformer 3.3 Position-wise Feed-Forward Networks <br></font>\n","><font color=\"Blue\">**Position-wise Feed-Forward Networks <br></font>**</font><br>\n","> â€» Position-wiseã¨ã„ã†ã®ã¯ãŸã å˜ã«ã€å„å˜èªã”ã¨ã«ç‹¬ç«‹ã—ã¦ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒã‚ã‚‹ã¨ã„ã†ã“ã¨(ãŸã ã—ã€é‡ã¿ã¯å…±æœ‰)ã€‚ ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å†…ã§ã¯ä»–å˜èªã¨ã®å¹²æ¸‰ã¯ãªã„ã€‚2å±¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ãªã£ã¦ã„ã‚‹ã€‚<br>\n","<br>\n",">$\\rm{FFN}(x) = \\max(0, xW_1+b_1)W_2+b_2$"],"metadata":{"id":"RTBUAbnwnDXd"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Transformer 3.4 Embeddings and Softmax <br>"],"metadata":{"id":"QwQXdt5vnEvC"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Transformer 3.5 Positional Encoding<br></font>\n","><font color=\"Blue\">**Positional Encoding**</font><br>\n","> â€» æ™‚ç³»åˆ—ã‚’è€ƒæ…®ã™ã‚‹ãŸã‚ã«ã€å…¥åŠ›ã®åŸ‹ã‚è¾¼ã¿è¡¨ç¾ã«ã€Œä½ç½®æƒ…å ±ã€ã‚’åŸ‹ã‚è¾¼ã‚€ã€‚<br>\n","<br>\n",">$\\rm{PE}_{(pos, 2i)} = \\sin(pos / 10000^{2i / d_{model}})$\n","<br><br>\n","$\\rm{PE}_{(pos, 2i+1)} = \\cos(pos / 10000^{2i / d_{model}})$\n","<br><br>\n","$pos$ï¼š<font color=\"silver\">ä½ç½®</font><br>\n","$i$ï¼š<font color=\"silver\">æ¬¡å…ƒ</font><br>"],"metadata":{"id":"Cbp3Px4FnGO7"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Transformer 4 Why Self-Attention<br>\n",">â€» è¨ˆç®—é‡ãŒå°ã•ã„ã€‚(å†å¸°ã‚„ç•³ã¿è¾¼ã¿(Separable Convolution)ã‚ˆã‚Šã‚‚ã€‚)<br>\n","â€» ä¸¦åˆ—è¨ˆç®—å¯èƒ½<br>\n","â€» åºƒç¯„å›²ã®ä¾å­˜é–¢ä¿‚ã‚’å­¦ç¿’å¯èƒ½<br>\n","â€» é«˜ã„è§£é‡ˆå¯èƒ½æ€§<br>"],"metadata":{"id":"aQHReotVnH07"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Transformer 5 Training<br>"],"metadata":{"id":"dXntoyfmnJWj"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Transformer 6 Results<br></font>\n","\n",">  â€» ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®é•·ã• $n$ ã¯ï¼Œãƒ¢ãƒ‡ãƒ«ã®æ¬¡å…ƒ $d$ ã‚ˆã‚Šã‚‚å°ã•ã„ã“ã¨ãŒå¤šã„ã®ã§ã€$n<d$ ã§ï¼ŒSelf-Attentionã®è¨ˆç®—é‡ã‚³ã‚¹ãƒˆãŒæœ€ã‚‚å°ã•ããªã‚‹ã€‚\n","<br><br>\n","><img src=\"https://camo.qiitausercontent.com/493038d5bbfdd7e5a27858e84f288bf99c398d85/68747470733a2f2f696d6775722e636f6d2f667478666255682e706e67\" width=\"640\">\n","<br><br>\n","Complexity per layerï¼š1å±¤ã‚ãŸã‚Šã®è¨ˆç®—é‡<br>\n","Sequential Operationsï¼šé€æ¬¡å‡¦ç†ã‚’æœ€å°é™ã«ã™ã‚‹ä¸¦åˆ—å‡¦ç†å¯èƒ½ãªè¨ˆç®—é‡ã€‚Recurrentå±¤ã¯ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®é•·ã•ã ã‘ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã€‚<br>\n","Maximum Path Lengthï¼šãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å†…ã®é•·è·é›¢ä¾å­˜é–¢ä¿‚é–“ã®çµŒè·¯é•·ã€‚ Self-Attentionã¯å®šæ•°ã®ã‚³ã‚¹ãƒˆã§ï¼Œå…¥å‡ºåŠ›é–“ã®ä»»æ„ã®çµ„ã¿åˆã‚ã›ã®çµŒè·¯ã‚’ç¹‹ã’ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br>\n","<br>\n","> â€» Transformerã¯é«˜ã„ç¿»è¨³ç²¾åº¦ã‚’å‡ºã—ã¤ã¤ã€ã‹ã¤è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã§ãã¦ã„ã‚‹ã€‚<br>\n","<br>\n","><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fimgur.com%2FNzfVUU1.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=09d6a8ddcccf9bfb54845cea29493f2c\" width=\"640\"><br>"],"metadata":{"id":"O224v9pNnK50"}},{"cell_type":"markdown","source":["# <font color=\"silver\">Transformer 7 Conclusion <br>"],"metadata":{"id":"dsPaGkk2nMgo"}},{"cell_type":"markdown","source":["# <font color=\"Blue\">â– </font><font color=\"silver\">GNMT [<font color=\"silver\">â€¦](https://1drv.ms/w/s!AtNuKiQGFvCwpDqHErlaj63TplyF?e=NNelkC)</font><br>\n","<font color=\"silver\">GNMT, Google's Neural Machine Translation</font><br>\n","https://arxiv.org/pdf/1609.08144.pdf"],"metadata":{"id":"YcBxi6eYwbX2"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GNMT  1 Introduction èƒŒæ™¯"],"metadata":{"id":"QjphAxfTJti3"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GNMT  2 Related Work é–¢é€£äº‹é …"],"metadata":{"id":"ILrkvnHgJtq5"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GNMT  3 Model Architecture</font>\n","># <font color=\"silver\">Language Model, è¨€èªãƒ¢ãƒ‡ãƒ«</font>\n",">$\\boldsymbol{x_1}, \\, \\boldsymbol{x_2}, \\, \\ldots, \\, \\boldsymbol{x_M} = \\mathrm{EncorderRNN}(x_1, \\, x_2, \\, \\ldots, \\, x_M)$\n","<br><br>\n","$\\displaystyle\\begin{align}\n","P(Y|X) &= P(Y|\\boldsymbol{x_1}, \\, \\boldsymbol{x_2}, \\, \\ldots, \\, \\boldsymbol{x_M})\\\\\n","&= \\displaystyle\\prod_{i=1}^{N} P(y_i|y_0,y_1,\\ldots,y_{i-1};\\boldsymbol{x_1}, \\, \\boldsymbol{x_2}, \\, \\ldots, \\, \\boldsymbol{x_M})\n"," \\end{align}$\n","<br>\n"," $P(y_i | y_0, y_1, y_2, ..., y_{i-1};{\\boldsymbol x}_1, {\\boldsymbol x}_2, ..., {\\boldsymbol x_M}) $\n","># <font color=\"silver\">Encoder-Decoder</font>\n","> â€» 8å±¤ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãŠã‚ˆã³8å±¤ã®ãƒ‡ã‚³ãƒ¼ãƒ€ã® <font color=\"Blue\">**Encoder-Decoderæ§‹é€ **</font> ã§ã‚ã‚Šã€1å±¤ã”ã¨ã«è¨ˆ16å€‹ã® <font color=\"Blue\">**GPU**</font> ã‚’å‰²ã‚Šå½“ã¦ã‚‹ã€‚<br><br>\n","> â€» ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®1å±¤ç›®ï¼ˆ1æ®µç›®ã¨2æ®µç›®ã‚’åˆã‚ã›ãŸéƒ¨åˆ†ï¼‰ãŒ <font color=\"Blue\">**åŒæ–¹å‘LSTM**</font> ã§ã‚ã‚‹ã€‚ ã‚‚ã—ã€å…¨å±¤ã‚’åŒæ–¹å‘LSTMã«ã—ãŸå ´åˆã€ãã‚Œãã‚Œã®å±¤ã¯å‰ã®å±¤ã®é †æ–¹å‘ã¨é€†æ–¹å‘ ã®è¨ˆç®—ãŒçµ‚ã‚ã‚‹ã®ã‚’å¾…ãŸãªã‘ã‚Œã°ãªã‚‰ãšã€ 2GPU (é †æ–¹å‘ã«1ã€ é€†æ–¹å‘ã«1) ã— ã‹ä¸¦åˆ—ã«å‹•ã‹ã™ã“ã¨ãŒã§ããªã„ã€‚<br><br>\n","> â€» ãƒ‡ã‚³ãƒ¼ãƒ€ç¬¬1å±¤ã®å‡ºåŠ›ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ç¬¬8å±¤ã®å‡ºåŠ›ã¨ã§ <font color=\"Blue\">**Attention**</font> ã‚’è¨ˆç®—ã—ã€ãƒ‡ã‚³ãƒ¼ãƒ€ã®å…¨å±¤ã«é€ã‚‹ã€‚ãƒ‡ã‚³ãƒ¼ãƒ€ã®ç¬¬1å±¤ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®ç¬¬8å±¤ã§è¨ˆç®—ã™ã‚‹ã®ã¯ã€ä¸¦åˆ—åŒ–ã®åŠ¹ç‡ã‚’é«˜ã‚ã‚‹ãŸã‚ã€‚ ãƒ‡ã‚³ãƒ¼ãƒ€ã®ç¬¬8å±¤ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®ç¬¬8å±¤ã¨ã§ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’è¨ˆç®—ã™ã‚‹ã¨å¾…ã¡æ™‚é–“ãŒç™ºç”Ÿã™ã‚‹ã€‚<br><br>\n","<img src=\"https://norman3.github.io/papers/images/gnmt/f01.png\" width=\"640\"><br><br>\n",">$s_t = \\mathrm{AttentionFunction}(\\boldsymbol{y_{i-1}}, \\boldsymbol{x_t})  \\quad âˆ€t,\\quad 1 â‰¤ t â‰¤ M$\n","<br><br>\n","> $p_t = \\exp(s_t)/\\displaystyle\\sum_{t=1}^{M}\\exp(s_t) \\quad âˆ€t,\\quad 1 â‰¤ t â‰¤ M$\n","<br><br>\n","> $\\boldsymbol{a_i} = \\displaystyle\\sum_{t=1}^{M}p_t \\boldsymbol{x_t}$\n"],"metadata":{"id":"6njRUetvJ8PZ"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GNMT 3.1 Residual Connections</font>\n","> â€» <font color=\"Blue\">**Residual Connections, æ®‹å·®æ¥ç¶š**</font><br>\n","><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/R/Ryobot/20171218/20171218171123.png\" width=\"640\">\n","<br><br>\n","$\\begin{align}{\\bf c}_{t}^{i}, {\\bf m}_{t}^{i} &= LSTM_i({\\bf c}_{t-1}^{i}, {\\bf m}_{t-1}^{i}, {\\bf x}_{t}^{i-1};{\\bf W}^{i}) \\\\\n","{\\bf x}_{t}^{i} &= {\\bf m}_{t}^{i} \\\\\n","{\\bf c}_{t}^{i+1}, {\\bf m}_{t}^{i+1} &= LSTM_{i+1}({\\bf c}_{t-1}^{i+1}, {\\bf m}_{t-1}^{i+1}, {\\bf x}_{t}^{i};{\\bf W}^{i+1}) \\end{align}$\n","<br><br>\n","$\\begin{align}{\\bf c}_{t}^{i}, {\\bf m}_{t}^{i} &= LSTM_i({\\bf c}_{t-1}^{i}, {\\bf m}_{t-1}^{i}, {\\bf x}_{t}^{i-1};{\\bf W}^{i}) \\\\\n","{\\bf x}_{t}^{i} &= {\\bf m}_{t}^{i} + {\\bf x}_{t}^{i-1} \\\\\n","{\\bf c}_{t}^{i+1}, {\\bf m}_{t}^{i+1} &= LSTM_{i+1}({\\bf c}_{t-1}^{i+1}, {\\bf m}_{t-1}^{i+1}, {\\bf x}_{t}^{i};{\\bf W}^{i+1}) \\end{align}$"],"metadata":{"id":"zoCeCcSh9iui"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GNMT  3.2 Bi-directional Encoder for First Layer</font><br>\n","><img src=\"https://norman3.github.io/papers/images/gnmt/f04.png\" width=\"480\">"],"metadata":{"id":"1PAzNTvo-lz4"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GNMT 3.3 Model Parallelism\n","> â€» <font color=\"Blue\">**ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—**</font> åŠã³ <font color=\"Blue\">**ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—**</font> ã‚’æ¡ç”¨ã—ã¦ãŠã‚Šã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ›´æ–°ã¯ <font color=\"Blue\">**éåŒæœŸå‹**</font> ã§è¡Œã†ã€‚<br>"],"metadata":{"id":"MUOgJYjOOqHk"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GNMT 4 Segmentation Approaches"],"metadata":{"id":"nNSa-qspPIGL"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GNMT 4.1 Wordpiece Model\n","> â€» <font color=\"Blue\">**Wordpiece**</font> ã¨  <font color=\"Blue\">**Sentencepiece**</font><br>"],"metadata":{"id":"wKJNd42-PSpX"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GNMT 4.2 Mixed Word/Character Model"],"metadata":{"id":"0Dah_KPIPVpI"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GNMT 5 Training Criteria\n","> â€» <font color=\"Blue\">**Reward Objective, å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚‹å†å­¦ç¿’**</font><br><br>\n","><font color=\"black\">$\\displaystyle\\mathcal{O}_{mixed}(\\theta) = \\alpha \\times \\mathcal{O}_{ML}(\\theta) + \\mathcal{O}_{RL}(\\theta)$\n","<br><br>\n","$\\displaystyle\\mathcal{O}_{ML}({\\bf \\theta}) = \\sum_{i=1}^{N}\\log P_{\\theta}({\\bf Y}^{*(i)}|{\\bf X}^{(i)}) $\n","<br><br>\n","$\\displaystyle\\mathcal{O}_{RL}({\\bf \\theta}) = \\sum_{i=1}^{N}\\sum_{Y \\in \\mathcal{Y}} P_{\\theta}({\\bf Y}|{\\bf X}^{(i)}) r({\\bf Y}, {\\bf Y}^{*(i)}) $"],"metadata":{"id":"1d42zmUQPab-"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GNMT 6 Quantizable Model and Quantized Inference\n","> â€» <font color=\"Blue\">**Quantization, é‡å­åŒ–ã«ã‚ˆã‚‹é«˜é€ŸåŒ–**</font><br><br>\n",">$\\begin{align}{\\bf c}_{t}^{'i}, {\\bf m}_{t}^{i} &= LSTM_i({\\bf c}_{t-1}^{i}, {\\bf m}_{t-1}^{i}, {\\bf x}_{t}^{i-1};{\\bf W}^{i}) \\\\\n","{\\bf c}_{t}^{i} &= \\max(-\\delta, \\min(\\delta, {\\bf c}_{t}^{'i})) \\\\\n","{\\bf x}_{t}^{'i} &= {\\bf m}_{t}^{i} + {\\bf x}_{t}^{i-1} \\\\\n","{\\bf x}_{t}^{'i} &= \\max(-\\delta, min(\\delta, {\\bf x}_{t}^{'i}) \\\\\n","{\\bf c}_{t}^{i+1}, {\\bf m}_{t}^{i+1} &= LSTM_{i+1}({\\bf c}_{t-1}^{i+1}, {\\bf m}_{t-1}^{i+1}, {\\bf x}_{t}^{i};{\\bf W}^{i+1}) \\\\\n","{\\bf c}_{t}^{'i+1} &= \\max(\\delta, min(\\delta, {\\bf c}_{t}^{'i+1})) \\end{align}$\n","<br><br>\n","$\\begin{align}{\\bf W} &= [{\\bf W}_1, {\\bf W}_2, {\\bf W}_3, {\\bf W}_4, {\\bf W}_5, {\\bf W}_6, {\\bf W}_7, {\\bf W}_8 ] \\\\\n","{\\bf i}_t &= sigmoid({\\bf W}_1{\\bf x}_t + {\\bf W}_2{\\bf m}_t) \\\\\n","{\\bf i'}_t &=tanh({\\bf W}_3{\\bf x}_t + {\\bf W}_4{\\bf m}_t) \\\\\n","{\\bf f}_t &= sigmoid({\\bf W}_5{\\bf x}_t + {\\bf W}_6{\\bf m}_t) \\\\\n","{\\bf o}_t &= sigmoid({\\bf W}_7{\\bf x}_t + {\\bf W}_8{\\bf m}_t) \\\\\n","{\\bf c}_t &= {\\bf c}_{t-1} \\odot {\\bf f}_{t} + {\\bf i}_{t}^{'} \\odot {\\bf i}_{t} \\\\\n","{\\bf m}_t &= {\\bf c}_{t} \\odot {\\bf o}_{t} \\end{align}$\n","<br><br>\n","$\\begin{align}s_i &= \\max(abs({\\bf W}[i,:])) \\\\\n","{\\bf WQ}[i,j] &= round({\\bf W}[i,j] / {\\bf s}_i \\times 127.0) \\end{align}$\n","<br><br>\n","$\\begin{align}{\\bf v}_t &= {\\bf W}_s \\times {\\bf y}_t \\\\\n","{\\bf v}_t^{'} &= \\max(-\\gamma, min(\\gamma, {\\bf v}_t)) \\\\\n","{\\bf p}_t &= softmax({\\bf v}_t^{'})\\end{align}$\n","<br><br>\n","><img src=\"https://norman3.github.io/papers/images/gnmt/f05.png\" width=\"480\">\n","<br><br>\n","><img src=\"https://norman3.github.io/papers/images/gnmt/f06.png\" width=\"480\">\n","\n"],"metadata":{"id":"Lniu3De4QPnp"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GNMT 7 Decoder\n","\n",">$\\begin{align}s({\\bf Y}, {\\bf X}) &= \\log(P({\\bf Y}|{\\bf X}))/lp({\\bf Y}) + cp({\\bf X};{\\bf Y}) \\\\\n","lp({\\bf Y}) &= \\frac{(5+|{\\bf Y}|)^{\\alpha}}{(5+1)^{\\alpha}} \\\\\n","cp({\\bf X};{\\bf Y}) &= \\beta * \\sum_{i=1}^{|{\\bf X}|} \\log(\\min(\\sum_{j=1}^{|{\\bf Y}|}p_{i,j}, 1.0)), \\end{align}$\n","<br><br>\n","><img src=\"https://norman3.github.io/papers/images/gnmt/f07.png\" width=\"480\">\n","<br><br>\n","><img src=\"https://norman3.github.io/papers/images/gnmt/f08.png\" width=\"480\">"],"metadata":{"id":"OuKasYSShUD5"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GNMT 8 Experiments and Results å®Ÿé¨“\n","\n","><img src=\"https://norman3.github.io/papers/images/gnmt/f09.png\" width=\"480\">"],"metadata":{"id":"ptL3llHSRik4"}},{"cell_type":"markdown","source":["# <font color=\"Blue\">â– </font><font color=\"silver\">BERT [<font color=\"silver\">â€¦](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4675&cid=b0f01606242a6ed3&CT=1668010639719&OR=ItemsView)</font>\n","https://arxiv.org/pdf/1810.04805.pdf\n"],"metadata":{"id":"pK5t0MwcVt0l"}},{"cell_type":"markdown","source":["# <font color=\"silver\">BERT  1 Introduction å°å…¥\n","<img src=\"https://data-analytics.fun/wp-content/uploads/2020/04/bert3.png\" width=\"640\"><br>"],"metadata":{"id":"CZkaclhbekfd"}},{"cell_type":"markdown","source":["# <font color=\"silver\">BERT  2  Related Work é–¢é€£äº‹é …"],"metadata":{"id":"MICpVnPbhad4"}},{"cell_type":"markdown","source":["# <font color=\"silver\">BERT  3 BERT\n","> â€» åˆã‚ã¦ã®æ·±ã„åŒæ–¹å‘å‹æ•™å¸«ãªã—è¨€èªãƒ¢ãƒ‡ãƒ«<br>\n","> â€» æ•™å¸«ãªã—äº‹å‰å­¦ç¿’ã«ã‚ˆã‚Šè¨€èªåˆ†æ•£è¡¨ç¾ã‚’ç²å¾—ã—ã€æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã£ã¦ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã¸é©å¿œã•ã›ã‚‹<br>\n","> â€» æœ€å¾Œã«å‡ºåŠ›å±¤ã‚’è¿½åŠ ã™ã‚‹ã ã‘ã§åˆ©ç”¨ã§ãã‚‹æ±ç”¨æ€§ãŒé«˜ã„ãƒ¢ãƒ‡ãƒ«<br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fimgur.com%2F1ol4NHO.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=e51ac8d5c804ad835a5d5c50a13eb5dc\" width=\"640\"><br>\n","># <font color=\"silver\">ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£\n","> â€» æ·±ã„åŒæ–¹å‘å‹ã®Transformerã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®ã¿ã§æ§‹æˆã•ã‚ŒãŸæ§‹é€ <br>\n","> â€» Transformerã‚„GPTã¯å‰å‘ãã€ã¾ãŸã€ELMoã¯å‰å‘ãã¨å¾Œã‚å‘ãã‚’åˆ¥ã§è¨ˆç®—ã—ã¦ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’çµåˆã™ã‚‹ãŸã‚ã€æµ…ã„åŒæ–¹å‘LSTM<br>\n","># <font color=\"silver\">BERT  å…¥åŠ›ï¼å‡ºåŠ›è¡¨ç¾\n","> â€» sentenceã®å…ˆé ­ã«[CLS]ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŒãŸã›ã‚‹ã€‚<br>\n","> â€» é–“ã«[SEP]ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…¥ã‚Œ 1æ–‡ç›®ã‹2æ–‡ç›®ã‹ã‚’è¡¨ã™åŸ‹ã‚è¾¼ã¿è¡¨ç¾ã‚’åŠ ç®— ã™ã‚‹ã€‚<br>\n","> â€» ãƒˆãƒ¼ã‚¯ãƒ³ï¼‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼‹ãƒã‚¸ã‚·ãƒ§ãƒ³ã€‚<br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fimgur.com%2F65BPFqu.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=1b61f96cff68acdd08e93cb7f0ca2d77\" width=\"800\"><br>"],"metadata":{"id":"lkKQLdDZhwch"}},{"cell_type":"markdown","source":["# <font color=\"silver\">BERT  3.1 Pre-training BERT\n","># <font color=\"silver\">Task1: MLM,  Masked Language Modeling, å˜èªãƒã‚¹ã‚¯å•é¡Œ, å±€æ‰€çš„ãªç‰¹å¾´å­¦ç¿’\n","> â€» å…¥åŠ›ç³»åˆ—ã®ã†ã¡ã€éš ã•ã‚ŒãŸå˜èªãŒãªã«ã‹ã‚’äºˆæ¸¬<br>\n","> â€» å…¥åŠ›ã®15%ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’[Mask]ãƒˆãƒ¼ã‚¯ãƒ³ã§ãƒã‚¹ã‚¯ã—ã€å…ƒã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å½“ã¦ã‚‹ã‚¿ã‚¹ã‚¯<br>\n","># <font color=\"silver\">Task2: NSP, Next Sentence Prediction,  éš£æ¥æ–‡å•é¡Œ, å¤§åŸŸçš„ãªç‰¹å¾´å­¦ç¿’\n","> â€» 2ã¤ã®å…¥åŠ›æ–‡ãŒéš£ã‚Šåˆã†ã‚‚ã®ã‹ã©ã†ã‹ã‚’åˆ¤åˆ¥<br>\n","> â€» 2æ–‡é¸ã‚“ã§ãã‚Œã‚‰ãŒé€£ç¶šã—ãŸæ–‡ã‹ã©ã†ã‹ã‚’å½“ã¦ã‚‹ã‚¿ã‚¹ã‚¯<br>"],"metadata":{"id":"YzERtA2Dhxqk"}},{"cell_type":"markdown","source":["# <font color=\"silver\">BERT  3.2 Fine-tuning BERT\n","> <img src=\"https://camo.qiitausercontent.com/1e8f78d544a2e314fc94afeb7490a6b720ae3e73/68747470733a2f2f696d6775722e636f6d2f4a4f69735065762e706e67\" width=\"640\"><br>"],"metadata":{"id":"tJRP8V9jicA8"}},{"cell_type":"markdown","source":["# <font color=\"silver\">BERT  4 Experiments å®Ÿé¨“\n","> â€» GLUEãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ã¤ã„ã¦<br>\n","<img src=\"https://deepsquare.jp/wp-content/uploads/2020/09/GLUE.jpg\" width=\"800\"><br>\n","<img src=\"https://deepsquare.jp/wp-content/uploads/2020/09/SQuAD.png\" width=\"480\"><br>\n","<img src=\"https://deepsquare.jp/wp-content/uploads/2020/09/SWAG.png\" width=\"480\"><br>\n"],"metadata":{"id":"8kfhzPekilic"}},{"cell_type":"markdown","source":["# <font color=\"silver\">BERT  5. Ablation Studies\n","><img src=\"https://deepsquare.jp/wp-content/uploads/2020/09/compare_traing.png\" width=\"480\"><br>\n","<img src=\"https://deepsquare.jp/wp-content/uploads/2020/09/model_size.png\" width=\"480\"><br>\n","<img src=\"https://deepsquare.jp/wp-content/uploads/2020/09/feature_approch.png\" width=\"480\"><br>"],"metadata":{"id":"ePahR0lFjI1c"}},{"cell_type":"markdown","source":["# <font color=\"silver\">BERT  6 Conclusion çµè«–"],"metadata":{"id":"0LzXTRlikL2X"}},{"cell_type":"markdown","source":["# <font color=\"Blue\">â– </font><font color=\"silver\">GPT [<font color=\"silver\">â€¦</font>](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4677&cid=b0f01606242a6ed3&CT=1666551710079&OR=ItemsView)</font><br>"],"metadata":{"id":"BnfMqUeMUgme"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   1 Introduction èƒŒæ™¯"],"metadata":{"id":"1TAix0KpmO6Z"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   2 Related Work é–¢é€£äº‹é …"],"metadata":{"id":"bk8ZIDzNmPO-"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   Semi-supervised learning for NLP  "],"metadata":{"id":"Ec-SGIsomPgY"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   Unsupervised pre-training\n"],"metadata":{"id":"YvJh3j3lmPxw"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   Auxiliary training objectives"],"metadata":{"id":"56vfn6GzmQHo"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   3 Framework\n","<img src=\"https://data-analytics.fun/wp-content/uploads/2020/04/open-gpt.png\" width=\"160\"><br>\n","<img src=\"https://data-analytics.fun/wp-content/uploads/2020/04/open-gpt_input.png\" width=\"640\"><br>"],"metadata":{"id":"ui_D-kXBmQY_"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   3.1 Unsupervised pre-training\n","$ \\displaystyle L_1\\left(\\mathcal{U}\\right)=\\sum_i \\log P\\left(u_i| u_{i-k}, \\cdots, u_{i-1}; \\Theta\\right)$\n","<br><br>\n","$\\begin{align} h_0 = UW_e + W_p \\end{align}$\n","<br><br>\n","$h_l=\\text{transformer_block}\\left(h_{l-1}\\right)$\n","<br><br>\n","$P(u)=\\text{softmax}\\left(h_nW_e^T\\right)$\n","<br><br>\n","$W_e$ï¼š<font color=\"silver\">word embedding matix<br></font>\n","$W_p$ï¼š<font color=\"silver\">position embedding matrixã€Transformerã®è«–æ–‡ã®ã‚ˆã†ã«sinãƒ»cosã‚’ä½¿ã£ãŸæ–¹æ³•ã§ã¯ãªãã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’ã™ã‚‹ã€‚"],"metadata":{"id":"YD1FGqCFmQpn"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   3.2 Supervised fine-tuning\n","$P\\left(y|x^1, \\cdots, x^m\\right)=\\text{softmax}\\left(h_l^m W_y\\right)$\n","<br><br>\n","$\\displaystyle L_2\\left(\\mathcal{C}\\right)=\\sum_{(x, y)}\\log P\\left(y|x^1, \\cdots, x^m\\right)$\n","<br><br>\n","$L_3(\\mathcal{C})=L_2(\\mathcal{C})+\\lambda*L_1(\\mathcal{C})$"],"metadata":{"id":"wvjJe-kbmQ5-"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   3.3 Task-specific input transformation"],"metadata":{"id":"zpA8700mmg7o"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   Textual entailment"],"metadata":{"id":"sPaf_68jmhO2"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   Similarity"],"metadata":{"id":"usCzAjVQmhgG"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   Question Answering and Commonsense Reasoning  "],"metadata":{"id":"_XB5KJrImRKW"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   4 Experiments å®Ÿé¨“\n"],"metadata":{"id":"2qth9pJlms6C"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   4.1 Setup"],"metadata":{"id":"LbUe5dCYmtP3"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   Unsupervised pre-training"],"metadata":{"id":"0c85svJKm1X3"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   Model specifications\n","GELU, Gaussian Error Linear Unit<br>\n","<br>\n","$\\begin{align} \\text{GELU}(x)&=x\\Phi(x)\\\\ &\\sim0.5x\\left(1+\\tanh\\left[\\sqrt{2/\\pi}\\left(x+0.044715x^3\\right)\\right]\\right) \\end{align}$<br>\n","<br>\n","<img src=\"https://data-analytics.fun/wp-content/uploads/2020/04/GELU.png\" width=\"320\"><br>\n"],"metadata":{"id":"bQyF18Wfm13X"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   Fine-tuning details"],"metadata":{"id":"X-iYemojm74o"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   4.2 Supervised fine-tuning"],"metadata":{"id":"de_amNOCm8JP"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   Natural Language Inference\n","<img src=\"https://data-analytics.fun/wp-content/uploads/2020/04/open-gpt_result1-1024x444.png\" width=\"640\"><br>"],"metadata":{"id":"riUdybsLm_-o"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   Question answering and commonsense reasoning\n","<img src=\"https://data-analytics.fun/wp-content/uploads/2020/04/open-gpt_result2-1024x376.png\" width=\"640\"><br>"],"metadata":{"id":"whtwCqztnAP-"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   Semantic Similarity\n","<img src=\"https://data-analytics.fun/wp-content/uploads/2020/04/open-gpt_result3-1024x481.png\" width=\"640\"><br>"],"metadata":{"id":"PlypquaSnAiZ"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   Classification"],"metadata":{"id":"AiYbHaBgqLhg"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   5 Analysis"],"metadata":{"id":"tFpggFo6qL1N"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   Impact of number of layers transferred"],"metadata":{"id":"PRsVw7JOqMJ1"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   Zero-shot Behaviors"],"metadata":{"id":"XeRPMguQqSWw"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   Ablation studies"],"metadata":{"id":"X3PvWNZfqSrF"}},{"cell_type":"markdown","source":["# <font color=\"silver\">GPT   6 Conclusion çµè«–"],"metadata":{"id":"e1NqLmCrqYRg"}},{"cell_type":"markdown","source":["# <font color=\"Blue\">â– </font><font color=\"silver\">WaveNet [<font color=\"silver\">â€¦](https://onedrive.live.com/edit.aspx?resid=B0F01606242A6ED3!4718&cid=b0f01606242a6ed3&CT=1666690533933&OR=ItemsView)<br>\n","https://arxiv.org/pdf/1609.03499.pdf\n"],"metadata":{"id":"AiYokRajnRBM"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WaveNet  1 Introduction èƒŒæ™¯"],"metadata":{"id":"oLopu_7aoWQI"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WaveNet  2 WaveNet</font>\n","> â€» PixelCNNã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸéŸ³å£°æ³¢å½¢ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</font><br>\n","${p(\\mathbf{x}) = \\displaystyle \\prod_{t=1}^{T}p(x_{t}\\ |\\ x_{1}, \\cdots, x_{t-1})\n","}$"],"metadata":{"id":"X_ruWZ1hoaY2"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WaveNet  2.1 Dilated Causal Convolutions\n","># <font color=\"silver\">Causal Convolution</font>\n","> â€» äºˆæ¸¬åˆ†å¸ƒ $p(x_{t+1} | x_{1}, \\cdots, x_{t})$ã¯å°†æ¥ã®æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ— $x_{t+1}, x_{t+2}, \\cdots, x_{T}$ã«ã¯ä¾å­˜ã—ãªã„<br>\n","> â€» å°†æ¥ã®ãƒ‡ãƒ¼ã‚¿ã«ãƒã‚¹ã‚¯ã—ã¦ã„ã‚‹ã¨ã„ã†masked convolutionã¨ç­‰ä¾¡<br>\n","> â€» RNNã‚ˆã‚Šå­¦ç¿’ãŒé€Ÿã„<br>\n","> â€» å—å®¹ä½“ã‚’åºƒãã™ã‚‹ã«ã¯ã€å¤šãã®å±¤åˆã¯å¤§ããªãƒ•ã‚£ãƒ«ã‚¿ãŒå¿…è¦<br><br>\n","<img src=\"https://storage.googleapis.com/zenn-user-upload/44262da54bfa-20220804.png\" width=\"480\"><br>\n","># <font color=\"silver\"> Dilated Causal Convolution</font>\n","> â€» å±¤ãŒæ·±ããªã‚‹ã«ã¤ã‚Œã¦, ç•³ã¿è¾¼ã‚€ãƒãƒ¼ãƒ‰ã‚’é›¢ã™(Dilation)<br>\n","> â€» 1,2,4,8,â‹¯,512ã¨æŒ‡æ•°çš„ã«å¤§ããã—ã¦ã„ã‚‹.  Inputã‹ã‚‰Outputã«ã‹ã‘ã¦, Dilation=1,2,4,8Dilation=1,2,4,8ã¨ãªã£ã¦ã„ã‚‹<br><br>\n","<img src=\"https://storage.googleapis.com/zenn-user-upload/d30785693173-20220804.png\" width=\"480\"><br>\n","<br>\n","<font color=\"silver\">$\\tiny\\text{ç”»åƒå¼•ç”¨å…ƒ}$[<font color=\"silver\">â€¦](https://subscription.packtpub.com/book/data/9781789136364/4/ch04lvl1sec59/dilated-and-causal-convolution)</font></font><br>\n","<img src=\"https://static.packt-cdn.com/products/9781789136364/graphics/B10354_04_16.jpg\" width=\"240\">\n","<img src=\"https://static.packt-cdn.com/products/9781789136364/graphics/B10354_04_17.jpg\" width=\"240\">\n","<img src=\"https://static.packt-cdn.com/products/9781789136364/graphics/B10354_04_18.jpg\" width=\"240\">"],"metadata":{"id":"KVxOxI4tobm6"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WaveNet  2.2 Softmax Distribution</font>\n","> â€» $Î¼$-law companding transformation</font><br>\n","> â€» éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã¯16-bit/tã§ã‚ã‚‹ãŸã‚ã€65,536å€‹ã®ç¢ºç‡ã®è¨ˆç®—ãŒå¿…è¦ã§è¨ˆç®—é‡ãŒå¤šã„ã€‚è¨ˆç®—é‡å‰Šæ¸›ã®ãŸã‚ã€Softmax Layerã§ã¯ã€Î¼-lowã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”¨ã„ã¦256é€šã‚Šã«é‡å­åŒ–ã—ã€ç”Ÿæˆã™ã‚‹éŸ³å£°ãŒã©ã®ã‚¯ãƒ©ã‚¹ã«å±ã™ã‚‹ã‹ã¨ã„ã†åˆ†é¡å•é¡Œã¨ã—ã¦ç”ŸæˆéŸ³å£°ã®äºˆæ¸¬ã‚’è¡Œã†ã€‚\n","<br>\n","$f(x_{t}) = \\rm{sign}(x_{t}) \\displaystyle \\frac{\\log \\{1 + \\mu |x_{t}|\\}}{\\log \\{1 + \\mu \\}}$\n","<br><br>\n","$-1 < x_{t} < 1, \\mu = 255$\n"],"metadata":{"id":"e06wODeHob_7"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WaveNet  2.3 Gated Activation Units\n","> â€» ã‚²ãƒ¼ãƒˆã¨å‡ºåŠ›å€™è£œã«ã¯åˆ¥ã®é‡ã¿ã‚’ç”¨ã„ã‚‹<br>\n","<font color=\"black\">$\\mathbf{z} = \\tanh (W_{f, k} * \\mathbf{x}) \\odot \\sigma (W_{g, k} * \\mathbf{x})$<br><br>\n","$*$ï¼š<font color=\"silver\">ç•³ã¿è¾¼ã¿ã®æ¼”ç®—</font><br>\n","$k$ï¼š<font color=\"silver\">layer index</font><br>\n","$f$ï¼š<font color=\"silver\">filter</font><br>\n","$g$ï¼š<font color=\"silver\">gate</font><br>\n","$Ïƒ$ï¼š<font color=\"silver\">sigmoidé–¢æ•°</font>\n","<br><br>\n","<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F218720%2F081f61bb-6bc2-f891-36b0-26f3b4df6e16.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=b093519e6fa1320dca152e8beaff1ad7\" width=\"480\"><br>\n"],"metadata":{"id":"uWslJqWwocVT"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WaveNet  2.4 Residual and skip connections\n","> â€» Residual and skip connectionss<br>\n","> â€» 1x1 Convolutionsã§ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã‚’èª¿ç¯€ã™ã‚‹\n"],"metadata":{"id":"JxgGhqrXocrk"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WaveNet  2.5 Conditional WaveNet\n","> â€» è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«ã«ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ã®ç‰¹å¾´ã‚’ç‰¹å®šã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã™ã‚‹ã‚¤ãƒ³ãƒ—ãƒƒãƒˆ$\\mathbf{h}$ã‚’åŠ ãˆã‚‹ã€‚<br>\n","> â€» ä¾‹ãˆã°, è¤‡æ•°ã®è©±ã—æ‰‹ã®éŸ³å£°ãŒå«ã¾ã‚Œã‚‹éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¤ã„ã¦ã‚¤ãƒ³ãƒ—ãƒƒãƒˆ$\\mathbf{h}$ã¨ã—ã¦è©±ã—æ‰‹ã®ç‰¹å¾´ã‚’ãƒ¢ãƒ‡ãƒ«ã«åŠ ãˆã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€ãã®è¤‡æ•°ã®è©±ã—æ‰‹ã®ä¸­ã‹ã‚‰ç‰¹å®šã®è©±ã—æ‰‹ã‚’é¸æŠã™ã‚‹ã“ã¨ãŒã§ãã‚‹<br>\n","<font color=\"black\">$p(\\mathbf{x}\\ |\\ \\mathbf{h}) = \\displaystyle \\prod_{t=1}^{T}p(x_{t}\\ | \\ x_{1}, \\cdots, x_{t-1}, \\mathbf{h})$\n","># <font color=\"silver\">Global conditioning\n",">$\\mathbf{z} = \\tanh (W_{f, k} * \\mathbf{x} + V_{f, k}^{T}\\mathbf{h}) \\odot \\sigma (W_{g, k} * \\mathbf{x} + V_{g, k}^{T}\\mathbf{h})$\n","># <font color=\"silver\">Local conditioning\n",">$\\mathbf{z} = \\tanh (W_{f, k} * \\mathbf{x} + V_{f, k}^{T} * f(\\mathbf{h})) \\odot \\sigma (W_{g, k} * \\mathbf{x} + V_{g, k}^{T} * f(\\mathbf{h}))$"],"metadata":{"id":"ZuiKpVpfodBU"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WaveNet  2.6 Context Stack"],"metadata":{"id":"sHH_FvoGozbP"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WaveNet  3 Experiments å®Ÿé¨“"],"metadata":{"id":"Kc0kFp2xpvJu"}},{"cell_type":"markdown","source":["# <font color=\"silver\">WaveNet  4 Conclusion çµè«–"],"metadata":{"id":"dM1jI4mkp27m"}}]}